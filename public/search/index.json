[{"content":"アルゼンチンのアンデス山脈を舞台にした壮大な山岳写真に、私たちの経済活動の痕跡が刻まれているとしたら―。ドイツ出身のアーティスト Michael Najjar（マイケル・ナジャー） が手がけた写真シリーズ「High Altitude」は、その驚くべき試みを実現しています。\nこのシリーズは、ナジャー自身が標高 7,000m 級の山々を実際に登攀（とうはん）し撮影した風景をベースにしています。しかし単なる山岳写真ではありません。山肌の稜線は、世界主要市場の株価指数の推移をもとにデジタル加工されており、日経平均、ナスダック、リーマン・ブラザーズの崩壊など、数十年にわたる金融データが「山のかたち」として可視化されているのです。\n1966年から2009年までの日経平均株価 1960年代後半は、日本が高度経済成長を遂げていた時期であり、株価も右肩上がりでした。その後、1989年のバブル崩壊 を経て、90年代から2000年代にかけての「失われた20年」に沈んでいきます。1966年〜2009年という範囲を選ぶことで、\n成長 バブル 崩壊と長期低迷 という日本経済の「典型的な物語」が一枚の山岳稜線に収まるのです。 1980年から2009年までのナスダック指数 1980年から2009年のナスダック指数は、テクノロジー市場の勃興と危機を象徴する動きです。80年代にはマイクロソフトやアップルなどの新興IT企業が上場し、市場全体が着実に拡大。90年代後半にはドットコム・バブルによって指数は急騰しますが、2000年の崩壊で一気に暴落しました。その後2000年代半ばにかけて再び上昇基調を見せるものの、2008年のリーマン・ショックで再び大きく下落します。この稜線は、テクノロジー産業の「急成長」「バブル」「崩壊」「再生」を劇的に表現しています。\n1992年から2008年までのリーマン・ブラザーズ株価 1992年から2008年までのリーマン・ブラザーズ株価は、金融業界の拡大と突然の崩壊を象徴する稜線です。90年代には投資銀行としての地位を高め、2000年代半ばまでは住宅ローン関連ビジネスの拡大によって株価も右肩上がりに成長しました。しかし、2007年のサブプライム危機をきっかけに急落し、2008年9月の破綻時には株価が一気に無価値同然に崩れ落ちます。作品に刻まれた稜線は、長い上昇ののち突然断ち切られるように途絶えており、世界金融危機の衝撃を山の崖として体感できるビジュアルとなっています。\n1980年から2009年のハンセン指数（香港市場） 1980年から2009年のハンセン指数（香港市場）は、中国本土と香港経済の急速な成長を映し出す稜線です。1980年代には比較的安定した推移を見せつつ、1997年のアジア通貨危機で急落。その後は中国の経済開放と急成長を背景に、2000年代半ばにかけて指数は大きく上昇し、2007年には史上最高値を記録しました。しかし、2008年のリーマン・ショックでは急落し、グローバル市場の一部としての香港の脆弱性が露わになります。 この稜線は、アジア金融市場が国際的な波に翻弄されながらも力強く成長してきた軌跡を、山岳のシルエットとして鮮烈に描き出しています。\n株価が風景を彫刻する 公式サイトの解説によると、「High Altitude」シリーズは過去20〜30年の世界主要株価指数の動きを山の稜線に変換したものです。つまり、経済の浮き沈みを登山者が見上げる山岳の形として具現化しています。これにより、私たちが普段は抽象的な数字としてしか目にしない株価変動が、自然景観に刻印されたかのようにリアルな存在感を放ちます。\nbitforms gallery の展覧会説明では、このシリーズが単なる写真表現にとどまらず、データとランドスケープを融合させたメディア・アートの実験であることが強調されています。作品タイトルには「lehman_92-08」のように具体的な年号が含まれるものもあり、個別の市場や銘柄のストーリーが「山」として残されています。\n山と経済のスケールを往還する体験 ナジャーの「High Altitude」は、私たちが経済をどう受け止めるかについて新しい視点を与えます。通常はグラフや数字の羅列として処理されるデータが、圧倒的な自然景観と結びつくことで、経済のリズムが地球規模の地形変動のように感じられるのです。そこには、金融市場の動きが人間社会を超えて「自然現象」にまで思えてしまう、ぞっとするような示唆があります。\nおまけ：Kevin Slavin のTEDトーク 株価やアルゴリズムが現実世界を変えてしまうというテーマは Kevin Slavin（ケヴィン・スレイヴィン）のTEDトーク「How algorithms shape our world」 でも取り上げられています。彼は高速取引のために山を削り、ニューヨークとシカゴを結ぶ通信経路を直線化した事例を紹介し、アルゴリズムが文字通り地形を変えてしまう現実を語りました。\nナジャーの作品とあわせて考えると、私たちの経済活動やアルゴリズムは、抽象的なデータにとどまらず、風景や地形そのものを形づくる力を持っていることに気づかされます。\n参考・出典 Michael Najjar: High Altitude（公式サイト） High Altitude – bitforms gallery（展示サイト） ","date":"2025-09-20T00:00:00Z","image":"http://localhost:1313/high-altitude/images/nikkei_66-09_hu_aa5464ac2dc03323.png","permalink":"http://localhost:1313/high-altitude/","title":"山岳写真に刻まれた株価の変動 ― Michael Najjar「High Altitude」"},{"content":"2011年のTEDGlobalで登壇したケヴィン・スレイヴィンは、私たちの世界がアルゴリズムによってどのように形作られているかを語りました。その中でも特に印象的なのが「高速取引（High-Frequency Trading）のために山を削った」というエピソードです。\n山を削ってでも速さを求める金融市場 金融市場では、取引所に注文を届けるまでのわずか数ミリ秒が勝敗を分けます。そのため、ニューヨークとシカゴを結ぶ通信回線を極限まで短縮する計画が進められました。\nこのプロジェクトを担ったのが Spread Networks という企業です。Forbes の報道によれば、総工費はおよそ3億ドル。従来の回線が鉄道や道路に沿って大きく迂回していたのに対し、新ルートはアレゲニー山脈を突き抜けるように「できる限り直線」に敷設されました。その結果、通信時間は往復でおよそ16ミリ秒から13ミリ秒へと短縮されたといいます。わずか3ミリ秒の改善のために、山岳を突き抜ける大規模な工事が行われたという事実は衝撃的です。しかし高速取引の世界では、このわずかな差が巨額の利益につながるため、莫大な投資が正当化されてしまうのです。\nこの「山を削る」という比喩は、アルゴリズムが単なるコンピュータの中の存在ではなく、物理的な地形をも書き換える力を持つことを端的に示しています。\nデータが風景を形づくる ― Michael Najjar「High Altitude」 このエピソードを思い起こさせる作品に、ドイツ出身のアーティスト Michael Najjar の写真シリーズ「High Altitude」があります。\n彼はアルゼンチンの高山を実際に（とうはん）して撮影し、その稜線を 株価指数の時系列データに基づいて加工しました。日経平均やナスダック、リーマン・ブラザーズの株価までが、山のかたちとして可視化されています。\nつまり、ナジャーの作品では「株価が山をつくる」。一方で、スレイヴィンのエピソードでは「アルゴリズムのために山が削られる」。 方向は逆ですが、どちらも 人間の経済活動やアルゴリズムが、風景や地形を変えてしまう という驚くべき現実を示しています。\nまとめ スレイヴィンが語った「山を削るアルゴリズム」と、ナジャーが示した「山に刻まれた株価の稜線」。 両者は異なる文脈にありながらも、共通してデータやアルゴリズムが抽象を超えて現実世界の形を変化させる様子を示しています。\n注意 実際にニューヨーク〜シカゴ間で最短ルートの光ファイバーが敷設されたことは、Forbes や学術研究でも裏付けられています。ただし「大規模に山体を切り崩した」かどうかまでは公開情報から確認できません。したがって、“山を削った”というのは、地形を突き抜ける最短ルートを選んだことの比喩と理解するのが妥当でしょう。\n参考・出典 -Kevin Slavin: How algorithms shape our world | TED Talk\n-Michael Najjar: High Altitude（公式サイト）\n-High Altitude – bitforms gallery 展覧会ページ\n-Spread Networks – Wikipedia\n-Chicago Booth Review: An Alternative to High-Frequency Trading\n-Forbes: Wall Street’s Speed War\n-Budish, Cramton, Shim: The High-Frequency Trading Arms Race（Quarterly Journal of Economics, 2015）\n","date":"2025-09-20T00:00:00Z","image":"http://localhost:1313/high-frequency-trading/images/how_algorithms_shape_02_hu_4abb2ad60b45e4bb.png","permalink":"http://localhost:1313/high-frequency-trading/","title":"地形を変えるアルゴリズム ― Kevin Slavin のTEDトークから"},{"content":"この記事では、連続的カラースキームの基本と、防災情報「キキクル」に見られる独自の色彩設計の工夫を取り上げ、その示唆を考えます。\n連続的カラースキームとは？ データ可視化におけるカラースキームには、「連続的（sequential）」「発散的（diverging）」「定性的（categorical）」の3種類があります。 このうち 連続的カラースキーム（sequential color scheme） は、数値が大きい・小さいという一方向の大小関係を持つデータを表現するために使われます。\n例： 人口密度 降水量 売上高 温度 人間の目は「明るさ」の違いを見分ける感度が高いため、データの大小や重要度を明度の差に対応させて表現するのが、データの性質にあったカラースキーム（複数の色のセット）を考える際の入り口となる基本です。そしてその実現のため 単色の濃淡（1つの色相×明度） や 2色間のグラデーション（２つの色相×明度） といった方法が典型例として広く使われています。\nキキクルの事例：3色以上を組み合わせた連続表現 しかし、気象庁の「キキクル」で用いられている手法は、この典型から外れています。キキクルとは、気象庁が提供する 大雨・洪水・土砂災害などの危険度を色分けして地図上に表示するサービスです。地域ごとに危険度を段階的に示し、住民が避難のタイミングを判断する手助けを目的としています。\nキキクルではその危険度について、黄 → 橙 → 赤 → 紫 → 黒 という複数の色相を組み合わせながら、同時に明度を下げていく配色をしており、連続的カラースキームとしては珍しい設計です。通常の濃淡や2色グラデーションではなく、「段階性の強調」と「最終段階＝黒の終端感」を兼ね備えており、防災情報という利用シーンに合わせて工夫された特異な例といえます。\nそして注目すべきは「黒」を最終段階に用いている点です。 通常の連続スキームではあまり使われませんが「命に関わる危険が切迫している」という強いメッセージを込めて配色の終端としています。 これにより、利用者は「ここが最終段階だ」と明確に理解できます。\n一般的な連続スキームとの違い 一般的な連続スキーム 青の濃淡や緑→黄など、滑らかな変化を重視 中間値もスムーズに把握しやすい キキクルの連続スキーム 色相を切り替えて段階を強調 リスク段階の境界が明確で、直感的に理解しやすい 特に「避難行動を促す」という防災・リスクコミュニケーションの文脈に合致 学びのポイント 連続スキームは 単色濃淡だけに限らない 色相・明度・彩度を組み合わせることで、意味や文脈に合った表現が可能 特殊な色（黒など）も、目的が明確なら有効に使える つまり、配色は「美的センス」だけではなく、データの意味と利用シーンに根ざした設計であることを示す好例と言えるでしょう。\n参考・出典 キキクル（危険度分布）「黒」の新設、「うす紫」と「濃い紫」の統合 ","date":"2025-09-20T00:00:00Z","image":"http://localhost:1313/bosai-risk-color/images/sequential_kikikuru_compare_5_jp_hu_54dc7f3de1989465.png","permalink":"http://localhost:1313/bosai-risk-color/","title":"連続的カラースキームとキキクルの事例"},{"content":"私たちの判断や意思決定は、合理的なようでいて、しばしば、予測可能な誤りを繰り返します。これが 認知バイアス です。たとえば「宝くじの当選確率」を過大評価したり、「自分の信念を裏づける情報」だけを集めてしまうといった現象がそうです。\n認知バイアスは膨大な種類があり、Wikipedia には170を超える項目が並んでいます。これをそのまま眺めてもとても覚えきれません。そこで Buster Benson が試みたのが、「人間の脳が直面する問題」に沿って再整理することでした。\nその成果が、ここで紹介する Cognitive Bias Codex（認知バイアス・コーデックス） です。\n4つの大きな問題 Codex の特徴は、数多くのバイアスを 4つの基本問題 に分類している点です。\n情報が多すぎる（Too much information） 世界は情報過多で溢れており、脳は重要そうなものを強調する。結果として「目立つもの」「最近の出来事」に過剰に注目してしまう。 意味が足りない（Not enough meaning） 私たちは断片的な情報をストーリーで埋め合わせ、パターンや因果関係を“見つけた気”になる。 迅速に行動する必要性（Need to act fast） 判断や行動を遅らせると不利になるため、単純化や思い込みを使って即断してしまう。 何を記憶すべきか（What should we remember?） 膨大な体験すべてを覚えることはできないため、「印象に残るもの」だけを記憶する。その過程で記憶は歪み、都合よく再構成される。 Codex のインパクト この放射状のマップは、認知バイアスの全体像を一望できる視覚的な地図です。\n網羅性：100を超えるバイアスが一目で見渡せる。 シンプルな構造：中心の脳から4方向に枝分かれし、人間の制約がどこに集中しているか直感的に分かる。 共有しやすさ：カラフルでわかりやすく、SNSやスライドで広まりやすい。 結果として、この図は「認知バイアスといえばこれ」と言われるほど有名になりました。\nまとめ Cognitive Bias Codex は Wikipedia の膨大なリストをもとに、Buster Benson が経験則で再分類した成果物。 分類軸は「人間の脳が直面する4つの問題」。 わかりやすく、視覚的に美しいマップに仕上げたことで、SNSや書籍を通じて世界的に普及。 人間がどんな思考のクセを持ちやすいかを直感的に理解するための「入門の図」。 参考・出典 Cognitive bias cheat sheet ","date":"2025-09-19T00:00:00Z","image":"http://localhost:1313/cognitive-biases-blog/images/bias-blog_hu_7985f79028082845.png","permalink":"http://localhost:1313/cognitive-biases-blog/","title":"「Cognitive Bias Codex」で眺める人間の思考のクセ"},{"content":"私たちの判断や意思決定は、しばしば「合理的なはず」なのに予測可能な誤りを繰り返します。これが 認知バイアス です。\nたとえば「宝くじが当たる確率」を過大評価したり、「都合のいい情報」だけを集めてしまうのもその一例です。\nこうしたバイアスは数が多く、Wikipedia には170を超える一覧が存在します。しかし「数が多すぎて覚えきれない」「どれとどれが似ているのか分からない」といった課題もあります。そこで、人々はこの膨大なリストをどう整理すればよいのか、さまざまな試みを行ってきました。代表的なのが次の二つの整理法です。\n2つの整理法 項目 ブログ記事「Cognitive Bias Cheat Sheet」（Buster Benson, 2016） 論文「A Task-Based Taxonomy of Cognitive Biases for Information Visualization」（Dimara et al., 2020） データソース Wikipedia「List of Cognitive Biases」 同じく Wikipedia リスト（176件から154件を厳選） 手法 個人の経験則・直感（ヒューリスティック）で整理 研究者数名が文献を精査し、実験研究を基準にカードソート法で分類 分類の軸 脳が直面する4つの問題（情報過多／意味不足／即時行動／記憶制約） バイアスが観測された「実験タスク」（推定／意思決定／仮説評価／因果帰属／記憶／意見報告／その他） 成果物 わかりやすい解説と、後に有名になった「Cognitive Bias Codex」の放射状マップ図 可視化研究者が活用できる体系的な分類表と研究課題の提示 両者は同じ Wikipedia のリストを出発点にしていますが、目指す方向がまったく異なります。\nBenson のブログ記事での整理は「わかりやすさ」を重視しており、一般の人でもすぐに使えるフレームワークになりました。\n一方、Dimara らの研究は「科学的な再現性」と「可視化研究への応用」を目的としており、専門性が高く、一般には広まりにくかったのです。\nどちらが有名になったか？ 一般に有名なのは前者の「Codex」 です。カラフルで壮大な放射状マップがSNSやスライドで拡散され、いまや「認知バイアスといえばこの図」と言われるほどです。\n一方で、数年かけて精査した Dimara らの論文や分類表は、研究者の間でしか知られていません。\nこれは認知バイアスそのものではないか なぜ「経験則ベースの図」が広まり「研究ベースの図」が広まらなかったのでしょうか？\nその理由自体が認知バイアスで説明できます。\n処理流暢性バイアス（fluency bias）\n分かりやすく綺麗な図ほど信頼できると感じやすい。 ハロー効果（halo effect）\n見栄えの良さが内容の信頼性まで引き上げてしまう。 バンドワゴン効果（bandwagon effect）\n多くの人が使っていると「正しい」と思ってしまう。 努力軽視（effort neglect）\n論文の精緻な労力は外から見えにくいため、評価に結びつかない。 つまり、「Cognitive Bias Codex が有名で、論文の図が無名」という現象そのものが、人間がバイアスに支配される例になっているのです。\nまとめ 共通点：どちらも Wikipedia のリストを出発点にしている。 違い： Codex → 経験則・直感での整理、一般に広まる Dimara 論文 → 研究的・実証的な整理、専門的にとどまる 教訓：人は「わかりやすくて見栄えのする情報」を好み、手間暇をかけた科学的整理を見過ごしがち。 皮肉：この状況自体が「認知バイアス」の一例である。 参考・出典 A Task-Based Taxonomy of Cognitive Biases for Information Visualization Cognitive bias cheat sheet ","date":"2025-09-19T00:00:00Z","image":"http://localhost:1313/cognitive-biases-compare/images/bias-comparison-final_hu_84d51545b527239c.png","permalink":"http://localhost:1313/cognitive-biases-compare/","title":"認知バイアスの分類 - なぜ「Cognitive Bias Codex」は有名で、研究論文は知られていないのか？"},{"content":"認知バイアスは、人間が合理的に考えているつもりでも陥ってしまう思考のクセです。\nWikipedia には170を超えるバイアスがリストアップされていますが、そのままでは数が多すぎて把握しきれず、どの状況で役立つのかも分かりづらいという問題があります。\nそこで Dimara らの研究チーム（2020）は、既存の心理学研究を整理し直し、「どんな実験タスクでバイアスが観測されたか」という観点から体系化を試みました。これが A Task-Based Taxonomy of Cognitive Biases です。\n分類の方法 研究者たちは、まず Wikipedia の一覧を出発点に176件のバイアスを収集しました。そこから信頼できる実験研究を精査し、重複や裏付けの薄いものを整理して 最終的に154件 を採用。\n次に、それぞれのバイアスが検出された心理学実験を調べ、そこで参加者が行っていた「タスク」に注目しました。これを手がかりに、似た性質のバイアスをまとめていったのです。\n7つの主要カテゴリ こうして導き出されたのが、次の7つのタスクカテゴリです。\nEstimation（推定）\n数値や確率を見積もるときに生じるバイアス（例：アンカリング、計画の誤謬）。\nDecision（意思決定）\n複数の選択肢から選ぶ際に現れるバイアス（例：損失回避、フレーミング効果）。\nHypothesis Assessment（仮説評価）\n証拠を検討するときに起こるバイアス（例：確証バイアス、錯誤相関）。\nCausal Attribution（因果帰属）\n原因や責任を判断するときのバイアス（例：自己奉仕バイアス、アクター・オブザーバー効果）。\nRecall（記憶）\n記憶の保持や想起にかかわるバイアス（例：ピーク・エンドの法則、偽記憶）。\nOpinion Reporting（意見報告）\n自分の意見を述べたり、他人に影響される場面でのバイアス（例：バンドワゴン効果、第三者効果）。\nOther（その他）\n上記に収まらないユニークなバイアス（例：単位バイアス、ダチョウ効果）。\nこの研究の意義 Dimara らの分類の特徴は 「なぜバイアスが起こるか」ではなく「いつ起こるか」に注目したこと です。\nつまり「推定をするときに出やすいバイアスはこれ」「記憶の場面で出やすいバイアスはこれ」と整理されているため、研究者や実務者が自分の関心領域に関連するバイアスをすぐに見つけられるようになっています。\nまた、情報可視化の研究にとっては、各カテゴリと可視化タスクを対応づけることで、「どのような可視化がどのバイアスを軽減できるか」「逆に助長してしまうのか」といった新しい問いを立てやすくなると論じています。\nまとめ Dimara らは Wikipedia のリストをもとに、154件の認知バイアスを整理し直した。 分類の基準は「観測された実験タスク」であり、7つのカテゴリにまとめられている。 このタスクベースの枠組みは、心理学と情報可視化研究の橋渡しを目的としている。 参考・出典 A Task-Based Taxonomy of Cognitive Biases for Information Visualization ","date":"2025-09-19T00:00:00Z","image":"http://localhost:1313/cognitive-biases-paper/images/bias-paper_hu_6157a3eb60f7ccce.png","permalink":"http://localhost:1313/cognitive-biases-paper/","title":"認知バイアスを「タスク」で整理する──Dimara らの新しい分類法"},{"content":"1879年、フランス公共事業省は全国の交通路の整備状況をまとめたユニークな地図を発行しました。 地形を描くベース・マップの上に、各県ごとの「交通インフラの内訳」を扇形グラフにして地図上に配置した統計チャート地図です。\n扇形で描かれた交通路の内訳 地図上には県ごとに半円のダイアグラムが置かれています。上半分は7色に分かれ、交通路の種類ごとの延長距離を示します。\n紫：国道 橙：県道 黄：水路（運河や航行可能な川） 青：鉄道 ピンク（濃淡3段階）：地方道（大規模・重要・普通の共同道路） 色の面積がその種類の延長距離に比例しているため、一目で「どの県が道路中心なのか、鉄道が発展しているのか、水運が依然として重要なのか」が読み取れます。\n下半円は「相対的な便利さ」 半円の下側には2つの扇形が加えられています。\n左の青：領土面積に対する交通路の比率（＝土地に対してどれだけ道路が張り巡らされているか） 右の黄：人口に対する交通路の比率（＝住民一人あたりどれくらい交通インフラがあるか） これにより、単なる総延長だけでなく、「住民や土地にとっての便利さ」まで表現されているのです。\n凡例の並び順に見る当時のインフラ観 興味深いのは、凡例の並び順。現代の感覚では「道路を一括りにして鉄道や水路と対比する」ほうが自然ですが、この地図では国道と県道のあとに水路・鉄道が置かれ、最後に地方道がまとめられています。\nこの並び方には当時の価値観が反映されていると考えられます。\n国道や県道は国家直轄の最重要インフラとして先頭に。 水路は伝統的な交通手段として続き、鉄道は新しいインフラとしてその後に。 地方道は細分化され、最後にまとめて扱われています。 つまり、この図からは 「鉄道はまだ新参者であり、道路が社会の基盤であった」 という19世紀末のフランスのインフラ観が浮かび上がってきます。\nまとめ この地図は、\n上半円で「交通路の種類別内訳」 下半円で「人口・領土に対する相対的な比率」 を同時に示すことで、インフラの姿を多面的に伝えています。 単なる統計表ではなく、色と形で「交通路の物語」を描いたこの図は、現代のインフォグラフィックスにも通じる工夫が随所に見られます。\n1879年の人々がこの地図を見て、自分の県の鉄道や道路の充実ぶりをどのように感じたのか、想像するだけで面白くなってきます。\n参考・出典 Carte Figurative du Developpment des Voies de Communication Par Department au 31 Decembre 1878. - David Rumsey Historical Map Collection ","date":"2025-09-15T00:00:00Z","image":"http://localhost:1313/chart-map-transportation-infrastructure/images/12511007_closeup_hu_28adee4e1700bf83.png","permalink":"http://localhost:1313/chart-map-transportation-infrastructure/","title":"交通インフラの内訳を可視化した統計チャート地図"},{"content":"19世紀のヨーロッパでは、鉄道の敷設がめまぐるしく進みました。その姿を人々にわかりやすく伝えるため、フランス公共事業省が1880年に発行したのが、この「鉄道発展図」です。\n一見すると地図の上に青い円が散りばめられただけのように見えますが、そこには当時のデータ可視化の工夫が詰まっています。\n青い円の意味 外側に並ぶ青い円は、各国における鉄道の総延長を示しています。 1830年から1878年までの6つの時点（1830, 1840, 1850, 1860, 1870, 1878）が等間隔に配置され、時代が進むごとに円が大きくなっていくのがわかります。\nポイントは「円の面積」が鉄道延長距離に比例していること。 データ量を正しく表すため、凡例には「半径を距離の平方根に比例させる」計算式が書き込まれています。つまり、見た目の大きさが実際の鉄道網の成長に対応するよう設計されているのです。\n中央の二色の扇形 中央の小さな円の中には、緑と黄色の半円が描かれています。\n緑：領土面積に対する鉄道の比率 黄色：人口に対する鉄道の比率 この扇形も、面積が比率に応じて変わるように描かれています。絶対量だけでなく「どれだけ便利に鉄道を使えるか」という相対的な指標まで一枚の図に盛り込んでいるのです。\nなぜこの地図が作られたのか？ 史実として明確な「動機」の記録は残っていません。しかし、当時の状況からいくつかの背景を推測することはできます。\n成果の可視化\u0026hellip;公共事業省が鉄道整備の進展を国民や議会に示し、「国家の進歩」をアピールする狙いがあった可能性があります。 国際比較の意識\u0026hellip;イギリス、ドイツ、アメリカなどとの比較を通じて、フランスの位置づけを明らかにし、国力を誇示しようとした側面も見て取れます。 可視化文化の浸透\u0026hellip;当時の技術官僚は、数値を地図や図表に落とし込み「説得力あるかたちで伝える」文化を持っていました。この地図もその延長線上にあると考えられます。 こうした点を踏まえると、この鉄道発展図は単なる統計資料というよりも、「国の物語」を可視化したインフォグラフィックスだったのではないでしょうか。\n19世紀のデータ可視化の知恵 現代の私たちがインフォグラフィックスやダッシュボードで当たり前に使う「面積で数量を表す」「相対指標と絶対量を同時に見せる」といった工夫は、実は150年前から試みられていました。\nこの鉄道発展図は、単なる地図ではなく「統計とデザインを融合させた可視化表現」の先駆けといえます。\nまとめ 青い円の大きさ＝鉄道延長距離（面積で比例） 配置された6つの円＝1830〜1878年の時系列 中央の緑と黄色＝領土・人口に対する相対的な発展度 背景には「国家の進歩を示す」という行政的・国際的な意図が込められていた可能性がある 鉄道の広がりを「見える形」にしたこの図は、今見ても十分に新鮮で、データをどう表現するかを考えるヒントになります。\n参考・出典 Carte Figurative du Developpement des Chemins de Fer Dans les Principaux Etats de 1830 a 1878. ","date":"2025-09-15T00:00:00Z","image":"http://localhost:1313/chart-map-railway/images/12511022_closeup_hu_c9a5d023c7f42c07.png","permalink":"http://localhost:1313/chart-map-railway/","title":"鉄道の発展を「円の面積」で描いた鉄道発展図"},{"content":"1888年にフランス公共事業省が発表した統計地図シリーズの中で、もっとも視覚的なインパクトを持つのがこの「Acceleration des Voyages en France depuis 200 ans（過去200年間にわたる旅の加速）」です。この地図は、私たちが今日当たり前に感じている「速さ」が、どのようにして獲得されたのかを示しています。\nどんな地図なのか 地図はパリを中心に、フランス各地を放射状に描き出しています。しかし、表しているのは物理的な距離ではなく、所要時間です。\n外側の淡いテクスチャのエリア … 17世紀中頃の旅行時間 内側に向かう濃いテクスチャのエリア … 1782年、1814年、1834年、1854年、1887年と時代を下るごとに短縮された旅行時間 この6つの「同心円状の輪郭」が重なり合い、まるで地図全体が次第に縮んでいくように見える仕組みになっています。\nバイヨンヌを例に 凡例では、パリからスペイン国境近くの都市バイヨンヌまでの所要時間が紹介されています。\n17世紀 … 358時間 1782年 … 200時間 1814年 … 116時間 1834年 … 64時間 1854年 … 27時間45分 1887年 … 11時間51分 つまり、わずか2世紀のあいだに、移動時間は30分の1に短縮されたのです。\n見方のポイント 輪郭の形は地理的に正確ではない\u0026hellip;加速の度合いが地域によって異なるため、地図の形はゆがんでいます。だからこそ、どの方向に交通インフラの進歩が進んだかが一目でわかる仕組みです。 縮んでいくフランス\u0026hellip;色の濃い時代ほど内側に収まり、結果として「フランス全体がセーヌ県の大きさまで縮んだ」かのように見えます。 旅行速度の劇的な進歩 この地図が伝えるのは、「20〜30倍の速さで旅する時代」を我々が生きているという事実です。移動のスピードは単なる快適さにとどまらず、行動範囲そのものを広げ、社会や経済のダイナミズムを変えました。\n凡例の工夫 都市は青い点で示され、地図の縮尺が許す場合には、パリからの所要時間が直接書き込まれています。また、これらの数字は凡例の右側にまとめられ、読者が一覧できるようになっています。\nまとめ この「時間の距離カルトグラム」は、フランスにおける移動の歴史を、数字ではなく体感的な距離感の変化として伝えてくれます。遠かったバイヨンヌやマルセイユが、数世代のうちに「ぐっと近く」なった様子を、地図を通して追体験できるのです。\n参考・出典 Acceleration des Voyages en France Depuis 200 ans. Baisse de Prix des Voyages en France Depuis 1798. - David Rumsey Historical Map Collection ","date":"2025-09-14T00:00:00Z","image":"http://localhost:1313/time-distance-map/images/time-distance-closeup_hu_f7adc4c268b6ffb.png","permalink":"http://localhost:1313/time-distance-map/","title":"時間の距離カルトグラム"},{"content":"19世紀フランスの人々にとって「旅」は、時間だけでなくお金の面でも大きな負担を伴うものでした。フランス公共事業省が1888年に発表した統計地図シリーズには、旅が「どれだけ早くなったか」を示す時間カルトグラムと並んで「どれだけ安くなったか」を示す興味深い地図が掲載されています。それが、この「Baisse de Prix des Voyages en France depuis 1798（1798年以降の旅費の低下）」です。\nどんな地図なのか パリを基点にフランス各地を描いています。そして対象は運賃（旅費）です。通常の地図は距離が描かれますが、ここではパリからの旅費を、パリからの距離に視覚的に変換しているのです。\n外側の薄いテクスチャのエリア（フランスの輪郭） … 1798年当時の旅費を表現。旅行コストが高かったため、都市は遠くに位置づけられています。 内側の濃いテクスチャのエリア … 1887年当時の旅費を表現。運賃の低下により、各都市がパリに「近づいた」ように描かれます。 つまり、都市が内側に寄っているほど「当時に比べて安く旅できるようになった」ことを意味します。\n読み解き方としては、パリから各都市へ直線で結んだ上で、1887年の旅費を距離に変換した箇所に都市名を記載します。同じ都市名が二か所にあるはずです。青い数字で旅費が記載されています。\n運賃の基準 同じ時代でも運賃は乗るクラスによって異なります。そこで比較の基準として、この地図では「もっとも多くの人が利用する等級」が採用されました。\n乗合馬車（diligence）：インペリアル（屋根席） 鉄道：三等車 これにより、庶民がどの程度安く旅行できるようになったのかを、より実感的に示しています。\n鉄道・馬車の各クラス料金 地図の凡例の右側には、鉄道と馬車の各クラスの料金を比較する表が添えられています。\n鉄道は一等・二等・三等 馬車は郵便馬車やクーペ、内部座席、インペリアルやロトンド これらを並べて見ると、一世紀のあいだに旅費はおおよそ30〜40％ほど低下したことがわかります。\n時間との比較 興味深いのは、旅費の低下率は「所要時間の短縮」に比べると小さいという点です。時間のほうは劇的に短縮されましたが、費用のほうはそれほど大きく下がったわけではありません。それでもなお、人々が実感できるほどの「旅の安さ」が実現していたことは確かです。\nまとめ この「旅費の距離カルトグラム」は、19世紀フランスでの旅行がいかに時間的にも金銭的にもアクセスしやすくなっていったかを示す貴重な資料です。\nこの地図を見ると、フランス各地がパリに少しずつ「近づいていく」様子が、物理的な距離ではなく、財布の中身の感覚で伝わってきますね。\n参考・出典 Acceleration des Voyages en France Depuis 200 ans. Baisse de Prix des Voyages en France Depuis 1798. - David Rumsey Historical Map Collection ","date":"2025-09-14T00:00:00Z","image":"http://localhost:1313/time-distance-map-price/images/time-distance-price-closeup_hu_12aaa78f7d382a24.png","permalink":"http://localhost:1313/time-distance-map-price/","title":"旅費の距離カルトグラム"},{"content":"データをわかりやすく、そして印象的に表現する方法のひとつに「カルトグラム（Cartogram）」があります。これは地図上の領域（国や都道府県など）の面積や形を、人口や経済規模、投票数などの数値データに比例させて変形した地図です。普段見慣れている地図が大きく歪むことで、データの特徴が一目でわかるのが魅力です。ここではデータを面積に反映させる面積カルトグラムのうち、代表的な4種類のカルトグラムを紹介します。\nカルトグラム手法の比較一覧 手法 特徴 メリット デメリット 連続的カルトグラム 隣接関係を保ちながら、面積をデータに比例させて変形 地図らしさが残るため直感的 全体的に歪んで読みにくい場合がある 非連続的カルトグラム 地域ごとに独立させ、面積をデータに比例 歪みが少なく比較しやすい 隣接関係が失われる 擬似連続カルトグラム 丸や四角など幾何図形の大きさや色で表現 データ比較がしやすい 地形が失われる グリッド・カルトグラム グリッド単位で地域を置換 個数や色による表現が明確 位置関係が単純化されすぎる 連続的カルトグラム (Continuous Cartogram) 一票の格差でいびつな日本 2021年衆院選の比例代表得票率 主な政党の得票率 2021年衆院選の比例代表得票率 主な政党の得票率\nカルトグラムを利用して、米国におけるウォルマート、マクドナルド、スターバックスの分布を表示する Supercenters, Hamburgers, and Coffee: Using density-equalizing cartograms to display the distribution of Walmarts, McDonalds, and Starbucks in the US\n地球規模の生活環境がどのように変化しているかを考えるために必要な地図 The map we need if we want to think about how global living conditions are changing\n連続的カルトグラムは、国境や県境といった隣接関係を保ちながら、各地域をデータに応じて面積ごと変形する手法です。 たとえば人口を基準にすると、人口の多い地域は大きく、少ない地域は小さく変形されます。結果として全体の地図がぐにゃりと歪み、見慣れた地図とのギャップから「どこが大きく、どこが小さいのか」が直感的に理解できます。\n非連続的カルトグラム (Non-Continuous Cartogram) 選挙人地図（11/6/12）：選挙日 The Electoral College Map (11/6/12): Election Day\n非連続的カルトグラムは、隣接性を捨てて各地域を独立させた上で、面積をデータに比例させる手法です。 たとえばアメリカの州ごとの投票結果を示す場合、州の位置や境界は保ちながらも州同士の距離感は無視されるため、全体としてはモザイク状の地図になります。隣接関係の形状の変化に影響を受けずに、それぞれの地域のデータ量が強調されるのが特徴です。\n擬似連続カルトグラム (Pseudo-Continuous Cartogram) ニューヨーク・タイムズ「オリンピックメダル地図」、2012年。 A Map of Olympic Medals\nオバマ大統領による変更前に、保険契約を更新できる州 States Where Insured Could Renew Plans Before Change by Obama\n擬似連続カルトグラムは、地域を地形のまま表現するのではなく、丸や四角などの単純な幾何図形に置き換えた上で、それをデータに応じて大きさを変える方法です。 代表例は「ドーリング・カルトグラム（Dorling cartogram）」と呼ばれる手法で、国や地域を円の大きさで表し、位置関係をできるだけ近づけて配置します。地形の正確さを犠牲にする代わりに、データの比較がしやすくなるのが利点です。\nグリッド・カルトグラム (Gridded Cartogram) すべては538人の選挙人票次第だ It’s all about the 538 Electoral College votes\nグリッド・カルトグラムは地形を、データに応じた個数のグリッド（四角形や六角形など）を並べて表現する方法です。個数以外に色でも別変数を表現することができます。位置関係をある程度保ちつつ、数の比較が直感的に理解できるのが特徴です。\nまとめ カルトグラムは「地図」という馴染みのあるフォーマットにデータを組み込むことで、地域差や規模感を強く訴えることができる表現手法です。適切なタイプを選ぶことで、データが持つストーリーを効果的に伝えることができます。\n","date":"2025-09-10T00:00:00Z","image":"http://localhost:1313/cartogram/images/cartogram_hu_f311eb1434cb8e3e.png","permalink":"http://localhost:1313/cartogram/","title":"カルトグラム：見慣れた地図がデータで歪む面白さ"},{"content":"いま私たちが当然のように使う「統計」。その裏側には、statistics を日本語にするために “新しい漢字” まで考案した人たちがいた——という静かな驚きがあります。当時の知識人が「ことばを日本語として根づかせる」ために、そこまで試行錯誤していた事実に、思わず息をのむのです。\n1889年、論争は始まる 発端は明治22（1889）年。森鷗外（森林太郎）が、エステルレン著・呉秀三訳『医学統計論』の「題言」（序文）で統計観を示したことをきっかけに、スタチスチック社の今井武夫と論争が起こります。やりとりは約10か月に及び、複数の雑誌（『東京医事新誌』『スタチスチック雑誌』など）を舞台に続きました。 ￼ ￼ ￼\nここで、実際のやりとりをまとめた年表ミニ図をご覧ください。森鷗外（森林太郎）と今井武夫を中心に、複数誌で激しい応酬が続いたことが分かります。\n年月（明治） 著者 論文・著作名 掲載誌／号数 備考 22年3月 森林太郎 統計ト一般ト 東京医事新誌 373号 「鴎外全集」第22巻 22年5月 今井武夫 統計ト一般ト スタチスチック雑誌 7号 「鴎外全集」33巻 22年6月 森林太郎 統計ト一般トノ分流 東京医事新誌 584号 「鴎外全集」第22巻 22年7月 今井武夫 再ビ統計ト一般ト スタチスチック雑誌 9号 22年8月 森林太郎 統計ト宗論ヲ論ス 東京医事新誌 593号 「鴎外全集」第28巻 22年8月 森林太郎 統計学総論答今井武夫君 東京医事新誌 593号 同上 22年9月 今井武夫 三タビ統計ト一般ト スタチスチック雑誌 19号 22年9月 森林太郎 統計ト一般トヲ論ス 東京医事新誌 600号 「鴎外全集」第24巻 22年10月 森林太郎 再ビ統計学ト宗論ヲ論ス 東京医事新誌 606号 「鴎外全集」第28巻 22年11月 今井武夫 四タビ統計ト一般ト スタチスチック雑誌 29号 22年12月 今井武夫 四タビ統計ト一般ト（未完） スタチスチック雑誌 44号 統計博物館所蔵 争点は3つ 当時の資料を整理すると、争点は次の三本柱でした。\n争点 森鷗外（森林太郎） 今井武夫（杉亨二グループ） 「スタチスチック」の訳語は「統計」が適切である スタチスチックは「統べ計る」という訳語で意味は通じる 中国語の「統計」には合計の意味の外はない 統計学は科学であるのか、方法論であるのか スタチスチックは科学でなく方法である スタチスチックは、他の科学を補助する方法のみではなく、人間社会の現象を研究する科学である 統計は因果関係を探求すべき方法か スタチスチックは原因を探り法則を知り得るものではない 人間社会や国家の諸現象を、いろいろな要因との関係で探討すれば、原因を探り法則を定めることができる このように訳語問題は、いつしか科学観・方法論の論争へとせり上がっていきます。のちに日本の統計界で長く続く「社会統計」派と「数理統計」派の視界の差にもつながる論点でした。 ￼\n「統計」が定着していく 結論としては 「統計」 という訳語が次第に一般化していきます。実際、統計界の重鎮・杉亨二自身が「統計」という語を用いていた事実が、訳語の妥当性を支える根拠として挙げられています（森側の反論点）。 ￼\nそして“新漢字”は残らなかった 一方で、statistics を表すための新造漢字まで試作された時期がありました。読みや意味が直感的に通らず、運用・普及という言語の現実を前に採用は見送られていきます。けれど、その存在が示しているのは、外来概念を日本語の器にきちんと収めたいという切実な意思です。カタカナ表記で済ませず、適訳を磨き、場合によっては文字そのものを作るという発想。明治のことばの現場は、驚くほどクリエイティブでした。\nいまの目から見た教訓 この小さな論争史には、二つの教訓があります。\n言葉は単なるラベルではない。 訳語の選び方が、その学問の“輪郭”や“広がり”を規定する。 方法か科学か。 統計をどう位置づけるかは、教育や実務の指針に直結する。 だからこそ 「統計」 という二文字が今日まで生き残った事実には、言語選択と学問観のせめぎ合いが凝縮しているのです。 ⸻\n参考・出典 統計の偉人たち｜統計150年特設サイト｜統計局ホームページ 統計エピソード（1）「統計」という言葉の起源｜宇宙統計ステーションNARUHODO 統計Today No.136「森鷗外と統計」｜統計数理研究所 J-STAGE｜森鷗外の統計論の源泉（学術論文） CiNii｜森鴎外の統計学観 書評「統計学の日本史」｜統計数理研究所 ","date":"2025-09-07T00:00:00Z","image":"http://localhost:1313/translate-statistics/images/translate-statistics_hu_1806673c80cff4eb.png","permalink":"http://localhost:1313/translate-statistics/","title":"「統計」が「統計」になるまで—訳字論争と'新漢字'の時代感"},{"content":"データ可視化の世界では、「二重軸（Dual Y-Axis）チャート」はしばしば批判の対象になります。 「誤解を招きやすい」「根本的に欠陥がある」と言われ、教育現場でも「使わないほうがいい」と教えられることが多いのです。\n実際、データ可視化の大家 Stephen Few や ggplot2 の作者 Hadley Wickham など、名だたる専門家が二重軸を否定しています。 理由はシンプルで、スケールが異なる2つの軸を並べると、見る人が直感的に誤解してしまうからです。\nそれでも消えない「二重軸チャート」 ところが、現実のデータ分析の現場では、二重軸チャートは今でも頻繁に使われています。 とくに金融分野では「なくてはならない道具」として定着しています。\nたとえば、為替と原油価格の関係を分析するケースを考えてみましょう。 カナダドルは原油価格に強く影響を受ける通貨として知られています。 アナリストやトレーダーは、両者の動きを見比べながら「どちらが先に動いたか」「どちらがリードしているのか」を知る必要があります。\nなぜ単一軸ではダメなのか？ 両者を1つの軸にまとめようとすると、問題が生じます。\n（図1: 単一軸に重ねたチャート。原油価格の上下に比べてカナダドルはほぼ平らに見えてしまう）\n正規化しても状況は改善しません。\n（図2: 値を100基準に正規化したチャート。それでも原油の変化が大きすぎて、カナダドルの動きがつぶれる）\n他の代替手法もあるが… 縦に並べれば形の比較はしやすくなりますが、先行・遅行は追いにくい。\n（図3: 形は比べやすいが、タイミングの比較は難しい）\nホライゾンチャートはインパクトはあるけれど、やはり「どちらが先か」は曖昧。\n（図4: 変化の大きさは見えるが、先行の読み取りは難しい）\n散布図にすると相関は分かりますが、日々のリード・ラグは把握しにくい。\n（図5: 相関は強いが、「先に動いたか」は掴みにくい）\n二重軸チャートの強み そこで役立つのが二重軸チャートです。\n（図6: 2系列の動きと、どちらが先に転じたかが直感的に追える）\n縦軸を2本にして並べることで、次のような分析が可能になります。\n2つの系列が同時に動いているかどうかを直感的に把握できる どちらが先に上昇・下降したのか、リード・ラグ関係を見分けられる 短期的な変化も「目で追える」 金融の世界では、こうした“タイミング”の把握が利益やリスクに直結します。 だからこそ、専門家の間では二重軸チャートが日常的に使われているのです。\n「全面禁止」ではなく「適材適所」 もちろん、二重軸チャートは誤解を招く危険性を持っています。 教育の現場や一般向けのレポートで安易に使うと、読み手が誤った解釈をしてしまうリスクは確かにあります。\nですが「常に悪」というわけではありません。 むしろ、特定の領域では最も有効な可視化手段のひとつになり得ます。\n大事なのは、使う目的と文脈です。 「見せたい相手は誰なのか」「何を明らかにしたいのか」を踏まえたうえで、 二重軸チャートというツールをどう使うかを考えるべきでしょう。\nまとめ 二重軸チャートは「誤解を生みやすい」という批判がある しかし金融分野などでは不可欠な分析手段として定着している 問題は「使うか使わないか」ではなく、「いつ、誰に、どう使うか」 二重軸チャートをただの「悪者」として排除するのではなく、その有用性とリスクを理解した上で「適材適所」で活用していく。\nそれが、これからのデータ可視化に求められる姿勢だと思います。\n参照論文 Why Two Y-Axes (Y2Y): A Case Study for Visual Correlation with Dual Axes ","date":"2025-08-28T00:00:00Z","image":"http://localhost:1313/two-axis/images/img-10_hu_5ddb0889d879e1b8.jpeg","permalink":"http://localhost:1313/two-axis/","title":"なぜ「二重軸チャート」は悪者にされがちなのか？ それでも必要とされる場面とは"},{"content":"Excelでピボットテーブル化した（もしくはいわゆる横持ちと呼ばれる状態）の表を、ピボットテーブルする前の状態（もしくはいわゆる縦持ちと呼ばれる状態）に戻す作業は、これまでやや複雑でしたが、ExcelにPowerQueryエディタが搭載されてから、手順がかなりシンプルになりました。\n公式ページ掲載の図。左が横持ち、右が縦持ち状態。\nここでは、作業手順を、公式ページを噛み砕いて紹介します。\nExcelを起動し、空のブックを作成する。 「データ」タブの「データの取得」から「PowerQueryエディタの起動」を選択する。別ウインドウでPowerQueryエディタが起動します。以後はPowerQueryエディタでの作業です。 「ファイル」タブ「新しいクエリ」にある「新しいソース」から横持ちCSVファイルを開く。 変換したい列のみを作業対象として範囲選択します。 「変換」タブを開き「任意の列」欄から「列のピボット解除」を選択し「選択した列のみをピボット解除」を指定します。これでピボット解除の処理が行われます。 「ホーム」タブの「閉じて読み込む」を選択します。PowerQueryエディタが閉じ、当初の空のブックに、作業した表データが格納されます。 ファイルとして保存します。 ","date":"2023-11-19T00:00:00Z","image":"http://localhost:1313/excel-reverse-pivot/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/excel-reverse-pivot/","title":"Excelでのピボットテーブルの解除"},{"content":"Excelでピボットテーブル化した（もしくはいわゆる横持ちと呼ばれる状態）の表を、ピボットテーブルする前の状態（もしくはいわゆる縦持ちと呼ばれる状態）に戻す作業は、これまでやや複雑でした。オープンソースのクレンジングツールであるOpenRefineを用いると、かなりシンプルな手順で実行することが可能です。\n「業種別の給与階級別構成割合」の表データを参考に手順を紹介します。\n「行列転置」→「縦持ち化」という機能を呼び出します。どの列からでも大丈夫です。\n修正する列の範囲を「この列から」「この列まで」指定します。2カラム化を選択します。キーカラム名には属性の名称、値カラム名には値の名称を付けます。横持ちの状態ではいずれの列の名称もデータファイル内に明示されていませんので、適切な名称を付けます。\n「変換対象ではないカラムは直上の値で満たす」にもチェックを入れておきましょう。\nこのように「逆ピボットテーブル化」=「縦持ち化」が行えました。\n","date":"2023-11-19T00:00:00Z","image":"http://localhost:1313/openrefine-reverse-pivot/images/image_3hours_refine_hu_b443b315df3556d2.png","permalink":"http://localhost:1313/openrefine-reverse-pivot/","title":"OpenRefineでのピボットテーブルの解除"},{"content":"企業、NPO、政府機関などが、デザイン・ガイドラインにデータ可視化を取り入れる動きがあります。事例を集めました。\n※随時更新します。最新更新日 2023-09-14。\nデータ可視化スタイルガイド（時系列・分野別） データ可視化スタイルガイド（内容一覧） ","date":"2023-09-14T00:00:00Z","permalink":"http://localhost:1313/design-guideline/","title":"デザイン・ガイドラインにおけるデータ可視化"},{"content":"mapbox-gl-jsとは mapbox-gl-jsとは、WebGLを用いてベクター形式の地図タイルをレンダリングし、インタラクティブに操作することを可能にするJavaScriptライブラリです。\nv1.0台の頃は、このライブラリを使用するけども、サーバサイド側でMapboxのサービス（＝Mapbox提供の地図タイルサービス）を利用しない場合、料金はかかりませんでした。v2.0以降は、このライブラリを使用するだけでも、ライブラリの呼び出し回数に基づいた利用料を払う必要があるよう、規約が変更されました。\nhttps://github.com/mapbox/mapbox-gl-js/issues/10162\nhttps://geo-news.jp/archives/2270\nv2.0による新機能 v2.0になり、機能面では以下のような刷新が図られ、非常に充実したものになっています。詳しくは公式サイトのブログをご覧ください。\nすべてのマップが3Dに CAMERA APIの整備 SKY API https://www.mapbox.com/blog/mapbox-gl-js-v2-3d-maps-camera-api-sky-api-launch\nコミュニティで開発が続くオープン・ソース版 オープン・ソース版だったv1.0を継続してオープン・ソースのまま開発を続けようという動きがエンジニア・コミュニティで起こり、maplibre-gl-jsという名称で公開されています。\nhttps://github.com/maplibre/maplibre-gl-js\n","date":"2021-06-10T00:00:00Z","image":"http://localhost:1313/mapbox-gl-js-v2/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/mapbox-gl-js-v2/","title":"mapbox-gl-jsがv2.0へヴァージョンアップと共に有料化へ"},{"content":"※本記事は朝日新聞社ジャーナリスト学校による「Journalism(ジャーナリズム) 2021年5月号」に掲載された著者自身による記事の転載です。 Journalismは残念ながら現在休刊中ですが、Amazonなどでバックナンバーを入手することができますので、機会があればぜひお手にとってください。\n読者と視聴者の利益のために直感的なビジュアルを目指そう 前回の「データジャーナリズム①定義と歴史を概観する」に続き、今回は具体的な事例と手法などを紹介する。また、そのプロセス（制作過程）とプレゼンテーション（見せ方）も考察したい。まずは、昨年のシグマ・アワードでの入賞作品をはじめとする事例を紹介する。\n具体的な事例の紹介 大気汚染の可視化 See How the Worldʼs Most Polluted Air Compares With Your Cityʼs - The New York Times https://www.nytimes.com/interactive/2019/12/02/climate/air-pollution-compare-ar-ul.html 各都市における大気汚染の度合いを、ＰＭ２・５に見立てたドットや世界地図の上空を行き来する空気の流れ、都市ごとの棒グラフなどで可視化している （下）。棒グラフではインドのデリーがチャートの掲載範囲を大きく超える形で描かれており、その汚染のひどさを強調している。デリーや北京と自分が住む都市との比較ができるようにもなっている。提供されている公式アプリ内のＡＲ（拡張現実）ヴァージョンの記事では、スマートフォンを通じて眺める周囲の景色にＰＭ２・５を表すドットが漂い、その都市における数値の大きさを実風景にオーバーレイする形で確認することができる。\nスマホの健康負荷の喚起 Why your smartphone is causing you ʻtextneckʼ syndrome https://multimedia.scmp.com/lifestyle/article/2183329/text-neck/ スマートフォンを利用する際に首を曲げている角度や時間によっては、首に20～30㎏前後の負荷を与えている。これが健康に悪影響を与える危険性を訴えるコンテンツ。写真や動画上に直接、「アノテーション」と呼ばれる解説を付け足して説明している （左） 。イラスト、写真、チャートなど様々な表現を同時に使用しながら、読者・視聴者の食わず嫌いを避け、わかりやすく伝達されるようページ全体に工夫がなされている。\nプライバシーポリシーの可視化 Polisis https://pribot.org/polisis https://pribot.org/polisis/?_id=5b03d2276ff131496ccf099c\u0026company_url=https%3A%2F%2Fwww.facebook.com\u0026category=first-party-collection-use 様々なサービスを利用する際、プライバシーポリシー（個人情報に関する指針）に同意が求められるが、長文で読みづらく、まともに読解しようとすれば大変な苦労をする。しかしこの中にエンドユーザーにとって一方的に不利益な条文があるかもしれないし、ポリシーの改定時にそういった内容がひっそり追加される可能性もある。Polisisというツールを利用すると、プライバシーポリシーにおいて「どんなデータ」を「どういった目的で取得する」のか、サードパーティ（利用サービスから第三者の関係にあるサービス）へデータの共有がなされているかどうか、などが明確となる。たとえばFacebookでは、２０２０年12月16日時点でこのような状態になっていた （下） 。マウスカーソルを乗せると該当部分のポリシーが文章で参照できる。\n偽フォロワー数の解析 Bytes and Pieces - Influencer: Instagram-Starsschummeln mit falschen Zahlen-Radio SRFVirus – SRF https://www.srf.ch/radio-srf-virus/bytes-and-pieces-influencer-instagram-stars-schummeln-mit-falschen-zahlen Instagramのインフルエンサーのフォロワー数は大きな影響力を持つとされ、企業は広告効果を期待して宣伝を依頼する。そのフォロワーのうち、いわゆるボット（コンピューターで生成したアカウント）がどのくらい占めているのかを、機械学習の「決 けっ定 てい木 ぎ 」という手法で推定した。記事ではスイスのインフルエンサーのうち、ほぼ３分の１のフォロワーはフェイクだとして、直接本人に問うている動画 （上） も掲載されている。\nプロセスとしての手法 次にデータを解析するプロセスから代表的な手法を七つ紹介していく。\n①データのデジタル化 紙でのみ存在するデータをデジタル化するには膨大な手間がかかる。人力で行おうとすれば、時間だけでなく費用も膨大にかかる。たとえば政治資金収支報告書。紙をスキャンしたデータがインターネット上で公表されているが、これを人力でデジタルデータにしようとすると人件費だけで１年分でも２０００万円前後はかかった例もある。だが、ＡＩを活用することで安価に実現できる可能性がある。従来のＯＣＲに加えて、手書き文字の判別や、写真や動画に誰が写っているかを特定する手法を複数組み合わせて、デジタル化ができるのだ。 近年新たに公表されたケネディ大統領暗殺事件にまつわるＣＩＡ調査に関する資料、これらは３万４千ページ超に及ぶ紙文書や画像をスキャンしたものである。マイクロソフト社では自社ＡＩ製品のパフォーマンス宣伝を兼ねて、この資料をすべてデジタル化し、人物名でタグ付けを行い、ネット上で検索できる状態で公開している （注１）。 また、リークされたいわゆるパナマ文書の解析にあたったＩＣＩＪ（国際調査報道ジャーナリスト連合）では、自分たちでデジタル化のためのツールを開発し、無料かつオープンソースで公開している。残念ながら現時点では英語、スペイン語、フランス語、ドイツ語のみの対応となるが、ＰＤＦ、画像、テキスト、スプレッドシート、スライドなど様々な形式のファイルをデジタル化し、人、組織、場所ごとに自動的にタグづけを行う （注２）。こうして作成した加工済データは、民間企業のクラウドサービスを経由せずに、国を超えたプロジェクトメンバーであるジャーナリストたちで共有されている。一般向けデータベースとしてはパナマ文書に続いたパラダイス文書などを含めて「オフショア・リークス・データベース」として公開されている （注３）。\n②異なるデータの名寄せ 別々に存在している二つのデータを結合することで新しい事実を発見する手法。ここでは、教師なし機械学習と統計モデリングを使用して、固定資産税の回避実態を明らかにした例を挙げる。 米国テキサス州の住宅所有者は個人またはカップルにつき一つの住宅のみを免税対象にできるが、AirBnBとして自宅を貸し出している「短期賃貸」は免税対象とならない。だが、複数の不動産を所有し、AirBnBで貸し出す利用実態があるにもかかわらず税金免除を申請している個人またはカップルを、この手法により特定することができた。ある地域での「短期賃貸」申請データと電力会社の加入者データの名寄せを行い解析した （注４） 。通常はExcelでいうところのVLOOKUPと呼ばれる操作により実行するが、住所や氏名の表記が人によってマチマチである場合はうまくいかない。これを機械学習によって実行することで、人力に比べて大幅に省力化できた。この手法はほかへも応用が利きそうだ。\n③住所と緯度経度の特定 住所のみが含まれ、緯度経度が含まれていないデータが多くある。一般的な地図アプリでは、そのままでは描画することはできない。最低限、緯度経度が必要だ。住所から緯度経度を算出することをジオコーディングと言うが、Yahoo!JAPANのジオコーディングAPIは利用使途が限定されており使いづらい。以下のサービスが使いやすいだろう。\n東京大学空間情報科学研究センター「ＣＳＶアドレスマッチングサービス」 https://newspat.csis.u-tokyo.ac.jp/geocode-cgi/geocode.cgi?action=start・OpenCage Geocoder API https://opencagedata.com/ ④写真からの住所の特定 ある写真がどこで撮影されたのかを特定したい場合、その写真に写り込んだ景色とGoogleマップの衛星写真表示を組み合わせて、一点透視図法を用いて特定していく手法がある。写真がどこで撮影されたのかを、調査に生かすことが可能だ。\n⑤センサーの活用 スマートフォンや、安価なコンピューター端末であるラズベリーパイやArduino、ドローンといったデバイスを用いてセンサーデータを取得し、活用する手法だ。画像解析の手法が洗練されていった結果、カメラをセンサーとして利用することもできる。外部マイクをつけたスマホを森林に多数設置し、音を機械学習で聞き分けて不法伐採を監視するサービスがある。\n⑥データ・クレンジング 資料を機械が読み取れる状態にすることを指す。紙に出力された文章はＯＣＲで文字起こしするが、この延長でＰＤＦや紙でしか存在しない表データをデジタルデータ化することや、分析や可視化のために最低限必要となる「整然データ」（Tidy data）化することを指す。Excelで手動で行うことも可能だが、クレンジング手順自体の透明性や効率化のために、専用ツールを用いる方が望ましい。\n⑦仮説の発見 取得したデータそのものから仮説を発見するというアプローチがある。未知のデータに何が含まれているかわからない時点での仮説は、データを探索することによって、思い込みだったとして否定されることもある。主にマーケティングに用いられる「ＢＩツール」と呼ばれるジャンルのツールが、実は自由度が高くデータ内を探索するのにふさわしい。ただ、地図や文章（自然言語）に関してはこの限りではない。無償のものと有償のものとあるので、各ツール（Tableau／Power BI／QGIS／KH Coderな ど ）を検索してみていただきたい。\nプレゼンテーションとしての手法 以上、データを解析するプロセスから見た手法を紹介してきたが、続いてプレゼンテーション、つまり「見せ方」から代表的な手法を紹介していく。\n①インフォグラフィック 数年前であればラトビアのInfogr.amというサービスが日本の報道機関で利用されていたが、最近ではイギリスのFlourishがよく使用されている。近年人気のBar Chart Raceがアニメーションで手軽に作れるほか、チャートの種類の豊富さ、モバイル対応などから人気のツールである。\nFlourish | Data Visualization \u0026amp; Storytelling https://flourish.studio/ ②フォトグラメトリ 日本の放送局の報道においても、事件や事故現場の様子をＣＧで再現することはよくあるが、ＣＧとリアル映像はあくまで別々のものとして扱われる。ニューヨーク・タイムズが最近よく使うこの手法では、制作したＣＧを用いるまでは同じだが、ＣＧ空間内でカメラ位置を自由に移動させて、現場に居合わせた一般人や記者が撮影した写真や動画をＣＧ空間とシームレスにつなぎ合わせる。この手法によって現場の様子を、できるだけ精緻に再現しようとするのである。ニューヨーク・タイムズの記事 （注５）では、ガザ地区での抗議活動の際に、ボランティアが射殺された事件を取り上げており、現場に居合わせた人たちのスマホの画像や動画データを収集し、時系列に沿ってその場所へマッピング。三角測量を用いて、射撃場所を特定した。\n③ストーリーボード\n報道はノンフィクションであり、テーマや素材の取捨選択とその並び順、という構成によってクリエーティビティを発揮するといえる。構成されたテキストによるストーリーを補足するために画像やインタラクティブコンテンツ、動画が用いられる。ウェブページであればスクロールやページングによって、コンテンツが丸々、動画であれば動画再生によって時間軸を構成していく。 この検討、つまりテーマや素材の取捨選択とその並び順の検討のために、コンテンツを静止画として紙に出力して俯瞰的にプレゼンテーションの手段を考えることを、ストーリーボードと呼ぶ。ストーリーボード自体は中間成果物で外部に公表はしない。最近ではストーリーボードをクラウドで行う、たとえばFigmaというクラウドで共有と共同作業が可能なデザインツールを用いた検討などが考えられる （注６） 。場所を問わずに参加が可能なことと、検討内容自体をデジタルで保存しておくことが可能である。\n④解説動画 ニュース解説メディア「Ｖｏｘ」やニューヨーク・タイムズによる事例が有名だが、動画による解説をExplainerVideo （解説動画）と呼ぶ （注７） 。解説動画は、イラストを用いたものとそうでないものに大別でき、前者については制作のためのツールや原理原則が存在する。後者は内容に合わせてその都度制作するため、英語圏でも制作のための明解な教材はない。ツールのイノベーションはあまりなく、アドビ社のPremiereやAfterEffectsで制作する。\n⑤インタラクティブコンテンツ 最近はブラウザ上でインタラクティブに操作できるコンテンツが増加している。インタラクティブな操作が可能ということは動的に見せられて魅力的であるだけでなく、デリバリーの仕方が根本的に変わる。二通りに分けて見てみよう。制作者側（作る人）が意図した順番でのみコンテンツ消費が可能な伝達の仕方、つまり従来のテキストコンテンツに近い届け方である「表現と伝達型」と、読者・視聴者（見る人）に大幅に自由度を与え、自身でデータを探索する自由さを与える「課題の探索型」だ。さらにはこれら二つを組み合わせる手法もある。 読者・視聴者にとっての自由度の調整は制作者側にとって難しい。特集記事部門でピュリツァー賞を受けたニューヨーク・タイムズのSnow Fallというコンテンツ制作に携わったグレゴア・アイシュ氏は、Snow Fallのようなアクセス数を集めたコンテンツであっても、インタラクションの後ろに隠された情報はユーザーの85％に見られることなくスルーされた、という衝撃的な結果を講演で明らかにした。近年ではスクローリーテリングと呼ばれる手法を用いることも増えたが、これはブラウザのスクロールに合わせて、コンテンツの表示・非表示や再生・停止をコントロールし、読者・視聴者に操作の負荷を与えない手法である。\n作り手にとってのメリット これまで定義、経緯、事例、手法と述べてきた。これらの未知のデータジャーナリズムの手法を学んでまで、記者が挑戦する意味はどこにあるのだろうか。通常の記事コンテンツと比較した際の特徴を以下に挙げる。\nＰＶが多く、滞在時間も長い ワシントン・ポストが14の新設ポジションを設け、グラフィックとデザインチームの拡大を行っている。これは同社サイトのうち最も訪問された七つの記事のうち六つはグラフィックスを用いたものであり、最も訪問された記事「コロナウイルスシミュレーター」が２位の３倍以上だったことを受けての決定だ。 ブルームバーグでは、２０１８年にグラフィックスチームが獲得した平均月間トラフィックは、前年比で19・３％増加したという。「我々は、グラフィックが与えた影響力を成功の物差しにしたいと考えている」と担当エグゼクティブディレクターを務めるマーチン・キオハン氏は述べている。\n時間や費用の削減 大量に存在する資料の中から、調査すべき資料を絞り込む。たとえば全体が数百万あるファイルの中から調査すべき数千ファイルへ絞り込むことができるだけでも人件費、ひいては費用面での効率化が図れる。前述のように、アナログで存在する資料をデジタル化する手法はＡＩによって大きく前進した。\n新たな記録手法の開拓 ユネスコの地球科学プログラムでは自然災害における「ハザード」（現象）と「ディザスター」（災害）を区別する。前者は自然災害の現象そのもので、後者は社会や経済が受ける影響や結果を指す。報道において、前者は写真や映像として断片的に記録されるが、後者の記録については確固たる方法論が存在しなかった。そのためデータ可視化の理論や事例を援用しながら、世界各地に点在する報道機関の現場においてそのあり方自体のトライ・アンド・エラーが日々行われており、現在進行形で国を超えて相互に刺激しあいながら洗練が進んでいる渦中にあるといえる。これについては災害報道以外でも同様で、データジャーナリズムが扱う大部分のテーマは社会科学と呼べるものであり、社会科学のデータ可視化は、目の前に即物的に視認することのできないテーマにまつわるデータを可視化することの難しさがある。\n受け手にとってのメリット では、読者・視聴者にとってのメリットは何だろうか。筆者がデータ可視化実務家として、また、デザイナーとして経験してきた観点から２点挙げたい。\n認知負荷の軽減 行動経済学者として有名なダニエル・カーネマン氏が提唱する、人間の思考モードをシステム１と２に分ける考え方がある。システム１とは直感的かつ自動的に行われる速い判断を指し、システム２とは計算などしながらじっくりと行われる論理的な判断を指す。個々人の文章を読むことに対する慣れやコンテンツによるところも大きいと思うが、長文で書かれたテキストを読み込み、内容を理解するという思考活動は、システム２に近いのではないだろうか。そしてこの伝達の仕方は作り手が図らずも読者を選んでしまう。プレゼンテーションにコンピューターを用いて、インフォグラフィックスと呼ばれる静止画による図解、データ可視化と呼ばれる操作可能なチャートや地図、動画によるストーリーテリングはいずれもシステム１に近い活動である。近くないとしたら作品の完成度の問題であるといえよう。作り手としてはどちらか一方ではなく、まずはシステム１に対して視覚的に広く訴求をし、さらに詳しく知りたい読者・視聴者にシステム２に対応した、思いの丈を記した文章へいざなう、という方法は検討できないだろうか。 スマートフォンが主戦場である以上、報道以外のジャンルであっても可処分時間を奪い合う競合となり、まずは負荷が少ないシステム１へ訴求することは思いのほか大事で、読者・視聴者にとっても意味のあることと考える。\n自分ゴトに引き寄せられる インタラクティブなチャートや地図によるプレゼンテーションは、読者・視聴者の興味・関心を誘発する。そして実際に操作をしてみる中で自分に関係することが出てきたら、より興味・関心を持つようになるはずである。データから全体の傾向とその中での自分の立ち位置が見えたり、クイズ形式で自分の知識が試されたり、自分の政治的志向が何にあたるのか、言語化できていなかったものを言語化できたり……。そうやって世の中の出来事と自分の接点を見いだすことは、読者・視聴者にとって喜びとなる。一般の人々は天から下を、全体を見下ろすような視点で世の中を眺めておらず、それぞれが職業や人生経験に基づいた固有の立ち位置から眺めている。そんな読者・視聴者に社会的な出来事との接点を提供することができれば、ジャーナリストにとっても喜びにつながるのではないだろうか。\n誰でもデータジャーナリスト データジャーナリズムのヴァージョン３・０の初期、イギリスのガーディアン紙でデータブログをはじめたサイモン・ロジャース氏は、現在Googleに所属し、国際的なコミュニティを牽引する大きな存在の一人である。２０２０年に開催した無料のＭ ム ー ク ＯＯＣ教材の中で彼は「誰でもデータジャーナリスト」と述べている。オープンなデータがあちこちに存在し、無料ツールがいくつも登場している。あとはやるだけだ、と。 記者をはじめとする皆さんには、まずは自身がこれまで興味をもって継続的に取材してきたことをテーマに、コンピューターを用いるとどんな可能性が広がるのか、本稿も参考に思いを馳せていただきたい。一人で始めれば気楽だし、別な専門性を持つ複数人で取り組めば発見が多いはずだ。\nリンク JFK Files - Microsoft AI Lab https://www.microsoft.com/en-us/ai/ai-lab-jfk-files Datashare | Visualizing.JP https://visualizing.jp/datashare/ ICIJ Offshore Leaks Database https://offshoreleaks.icij.org/ Artificial Informer - Dissecting a MachineLearning Powered Investigation https://artificialinformer.com/issue-one/dissecting-a-machine-learning-powered-investigation.html How Times Reporters Froze a Fatal Momenton a Protest Field in Gaza - The New YorkTimes https://www.nytimes.com/2018/12/30/reader-center/gaza-medic-israel-shooting-video-investigation.html https://www.figma.com/ https://www.youtube.com/c/Vox/featured ","date":"2021-05-10T00:00:00Z","image":"http://localhost:1313/asahi-journalism-2021-2/images/asahi-journalism-2021-2_hu_45a3014098fe254d.jpg","permalink":"http://localhost:1313/asahi-journalism-2021-2/","title":"データジャーナリズム　その２　事例と手法から"},{"content":"※本記事は朝日新聞社ジャーナリスト学校による「Journalism(ジャーナリズム) 2021年4月号」に掲載された著者自身による記事の転載です。 Journalismは残念ながら現在休刊中ですが、Amazonなどでバックナンバーを入手することができますので、機会があればぜひお手にとってください。\nデータジャーナリズム　その１　定義と歴史を概観する 始まりは1800年代にあり。現在の世界的潮流は? ここ数年来、注目されている取材手法に「データジャーナリズム」がある。政府や企業などが公開する大量の情報を分析し、新しい事実や埋もれていた社会課題を掘り起こす調査報道のことだ。ＩＴ技術の発達のおかげで身近になってきたが、一般の記者にとってはまだ遠い存在であるともいえる。当欄「記者講座」では今回から全４回の予定で、その定義や歴史、具体的な手法や実践例を紹介する。\n誰しもが東京オリンピック・パラリンピックの開催を迎えると信じて疑わなかった２０２０年が、年明け早々からＣＯＶＩＤ―19（新型コロナウイルス感染症）への恐怖に包まれ、大多数の国民の関心事となった。データジャーナリズムに取り組む報道機関やジャーナリストはこれまで限定的だったが、このコロナ禍により突如、中央・地方にかかわらず取り組まざるをえない状況が現出したといえる。とはいえ、報道において連日陽性者や重症者数をチャートやダッシュボード（様々な情報をまとめて一覧表示したもの）にして取り上げればそれでよいのか。ほかにできることはないのか。本稿では、海外を含めたデータジャーナリズムの定義と歴史をマクロに概観して提示する。\nデータジャーナリズムとは何か 定義はさまざまだが、おおむね「従来のジャーナリズム手法に加えて、データ分析、プログラミング、ストーリーの視覚化などの技術が採用されている現代ジャーナリズムの一側面である」（DataJournalism in Sweden）と 捉 え る こ とができる。その上でここでは以下の三つの観点から詳細にふれていく。\n１ 調査報道の一形態として データジャーナリズムを調査報道の一形態として捉えると理解が進む。調査報道とデータジャーナリズムをほぼ同義と捉える見解もあれば、「ワシントン・ポストがウォーターゲート事件で見せたような手法とはまったく対照的な調査報道」として、調査報道の中でも従来の手法 を ハ イ リ ス ク・ ハ イ リ タ ー ン 手 法、「データ集約型」をローリスク・ローリターン手法として明確に区別する見解もあるが、これはデータジャーナリズムをやや狭義に捉えているため、本稿では従来の手法と対照的には捉えず、その一形態として捉えることとする。\nまずは調査報道の定義を『調査報道実践マニュアル』（マーク・リー・ハンター編著、旬報社）から一部引用する。\n「通常のニュース報道は、世界をありのままに、客観的なイメージを作り出すことを目的としている。調査報道では、世界を改善するという主観的な目的に向かって、客観的に見て本当の材料、すなわち分別のある観察者が真実だと認めるような事実を使用する」\nそのためにまずは仮説を立てるわけだが、例えば政府や企業などの公的な組織の公式見解（表向き言っていること）と実際に行っていることが異なると考えた場合、これ自体が仮説となる。\nそしてその仮説を実証し、公式見解を覆すためにはできるだけ根源的な情報にアクセスし、そこから「真実だと認めるような事実」を入手する必要がある。そのため公開情報はもちろん、リークを含む未公開情報や人的情報源にアクセスし、物的証拠や状況証拠を突き止める。その際の証拠となる資料は、広く捉えればデータであるといえるし、資料を手動で扱うのみならずコンピューターを用いればデータジャーナリズムと言えるだろう。\n２ プロセスとプレゼンテーション さらにデータジャーナリズムの特徴をいえば、報道におけるプロセス（仮説・取材・資料の分析）とプレゼンテーション（コンテンツとして世の中へ提示）の双方を指すことが多くの研究によって強調されている。\nプロセスにおいては、データの収集や分析にコンピューターを用いることを指す。世界にあふれるデータ量は年々増加している。たとえばパナマ文書の際はリークした文書の容量が２・６テラバイト、１１５０万ファイルほど存在した。これら大量のファイルの中から告発に値する事実を発見するのは人力のみでは不可能に近かった。\nプレゼンテーションにおいては、一義的には、インターネット端末を閲覧対象とした際の提示方法として、インタラクティブ（双方向）なコンテンツやＶＲ（仮想現実）・ＡＲ（拡張現実）などのアプリ、もしくは映像などのコンテンツデリバリーを指すが、デジタルファーストで制作したコンテンツは、静止画として紙面への展開にも融通が利くため、たとえばニューヨーク・タイムズや日経新聞などではデジタルと紙面の両方で、同一データ同一コンテンツから切り口を変えて同時期にコンテンツを展開する事例もある。\nプロセスとプレゼンテーションは、どちらか一方のみでもコンピューターを用いてデータを扱っていればデータジャーナリズムと呼べる。すなわちプロセスにおいてコンピューターによるデータ分析を行い、プレゼンテーションとして通常の報道のようにテキストによる記事コンテンツとする場合でも、プロセスは通常の報道と同様であってもプレゼンテーションにおいてコンピューターを用いてデータを扱っていればデータジャーナリズムと呼べる。\n朝日新聞「データジャーナリズム事例集」による分類をひもとけば、プロセスとはデータベース重視・データ分析重視であり、プレゼンテーションとはビジュアライズ重視・マッピング重視・インタラクティブ重視だと言える。\nつまり、報道機関はデータジャーナリズムにいつの間にか取り組んできたと言えるのである。\n３ どう実践していくか ただしそうは言っても、こういった手法は、従来の記者としてのキャリアにおいて取り組んできた実務からすると、そこに乖 かい離り が感じられるかもしれない。これについては二つ述べたいと思う。\n一つ目は「海外を含めてどの報道機関にとってもその『乖離』は同様であり、外部の専門家や団体と積極的にコラボレーションしつつ実績やナレッジをためることで、その後組織内に専門人材を配置できるようになる」ということだ。社内外にかかわらず、通常は一人で作業を完結する「データジャーナリスト」は想定されず、多くの場合、執筆者・デザイナー・プログラマーという専門性を有した少なくとも３人からなるチームが最も有望であることが実証されている。\n二つ目には「分析と呼ぶものの中にも色々なレベルがあり、高度な専門性を必要とするデータ処理ではないもの、単純に項目や時系列の比較をデータ可視化によって行い、現象を捉えて取材対象を見定め、その後は通常通りの取材活動を行う」というやり方もあるということだ。\nその発達と歴史 それでは、データジャーナリズムはどうやって発達してきたのか。現在の潮流は何か。「データジャーナリズム」という概念や用語自体は21世紀、特に２０１０年以降のものだが、歴史としては19世紀初頭までさかのぼることができる。そして、１９５０年代以降、コンピューター支援報 道（CAR: Computer-Assisted Reporting）やプレシジョンジャーナリズム（Precision Journalism、高精度報道）と呼ばれた取り組みがあった。つまり、「データジャーナリズム」という概念を用いて過去の取り組みもすべて整理しなおせるという考え方があるのだ。以下、見てみよう。\nヴァージョン1.0 データジャーナリズムの始まりは１８００年代初頭で、データファイルやデータベースを統計の手法で処理を行っていくことを指すと定義できる。\nイギリスのガーディアン（当時はマンチェスター・ガーディアン）の創刊号にデータジャーナリズムによる記事が掲載されている（１８２１年５月５日）。マンチェスターとサルフォードのそれぞれの学校の生徒数と年間支出額の表データを記事にしたものだ。これは何人の生徒が無償教育を受けているのか、そして市内にはどれだけの貧しい子供たちがいるのかを示す非公表データのリークで、無償教育を受けている子供たちは８千人という公式数値がいかに不正確であったかを示した（実際は２万５千人弱だった）。\nヴァージョン2.0 １９５０年代以降、すでにこの時点で社会科学の方法論とコンピューターを用いた手法が登場する。コンピューター支援報道やプレシジョンジャーナリズムと呼ばれる取り組みだ。引用されることの多い『PrecisionJournalism: A Reporter\u0026rsquo;s Introduction to SocialScience Methods （高精度報道記者による社会科学的方法の紹介）』という著書のある米国人記者フィリップ・マイヤーによれば「社会科学的な研究手法を用いてデータを分析する科学的なアプローチを用いれば、ジャーナリストが間違えることは少なくなる」というものであった。そのマイヤーの代表作には『Riotin Detroit （デトロイト暴動）』がある。１９６７年に暴徒が市内の商店を襲撃、略奪を行った事件において、社会の最下層によるものだとした既存の報道をくつがえし、暴動の真の原因をデータから解明した仕事だ。データジャーナリズムの古典の一つといえる。\nヴァージョン3.0 データサイエンスの発達に伴って報道へも活用されていくことが２０００年頃から始まったが、本格的に認知されたのは２０１０年以降である。同年以降、データジャーナリズムに関した研究や助成金が増加していることが見てとれるからだ。背景としてデータサイエンスの発達のみならず、社会における技術の充実やムーブメント、結果として、社会生活の変化があることは間違いない。代表的な例を挙げておく。\n①常時接続　インターネット回線の普及、とくにスマートフォンというインターネットに常時接続している端末を手軽に持ち運んで活用する生活スタイルが普及していった。さらにＳＮＳが台頭することによって、これまでメディア媒体を通じてしか発信がかなわなかった著名人や公的な地位にいる人が直接一般に向けて発信を行えるようになり、かつ、事件や事故に居合わせた一般人が自身で発信を行えるようになった。これにより、取材対象となる人やコンテンツがＳＮＳ上に存在することとなった。個別の取材申し込みはともかく、特定イシューにおける発信者の履歴や傾向などを分析しようと思えば、データジャーナリズムの手法は欠かせない。\n②オープンデータ　オバマ氏が米大統領に就任後、透明性とオープンガバメントをうたい、政府情報のオープンデータ化を義務付けた。そのムーブメントがＧ８をはじめとする世界各国に広がっていき、政府が運営するデータポータルが充実していくことにつながった。それらは基本的にはオープンデータの定義通り、誰もが制約なく使用できるデータであった。また、そういったトップダウン以外のあり方も存在する。オープンデータという概念が広まってから先進国における初めてのオリンピックとなった２０１２年のロンドン・オリンピックでは、ガーディアンが過去の競技結果をデジタルデータ化し、オープンデータとして公開することで、その認知に一役買ったといえる。情報公開請求の仕組みは国ごとに異なっているが、オープン・バイ・デフォルトというオープンデータ原則の意味するところは大きい。\n③シビックテック　オープンデータと並走する形でシビックテックと呼ばれるムーブメントが世界的に広がっていった。市民がテクノロジーを活用して、自分たちの課題を解決しようとする取り組みだ。ソーシャルグッドな目的で制作したツールのソースコードをオープンライセンスで共有し、一度制作された仕組みを用いて、国や行政といった単位のデータを様々な団体が利用できるようになった。例えば「税金はどこへ行った？」のような、これまでであれば報道機関が運営するようなサイトが、一般市民と行政だけで作業が完結する形で登場するようになった。\n④Ｗｅｂフロントエンド技術の発達とチャート表現技術の普及　ユーザーの目に直接触れる部分であるＷｅｂフロントエンド技術の発達により、ajaxという技術を用いるとページのリロード（再読み込み）なしにコンテンツが更新可能なことから、Ｗｅｂがアプリケーションのような振る舞いをすることが可能となった。グーグルマップが分かりやすい一例だろう。その上で、これまでブラウザ上でデータ 可 視 化 表 現 を 行 う た め に はJavaやFlashなどを用いてデータの解釈などを独自に実装する必要があったが、D3.jsというオープンソースで事実上の標準となるライブラリが普及したことで、ブラウザ上でのチャートやグラフ・地図によるデータ可視化表現が一気に広がった。スマートフォン上のブラウザはＰＣ上のものと機能的な遜色がほぼなく、これらのコンテンツはそのままスマートフォン上でも動作する。報道のコンテンツとしても多用されることになる。\n⑤ＡＩの社会への実装　現在進行系の変化として、今後は特にＡＩを用いたシステムが社会に実装されつつある。平行してビッグデータが活用される局面が増加していき、それを用いた行政サービスは人間を類型化することにつながり、憲法の保障する個人の自由に抵触するのではないかという観点がある。個人情報の扱いを改めて議論する機運が欧米をはじめ日本でも高まり、日本では山本龍彦・慶應義塾大学教授の著作が知られている。社会の仕組みがそういったシステムやデータを基に実現されていく以上、そこにおける不正や欺 ぎ 瞞 まん、不公平などを暴く調査報道を行おうとすれば、コンピューターを用いた手法を使わざるを得ない局面が増加するだろう。\nオープンソースや無料ツールの普及、オープンデータ・ムーブメントなど、データジャーナリズムが登場することになった社会の変化としてこのような状況があるおかげで、世界中で報道機関に限らず、データジャーナリズムに取り組む組織や人が増えた。表現におけるカッティングエッジを追求する事例は、ある種のＤＸ（デジタル・トランスフォーメーション、デジタル化による組織変革）化を果たしたニューヨーク・タイムズやワシントン・ポストが主導しているように思える。アジアでは日経新聞やサウスチャイナ・モーニング・ポストが定期的に良質なコンテンツを生み出し続けている。\n近年の作品の傾向 世界中の報道機関がエントリーするデータジャーナリズムのアワードがある。母体になっていたのが、Global EditorsNetwork （GEN）という、編集者とメディアイノベーターのためのコミュニティだった。コミュニティが存在していた２０１１～19年までは「データジャーナリズム・アワード」、それ以降は「シグマ・アワード」と改称している。２０１３～16年にデータジャーナリズム・アワードで最終選考まで残った２２５の企画を分析した研究から一部を以下に紹介する。当時の作品の傾向がわかるはずだ。\n既存の大手報道機関が多くの賞を受賞する傾向にある データジャーナリズムは今も労働集約的。ほぼ３分の１（32・７％）が「分析かビジュアル化のため外部パートナーの協力があったことを明記している」。 新聞が依然、データジャーナリズムの主な担い手。推薦作品の43・１％、受賞作の37・８％は新聞社。続いて多かったのは、調査報道専門組織、雑誌とオンラインメディア、公共・民間放送、通信社。 主な対象は政治分野。半数近い48・２％は政治の話題で、これに国勢調査や犯罪報告書など社会分野（36・６％）、ビジネスと経済（28・１％）、健康と科学（21・４％）が続いた。一つの分野だけを扱うものが多いのも特徴で、例えば武器を規制する法律が銃撃事件の件数にどう影響するかといった政治と社会など二つ以上の分野にまたがる企画は少なかった。 企画の大半は独自に収集したデータではなく、公的機関のデータに依拠していた。ただし、実際に賞を受賞した作品の多くは、「申請によってか、自前の収集によって、あるいはリークによって取得したデータ」を含んでいた。 ビジュアル化に洗練はみられない。静止画像と図表が多くみられ、特に典型的なのは画像と図表の組み合わせ（40％）で、画像と地図の組み合わせが32・４％、地図と図表の組み合わせも31・１％だった。 インタラクティブ機能でも洗練されたものはまれだ。拡大できる地図やフィルター機能がよくみられたが、これらはデータジャーナリストが使いそうな無料アプリにも多く含まれているからなのかもしれない。 この研究以降の作品の傾向について、筆者の個人的な感想は、ビジュアル化の洗練は進む一方だということだ。同時にツール化によるコモディティ化（一般化、商品価値の低下）も進んでいる。誰かが新しい表現を開発すると、ツールのテンプレートとして取り組まれ、より多くの人が手軽にその表現を活用できる流れができているといえる。\n日本での経緯 『権力に迫る「調査報道」』（高田昌幸・大西祐資・松島佳子編著、旬報社）によると、調査報道を行う専門組織を新聞社が設置する動きは、全国紙、地方紙を問わず、２００６年以降に活発化した。その後数年で動きは落ち着いたとのことだが、２０１１年の東日本大震災以降、データジャーナリズムに取り組む機運が高まっていった。翌２０１２年秋には、朝日新聞やＮＨＫといった報道機関、本田技研工業やゼンリンデータコムといった企業、グーグルやツイッターといったＩＴプラットフォーム企業が集まって「東日本大震災ビッグデータワークショップ」が開催され、セクターを超えてコラボレーションするきっかけにもなり、ここからＮＨＫスペシャル「震災ビッグデータ」が生まれるきっかけにもなった。\nこの動きは途絶えることなく、朝日新聞、日経新聞、ＮＨＫ、ヤフーなどがデータジャーナリズムのコンテンツを継続的に制作している。同時期に、非営利組織である日本ジャーナリスト教育センター（ＪＣＥＪ）や朝日新聞がハッカソン・イベントを開催した。ジャーナリストとデザイナー、エンジニア、研究者が、イベントを通じてチームを組み、短い時間の中で作品をつくり上げるものだ。職能を超えて共に作品づくりに取り組む場づくりがなされ、筆者も一参加者として参加したが、今でも人のつながりとして残っている。\n２０１６年には、リーク文書を元に国を超えたジャーナリスト・チームによる労作コンテンツであるパナマ文書のデータベースが公開され、数カ国で元首レベルの公人が退任に追い込まれた。映画でも、「スポットライト 世紀のスクープ」「シチズンフォー スノーデンの暴露」といった作品が公開され、一般的に調査報道、データジャーナリズムの認知が日本国内でも広がったが、その頃には、日経新聞やヤフーを残して、継続的に制作している組織は少なくなり、以降、局所的単発的に組織の中の有志が制作しているコンテンツが不定期に公開される、という状況になっている。\nＣＯＶＩＤ－19の衝撃 だが、本稿の冒頭で触れたとおり、ＣＯＶＩＤ―19に見舞われた２０２０年、中央・地方にかかわらずデータジャーナリズムに取り組まざるをえない状況が突如現出した。行政の出す陽性者数などのデータの集計が行政側で間に合っておらず、公式データが不確実なままであったため、各報道機関内や民間有志が個別に毎日公表されるデータをメンテナンスしながらダッシュボードを運営しつづける、というかつてない状況が現れた。\n行政がこれまで扱う事象といえば、定期的で既知な出来事として国勢調査や選挙、不定期で未知な出来事として水害や地震などの自然災害、事件事故であった。これらはそれぞれ頻度が少なく不定期、局所的な現象であるといえた。だが、ＣＯＶＩＤ―19においては、発生頻度が毎日、対象地域が日本中ということで、発生頻度や対象地域がこれまでで最大となった。これはワークフローがＤＸ化されることでやっと対応できるほどの熾し 烈 れつさであろう。\n報道においても特に初期のころに混乱がみられた。２０２０年４月ごろのことだが、複数の報道機関による東京都の陽性率の報道が、分母と分子においてデータの基準（集計先の施設の種類）が異なっていたため、大きく率を修正せざるを得ないということが起きた。都の公式サイト上の表記がわかりづらく、公開されているデータファイル自体にそういった特性の違いが記述されていないため誤解を招きやすい状態にあったといえる。誤報は仕方ないとしても、指摘に対しては真摯に向き合い、訂正すべきは訂正する必要があるだろう。ＣＯＶＩＤ―19対応では報道機関各社の持ち味の違いがよく現れた。日本と海外の状況を同時に様々な指標を用いて更新し続けたところ、客観的なデータ提供に特化するところ、ＳＮＳ上のデマを積極的に見つけてデータやリサーチを元に反論を行っていくところなどが特徴的であった。\n次回は具体例と代表的な手法を見ていく。\n参考資料 Data Journalism in Sweden https://www.researchgate.net/publication/271682054_Data_Journalism_in_Sweden 『アメリカ・メディア・ウォーズ ジャーナリズムの現在地』（大治朋子、講談社現代新書） 『調査報道ジャーナリズムの挑戦―市民社会と国際支援戦略』（花田達朗ほか、旬報社） 『調査報道実践マニュアル―仮説・検証、ストーリーによる構成法』（マーク・リー・ハンター編著、旬報社） 朝日新聞社 データジャーナリズム事例集 http://www.asahi.com/miraimedia/dj/case/ Data Journalism: Principle Development AndKnowledge Adaptation in Thailand. EkaponThienthaworn https://repository.nida.ac.th/server/api/core/bitstreams/1f17c563-6f33-4a82-99b5-55fa245601fc/content The first Guardian data journalism: May 5,1821 https://www.theguardian.com/news/datablog/2011/sep/26/data-journalism-guardian Precision Journalism: A Reporter\u0026rsquo;s Introductionto Social Science Methods Philip Meyer https://books.google.co.jp/books/about/Precision_Journalism.html?id=uUzT0M_lPbYC\u0026redir_esc=y Riot in Detroit https://s3.amazonaws.com/s3.documentcloud.org/documents/2070181/detroit1967.pdf Data-driven reporting: An on-going (r)evolution? An analysis of projects nominatedfor the Data Journalism Awards 2013-2016 Wiebke Loosen, Julius Reimer, Fenja De Silva-Schmidt https://journals.sagepub.com/doi/abs/10.1177/1464884917735691?journalCode=joua https://www.niemanlab.org/2017/10/not-a-revolution-yet-data-journalism-hasnt-changed-that-much-in-4-years-a-new-paper-finds/ 『権力に迫る「調査報道」 原発事故、パナマ文書、日米安保をどう報じたか』（高田昌幸ほか、旬報社） 『震災ビッグデータ〈３・11の真実〉〈復興の鍵〉〈次世代防災〉』（阿部博史・ＮＨＫスペシャル「震災ビッグデータ」制作班、ＮＨＫ出版） The 2020 Sigma Awards DataJournalism.com https://datajournalism.com/awards VALID ‒ Visual Analytics in Data-drivenJournalism http://www.validproject.at/ Patterns in Award Winning Data Storytelling:Story Types, Enabling Tools and Competences Adegboyega Ojo, Behareh Heravi https://www.researchgate.net/publication/321409831_Patterns_in_Award_Winning_Data_Storytelling_Story_Types_Enabling_Tools_and_Competences ","date":"2021-04-09T00:00:00Z","image":"http://localhost:1313/asahi-journalism-2021-1/images/asahi-journalism-2021-1_hu_4e0f6734ca2de82d.jpg","permalink":"http://localhost:1313/asahi-journalism-2021-1/","title":"データジャーナリズム　その１　定義と歴史を概観する"},{"content":"データ・ジャーナリズムにおけるグローバル最大規模のアワード シグマ・アワードって? 今年で通算十一年目になるシグマ・アワード、エントリーを現在（2021年1月いっぱい）受付中です。\nシグマ・アワードは**「データジャーナリストのグローバルコミュニティに力を与え、高め、啓発することを目的とした新しいデータジャーナリズムコンテスト」です。運営や審査には第一線の研究者・実務家**がかかわり、世界中からエントリーがなされるアワードです。昨年（2020年）実績では、66の国と地域、287の組織から510点の応募があったとのことです。\n2021年、シグマ・アワード自身の考える重点項目 COVID-19パンデミックに取り組む人々に焦点を当て、世界中で行われている最高のデータジャーナリズムにスポットライトを当てる。 アワードを超えて永続するコミュニティ構築。 現代のジャーナリストが直面している真の緊急課題に取り組むウェビナー、チャット、オンラインリソースの収集をセットアップする。 世界中のデータジャーナリズムコミュニティを団結させ、活気づけ、拡大するための方法としてアワードを活用する。 昨年度（2020年）との違い 5000米ドルの賞金が、受賞者の間で分配されます。分配の仕方は審査員が決定する予定。 作品エントリーする「カテゴリー」の廃止。報道機関（ニューズルーム）の所属人数よる分類のみ、カテゴリーとして残っています。 応募に際してのルール 応応募作品は、2020年に発表された作品に限ります。 期日までに、公式オンラインフォームから提出してください。 応募者は何点でも応募することができます。 応募には、大規模ニューズルームか小規模ニューズルームか個人かを明記してください（小規模とは、ジャーナリスト（正規や下請けを含む）の数が35人以下の組織を指します）。複数組織によるコラボレーション作品の場合、大規模としてエントリーしてください。 シグマ・アワードのウェブサイトやその他のマーケティング資料に、応募団体の名前やロゴを含め、応募作品の素材を使用する権利を与えることに同意します。 審査員は、作品を本質的なものに絞り込んだ、短く、簡潔で、よく練られたエントリーを評価します（冗長に長く書いても評価しないという意味だと思われます）。 将来的には、この賞のプログラムを言語にとらわれないものにすることを目標としています。2021年のコンテストは締め切りが厳しいため、英語以外の言語での応募は、できるだけ翻訳が必要となります。事前審査員と審査員があなたの作品を十分に理解できるように、できるだけ多くの翻訳をしてください。 こんな作品を待っています、とのこと ジャーナリズムのサービスとして、素晴らしいデータ収集と分析を行い、理想的には公共の関心に答える、まだ知られていない事実に光を当てること。 素晴らしいストーリーテリングとエンゲージメント、おそらく視覚的にも対話的にも。 記事のレポートや分析として、もしくは、コミュニティが自分たちで重要な情報を発見できるようにするという意味で、素晴らしい公共サービスであること。 この分野を前進させるような素晴らしいアイデアを持っていること。 メディア・パートナー 各国にメディア・パートナー団体があります。日本では、Data Visualization Japanというコミュニティがここ数年取り組んでいます。\n追加情報 前回の受賞作品や過去の経緯などをスライドにとりまとめています。\n応募ページ エントリーページ\nご不明点 日本語によるお問い合わせに対応します。Twitterで @yuichy02 もしくはメールで datavizjapan@gmail.com までご連絡ください。\n","date":"2021-01-26T00:00:00Z","image":"http://localhost:1313/sigma-awards-2021/images/Sigmas-2021-promo-banner-twitterTFB1200x628_hu_9f4c33083083fc03.png","permalink":"http://localhost:1313/sigma-awards-2021/","title":"シグマ・アワード 2021"},{"content":"情報可視化におけるテクニックとして、Focus+Contextとよばれる手法があります。これは、コンテクストと詳細を分離せずに同時に提供する…というと少し複雑に聞こえますが、概要と詳細の両方を同一画面で地続きに表現するために、表示領域の空間を歪める方法です。\n二焦点ビュー(Bifocal View) Bifocal View (1982) こうした手法のさきがけは、1982年にRobert Spenceが発表しています。\nData Base Navigation: an Office Environment for the Professional\n遠近ウォール(Perspective Wall) The Perspective Wall (1991) The perspective wall: Detail and context smoothly integrated\n魚眼ビュー (Fish­ Eye View) Generalized Fisheye Views (1986) Generalized Fisheye Views\nFisheye Menu (2000) Fisheye Menu\nGraphical Fisheye Views (1993) Graphical Fisheye Views\nハイパーボリック・ブラウザー(Hyperbolic Browser) Hyperbolic Geometry (1995) A Focus+Context Technique Based on Hyperbolic Geometry for Visualizing Large Hierarchies\n3D Hyperbolic Space (1998) Exploring Large Graphs in 3D Hyperbolic Space\n","date":"2020-11-11T00:00:00Z","image":"http://localhost:1313/focus-context/images/image-35_hu_173df2e7b5869611.png","permalink":"http://localhost:1313/focus-context/","title":"Focus+Contextの実例"},{"content":"1996年に発表した “Overview first, zoom and filter, then details-on-demand” マントラが今に至るまで引用されることの多いBen Shneidermanさんと、スタンフォード大学からワシントン大学へラボを移動させ、D3.jsのメイン・コントリビュータであるMike Bostockを排出したJeff Heerさんが二人で、ビジュアル・アナリシスにおけるインタラクションの整理(リンク先はPDFファイル)を行っています。2010年の論考です。大きくは以下の三つに分類しています。\nデータとビューの指定(data and view specification) ビューの操作(view manipulation) 分析プロセスと出自(analysis process and provenance) それぞれの違いをまずはみていきましょう。\nデータとビューの指定(data and view specification) アナリストが様々なデータタイプを含む大規模なデータセットを探索できるようにするために、関心のあるデータとビューを指定するための、適切なコントロールを提供するという観点。\nビューの操作(view manipulation) 「データとビューの指定」によって作成された可視化を元に、そのビューを操作してパターンを強調したり、仮説を調査したり、詳細を掘り下げたりできるようにするという観点。\n分析プロセスと出自(analysis process and provenance) ビジュアル・アナリティクスには「可視化の生成と操作」だけではなく「データの探索と解釈の繰り返し」のプロセスを含み、その分析プロセスを足場にするための機能提供という観点。\n具体的な操作 データとビューの指定(data and view specification) 可視化(visualize)、フィルタリング(filter)、ソート(sort)、導出(derive)が挙げられています。\n可視化…データの可視化を指定すること。\n以下のような方法が挙げられています。\nよくある例ではテンプレート化されたチャートの中から一つ選択し、データ変数を割り当てることで、データをチャートとして描画すること。 \u0026ldquo;data-flow graphs\u0026rdquo; を使用して指定する。 可視化構築のための文法に基づいて指定する。ggplot2 や Protovis が該当する。 これらの方法は互いに排他的ではなく、同時に使用することで、使いやすさろ表現力を両立させることもできる、としています。\nフィルタリング…データ値をフィルタリングして、表示量を制限する。またデータセットの異なるサブセットを比較するためにフォーカスを移動する際に用いられる。\nさまざまなインタラクション技術 一連の補助コントロール、\u0026ldquo;ダイナミック・クエリ・ウィジェット\u0026rdquo; を使用する 後者 \u0026ldquo;ダイナミック・クエリ・ウィジェット\u0026rdquo; について以下の例が挙げられています。\nカテゴリまたは順序データ\n項目の数が少ない場合…ラジオボタンやチェックボックス 項目の数が多い場合や任意のテキストを含む場合…スクロール可能なリスト、階層リスト、検索ボックス（単純なキーワード検索、正規表現マッチング、オートコンプリート付き、構造化クエリ言語） 量的データ、および時間的データ\n単一のしきい値の場合…標準スライダー 複数のエンドポイントを指定する場合…範囲スライダー リアルタイム更新と組み合わせると、これらのウィジェットはデータのサブセットを迅速かつ可逆的に探索することができる、としています。\nソート…1つ以上の変数のデータ値に従って、レコードを並べ替えること。\n数値やテキスト値の昇順または降順ソート。 重要なパターンを明らかにするためには、曜日や月名のような特殊なソート順序が必要になることもある。 多変量表、ネットワークなどデータの種類によっては、値による単純なソートが必ずしもうまくいかないものもある。そのようなデータでは、項目間の距離測定を最小化しようとする、より洗練された並べ替え方法が必要になることがある。 導出…変数を変換したり、既存の値から新しい属性を導き出したりすること。\nスプレッドシートやデータベースのクエリ言語で見られるものと同様に、_計算言語_を介して提供される。 これらの基本的な機能に加えて、仮説検定法（t検定、ANOVA）は、統計と可視化の円滑な統合の利点を増幅させることができる。 導出された値は、記述統計（平均、中央値、分散）からモデル適合（回帰曲線）、データ変換（カウントや合計などのグループごとの集計）に至るまで、入力データを要約するためによく使用される。 ビューの操作(view manipulation) 選択(select)、ナビゲート(navigate)、切り口(coordinate)、整理(organize)が挙げられています。\n選択(select)…関心のある項目や領域を示すこと。何らかの動作の前段としてその適用範囲を「選択」することもある。\nマウスのホバー マウスのクリック 領域選択（長方形や楕円形の領域、または自由形状の「ラッソ」など） 領域カーソル（「ブラシ」や、マウスポインタに最も近いアイテムを選択するバブルカーソルなどの動的なセレクタ） 追加として、\n（より強力で複雑だと前置きありつつ）データに対するクエリとして選択をサポートする。 代表的なオブジェクトをクリックして、そのオブジェクトのプロパティに基づいてより広範な選択を行うことができる（例えば「このような青のアイテムをすべて選択する」など） PCとタブレットやスマートフォンではUIのコンテクストが異なるため注意します。\nこれらの選択は、多くの場合、操作するオブジェクトのセットを決定し、ハイライト、注釈、フィルタリング、または「オンデマンドでの詳細表示」を可能にします。\n選択はマウスやキーボードだけに限定される必要はありません。タッチ、ジェスチャー、音声などの入力モダリティによって、新しい効果的な選択が可能になるかもしれません。\nナビゲート…ビジュアライゼーションはよく、情報空間のビューポートとして機能する。アナリストは、これらのビューポートを操作して空間をナビゲートする必要がある。\nスクロール スクロールバーやマウスドラッグによる表示のパンニング ズームスライダやスクロールホイールを使った異なるレベル間のズーム そのほかにも\nセマンティック・ズーミング フォーカス＋コンテキスト メソッド 遠近両用 (bifocal) ビュー 概要と詳細表示 ディストーション表示 DOI(degree-of-interest)機能 が挙げられている。\nパン（ドラッグ）とズーム（ボタンとスクロール・ホイール）コントロールにより、ビューのナビゲーションが可能になります。\n「概要を最初に見て、ズームとフィルタリングを行い、次に詳細をオンデマンドで表示する」\nこのような方向付けを行った後に、データ・サブセットのより具体的で詳細な調査を行うことができます。\n「概要と詳細表示」はほかにも、たとえば地理空間の可視化で、全体に詳細表示を行い、スーパーインポーズされた矩形内で概要を表示します。\n「ディストーション表示」は、コンテクスト領域が拡大されないように表示領域全体を変形させるディストーション (拡大技術) です。UIとしてはMac OSXのDockがそれに該当します。\n「DOI(degree-of-interest)機能」は、一般的な重要度と操作ユーザーの関心度（マウスクリック、検索クエリ、他の関心度の高い項目への近接度など）の両方に基づいて、情報コンテンツのスコアを計算し、DOIスコアが動的に更新され、関連する未見のデータが表示されたり、無関係な詳細が非表示になったりします。\n切り口…分析者が異なる視点からデータを見ることができるようにするために、切り口を変えること。\nスモール・マルティプル(small multiples) トレリス・プロット(trellis plots) ブラッシングとリンク (Brushing and linking) 凡例と軸 リンク選択は、アナリストがあるビューのパターンが他のビューにどのように投影されるかを評価できるようにすることで、豊かで多次元的な推論を可能にします。\n凡例、ヒストグラム・スライダ、ハイライト・マーカー付きスクロールバーなどの付随するアイテムはすべて、データの複数のビューを提供することができます。\n凡例と軸は、カラーパレット、マーカー属性、変数範囲、または出自情報を変更するためのコントロールパネルにもなります。\n管理…可視化のコレクションを管理されること。\nツリー表示を追加することで、複数の可視化を一度に作成できるようにする ビューが追加または削除されたときの自動（再）サイジング 関連するビューを空間的に近接して配置するためのレイアウト・ルーチン 標準的な散布図マトリックスや、関心のある関連ビュー（例えば、可視化された属性と相関のあるデータ変数）のカスタム生成 複数のウィンドウをグループとして開閉できるようにし、それらを整然と並べる自動化サポート 複数の可視化を同時に探索する際に、すべての情報とセレクタを一度に見ることができたり、気が散るスクロールやウィンドウ操作が自動的に最小限に抑えられることで、洞察の抽出とレポート作成に集中することができます。\n大型化・マルチディスプレイが一般的になるにつれ、レイアウト整理ツールは、効果的なユーザー・エクスペリエンスを生み出す上で決定的な要素となるでしょう。\n分析プロセスと出自(analysis process and provenance) 記録(record)、注釈(annotate)、共有(share)、ガイド(guide)が挙げられています。\n記録…アナリストのインタラクション履歴を記録して可視化することができる。\nユーザーアクションの空間（ビューの仕様、ソート、フィルタリング、ズームなど）をモデル化することで、よりリッチなログを構築し、可視化することができる。 視覚的な履歴は、分岐した履歴の階層的なパターンも明らかにする。 関連するアクションを一緒に「チャンキング」するためのテクニックは、さらに乱雑さを減らすことができる。 コメント、タグ、評価などのメタデータを状態に追加することで、後のレビューや共有を容易にすることができる。 インタラクティブな履歴は、繰り返し可能な一連の操作をキャプチャし、名前を付けて再利用可能なマクロとして保存することもできる。 分析を行った後、分析者はその結果をレビューし、要約し、報告書やプレゼンテーションの形で伝える必要がある場合があるため。\nマウスやキーボードのイベントなどの低レベルの入力は簡単にキャプチャできますが、高レベルのセマンティックなアクションを記録すると、履歴はより価値のあるものになる。\n注釈（アノテーション）…ビジュアルヒストリー内の状態のテキスト注釈を可能にすること。\n可視化内の特定の項目や領域を「ポイント」して、これらのアノテーションを説明テキストや他のビューへのリンクと関連付ける。 自由形式の図形注釈だと、該当する集まりの周りに円を描いたり、グラフのピークに矢印を指し示したりすることで、視聴者の注意を向けることができる。 矢印の角度や色、手描きの円の形は、感情を伝える手がかりとなったり、強調を加えたりすることができる。\n共有…分析者本人以外の複数へビューやデータを共有し、複数の解釈、議論、結果の普及を伴う社会的プロセスを実行する。\n最低限、ビュー（png、jpg、pptなど）またはデータサブセット（csv、json、xlsなど）をエクスポートして、共有と再検討ができるようにしなければならない。 ビューやデータだけでなはなく、ツールの内部状態をモデル化してエクスポートし、他者が続きを探索できるようにする。 可視化ダッシュボードをインタラクティブなWebページとして公開すること。 ガイド…新規参入者をガイドし、専門家に進捗指標を提供するために、ガイドを提供する。\n新規参入者をガイドする。 専門家に進捗指標を提供する。 ","date":"2020-10-30T00:00:00Z","image":"http://localhost:1313/visual-analytics-interaction/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/visual-analytics-interaction/","title":"ビジュアル・アナリシスにおけるインタラクションの整理"},{"content":"Ji Soo Yiら(2007)が、情報可視化の分野でインタラクション技術の検討に関連する分類法を提案している研究をサーベイし、とりまとめています。\n大きく以下の４つに分類できるとしています。\n低レベルなインタラクション技術の分類 インタラクション技術の分類学的次元 インタラクション操作の分類 ユーザータスクの分類法 その上でインタラクション技術を記述するための粒度が様々で、包括的な分類法を定義することが難しいのではないか、としています。\n低レベルなインタラクション技術の分類 Shneiderman (1996) Overview zoom filter details-on-demand relate history extract Buja, Cook, and Swayne (1996) フォーカシング（[投影、アスペクト比、ズーム、パン]の選択、[変数、順序、スケール、スケールアスペクト比、アニメーション、3次元回転]の選択） リンク（条件付けとしてのブラッシング／分割／データベースクエリ） ビューの配置（散布図行列、条件付きプロット）の選択 Chuah and Roth (1996) 基本的な可視化インタラクション（BVI）操作：\nグラフィカル操作（データのエンコード、グラフィカルな値の設定、オブジェクトの操作） セット操作（セットの作成、セットの削除、セットの要約、その他） データ操作（追加、削除、派生属性、その他） Dix and Ellis (1998) ハイライトとフォーカス 追加情報へのアクセス - ドリルダウンとハイパーリンク 概要とコンテキスト 同じ表現／パラメータの変更 同じデータ／表現の変更 表現のリンク - 時間的融合 Keim (2002) ダイナミックプロジェクション インタラクティブなフィルタリング インタラクティブなズーム インタラクティブなディストーション インタラクティブなリンクとブラッシング Wilkinson (2005) フィルタリング（カテゴリ/連続/複数/高速フィルタリング） ナビゲート（ズーム/パンニング/レンズ） 操作（ノードドラッグ/カテゴリの並び替え） ブラッシングとリンク（ブラシ形状/ブラシロジック/高速ブラッシング） アニメーション（フレームアニメーション） 回転 変形（仕様/アセンブリ/表示/タップ/2タップ/3タップ) インタラクション技術の分類学的次元 Tweedie (1997) インタラクションの種類（手動、機械化、指示可能、操舵可能、自動） 直進性（直接・間接操作 ） Spence (2007) 相互作用モード（連続的、段階的、受動的、複合的相互作用） インタラクション操作の分類 Ward and Yang (2004) インタラクション演算子（ナビゲーション、選択、歪み） インタラクション空間（スクリーン空間、データ値空間、データ構造空間、属性空間、オブジェクト空間、可視化構造空間） インタラクションパラメータ（フォーカス、エクステント、変換、およびblender） ユーザータスクの分類法 Zhou and Feiner (1998) 関連性のある視覚タスク（関連付け、背景、分類、クラスター化、比較、相関、区別、強調、一般化、識別、位置特定、ランク付け、明らかに、切り替え） 直接的な視覚的整理とエンコーディングタスク（エンコード） Amar, Eagan, and Stasko (2005) 値の取得 フィルタリング 派生値の計算 極値の検索 ソート 範囲の決定 分布の特徴付け 異常値の検索 クラスタ化 相関関係 ","date":"2020-10-30T00:00:00Z","image":"http://localhost:1313/infovis-interaction-taxonomy/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/infovis-interaction-taxonomy/","title":"情報可視化におけるインタラクション技術の分類法"},{"content":"データビジュアライゼーション用にSVGやCanvasを描画するJavaScriptのライブラリ、D3.jsを利用して、SVGではなくCSS3のFlexboxを利用したチャート描画のスタディを行っていた記事をご紹介します。\nD3.jsは、可視化の自由度に注目がいきますが、ライブラリとして評価されているところはブラウザ上での可視化に必要な機能が一通りライブラリとして整備されていることで、たとえば「ヒストグラムのビンの計算といった統計的な基礎の計算」が行えたり、「様々な形式のデータファイルを非同期的に読み込んで可視化する際に扱いやすい多次元配列を内包するJSON形式に変換（RやPythonでいうところのデータフレームのようなもの）」したり、といったことが含まれます。\nD3.jsを用いると、SVGだけでなく、HTML上のフォーム要素（例：ラジオボタンやチェックボックス）などもデータドリブンに生成することが可能です。データ可視化におけるフォーム要素は「データと描画」もしくは「描画のみ」を操作するために利用されますから、可視化そのもの同様に、データドリブンに生成・変更できる必要があります。\nこのD3.jsの機能を利用して、レイアウト指定がトリッキーな、積み重ね棒グラフなどについて、SVGを用いずにCSSのFlexbox機能を使って実装してみた、というのが紹介する記事ということになります。\nCSS3のFlexboxって何だっけ ユーザーインターフェイスデザイン用に最適化された、CSS3で採用されたWeb標準のレイアウトモデルです。あるコンテナのアイテム内のレイアウトの最適化に向いています。以下のようなことが実現できます。\n任意の方向にレイアウト サイズを「フレックス」して、未使用のスペースを埋めるために拡大するか、親のオーバーフローを回避するために縮小する 水平方向と垂直方向の両方の配置を操作 コンテナ内のアイテムをネスト（水平内側垂直、または垂直内側水平）させて、2次元のレイアウトを作成 結果は… 具体的な成果についてはそれほど長い記事でもないのでリンク先の元記事を参照してもらえればと思いますが、矩形（四角形）の幾何図形を用いて、整列を柔軟に行うことができる、という性質を利用すれば、使い所がありそうです。SVGの空間座標が左上が(0,0)、右下がたとえば(100,100)といった座標系ですから、下から上へ積み上げる系のチャート描画の計算には一苦労します。そういった実装をする際の、非直感的な座標指定の気持ち悪さを解消する、といった感じでしょうか。\nそれ以外でも、今すぐパッとは思いつきませんが、これまでのチャートやグラフとは少し違った独自の可視化表現を探る際に、実装の手数の一つとして覚えておいていいかもしれません。\n","date":"2020-10-03T00:00:00Z","image":"http://localhost:1313/d3-flexbox/images/social-facebook_hu_3b5e20d67346605f.png","permalink":"http://localhost:1313/d3-flexbox/","title":"D3.jsは利用しつつ、SVGではなくFlexboxによるチャート描画"},{"content":"The PuddingというメディアのJan Diehmさんがデータジャーナリズムの講義（Data Journalism and Visualization with Free Tools）にて、どのようなタイプのデータ・ストーリーが存在するかとして、大きく以下の四つに分類し紹介していました。初見の分類法でしたのでこちらでも紹介します。説明文には筆者（矢崎）独自の観点や補足も付けています。ピックアップされている事例は元の講義に準じます。\nScrollytelling(スクローリーテリング) Microstories (マイクロストーリーズ) Non-traditional (非伝統的) Explainers (説明者) Scrollytelling(スクローリーテリング) 閲覧者がページを下にスクロールすると、アニメーションとともにストーリーが直線的に展開する手法。閲覧者はただスクロールするだけでよく、クリックやホバーを含む込み入った操作をする必要がありません。PCのみならずスマホやタブレットでの親和性も良いですね。\n元々この手法を用いた開拓者たるコンテンツはニューヨーク・タイムズのSnow Fallという作品。パララックス・スクロールに動画をシームレスに組み合わせてデータ・ストーリーに応用した印象です。\nパララックス・スクロール自体は、Snow Fall以前から、とくにiOSデバイスがFlashをサポートしなかったため、Flashがウェブで全面的に使えなくなって以降、主要でささやかな演出の一貫として、ウェブでの商品紹介ページなどでマーケティングの観点からよく利用されていた印象ですが、この手法のジャーナリズムへの転用といえそうです。\nSnow Fall: The Avalanche at Tunnel Creek - Multimedia Feature - NYTimes.com 登場した際、驚きをもってシェアされたSnow Fall。もう8年前のコンテンツですね。元ニューヨーク・タイムズのデータ・エンジニアが「ユーザーの85%がインタラクティブなコンテンツをスルーする」と衝撃的なトークをカンファレンスで行ったこともありました。これは別記事にします。\nhttps://www.nytimes.com/projects/2012/snow-fall/index.html#/?part=tunnel-creek\nTwenty years of the NBA redrafted The Pudding 作のコンテンツです。The Pudding はこのようなジャーナリズムど真ん中よりも少しエンターテイメント寄りのコンテンツが多い印象です。\nhttps://pudding.cool/2017/03/redraft/\nGoing Gray ロイターが日本の高齢化社会のことを他国との比較から注目しているコンテンツです。\nhttps://graphics.reuters.com/JAPAN-AGING/010091PB2LH/index.html\nMicrostories(マイクロストーリーズ) Scrollytellingに比べるとアナログなアプローチで、焦点をかなり絞り、静止画の一枚で完結するようなデータ・ストーリーの伝え方です。\nMona Chalabi Monaさんはニューヨーク在住のジャーナリストで、個人ワークをInstagram上で発表し続けています。\nhttps://www.instagram.com/p/BtTjIYwngqn/\nhttps://www.instagram.com/p/BtTjIYwngqn/\nDear Data MoMAのパーマネント・コレクションにも選出された、ロンドンとニューヨークに住む女性デザイナー同士のコラボレーションです。\nhttp://www.dear-data.com/\nNon-traditional(非伝統的) 従来のデータ・ストーリーとはまったく異なり、従来のチャートやグラフは全く用いず、代わりに画像・動画・ARやVRなどの新しい技術を使用してデータ・ストーリーを伝えています。\nApollo 11: As They Shot It - The New York Times ニューヨーク・タイムズによるApollo 11月面着陸五十周年を記念したコンテンツ。できるかぎり状況をリアリスティックを持った伝達のために、残された会話や写真を素材を再構成しています。スクローリーテリングの手法も用いていますがそれだけではないため、こちらの分類されているようです。\nhttps://www.nytimes.com/interactive/2019/07/18/science/apollo-11-as-they-shot-it-ul.html\nThe NFL Has Had 280 Concussions This Season チャートを一つも使用していませんが、これも「データ」を用いたデータ・ストーリーだとJanさんは紹介しています。\nhttps://vimeo.com/253738508\nExplainers(説明者) 物事の仕組みを詳細に説明するためにインタラクションやアニメーションが用いられているデータ・ストーリーです。\nParable of the Polygons - a playable post on the shape of society 筆者も大好きな、個人が考える多様性がコミュニティにどのようなインパクトがあるかを示したインタラクティブ・コンテンツです。\nhttps://ncase.me/polygons/\nHow To: Tune a Guitar ジャーナリズムといえるか疑問ですが、実際にギターをチューニングをするためのインタラクティブ・コンテンツです。\nhttps://mathisonian.github.io/idyll/how-to-tune-a-guitar/\nLet\u0026rsquo;s Learn About Waveforms ジャーナリズムといえるか疑問ですが、波形についての The Pudding 作のインタラクティブ・コンテンツです。\nhttps://pudding.cool/2018/02/waveforms/\n","date":"2020-10-02T00:00:00Z","image":"http://localhost:1313/data-story-4-types/images/NYT_SnowFall_hu_70b888dbdede6679.png","permalink":"http://localhost:1313/data-story-4-types/","title":"データ・ジャーナリズムにおけるデータ・ストーリー 四類型"},{"content":"「情報の科学と技術」2020年8月号 特集:RDF/SPARQLの検索と可視化にて初出の論考です。\n要約 大量のデータは，ただデータとして存在しているだけでは有効活用できない。データ可視化の価値について考察した。価値は人が感じるものである。そこでデータ可視化を発信者と受信者によるコミュニケーションの媒介と捉え，そのあり方を考察した。代表的なワークフローを選出し，発信者主体のものと受信者主体のもので二分し，概観した上で，そこから浮かび上がるニーズとコミュニケーションのあり方を考察した。データ可視化は人間社会において，人が人に何かを伝えたり，誰かの課題を解決することをサポートしたりと，今後も重要な役割を担うことは間違いない。\nキーワード: データ可視化，コミュニケーション，研究，情報デザイン，データジャーナリズム，データビジネス，ワークフロー\n1. はじめに SPARQL/RDFの活用により，複数のデータソースを統合してリッチなデータを作成することが可能となる。大量のデータは，ただデータとして存在しているだけでは有効活用できない。データの活用とその価値について，データ可視化という観点から考察した。データ可視化を発信者と受信者によるコミュニケーションの媒介と捉え，そのあり方を考察した。文中に個別の断りはないが，スモールデータやビッグデータのいずれかに限定しない。\n2. コミュニケーションとしてのデータ可視化 データ可視化を含む，データを活用した何らかの成果物をここではデータ・プロダクトと呼ぶことにする。データ・プロダクトは，作り手(生産者)と使い手(消費者)がいて，はじめて成り立つといえる。これを両者によるコミュニケーションであると捉え，作り手を発信者，使い手を受信者と言い換えることにする。データ可視化はデータ・プロダクト構成要素の一つであり，コミュニケーションとして捉える際に最も大事な要素であると考える。そこで，データ可視化が関わる領域において提唱されているワークフローから代表的なものを選出し，筆者の判断で発信者のモチベーションやニーズありきで成り立つ発信者主体のものと，同様に受信者主体のもので二分し，概観する。その上で，そこから浮かび上がるニーズとコミュニケーションのあり方を考察した。\n3. 発信者主体のコミュニケーション 発信者のモチベーションやニーズが中心にあって成立するデータ・プロダクトは表現伝達型であるといえる。以下の領域から選出した。\n研究(問題解決型) 情報デザインやアート表現 データジャーナリズム\n以下，領域ごとに代表的なワークフローを紹介し，データ可視化のニーズとコミュニケーションのあり方を考察する。 3.1 研究(問題解決型) 3.1.1 研究(問題解決型)のワークフロー 研究のワークフローには様々なものが提唱されており学術領域によっても異なるが，ここでは丸山宏「新企業の研究者をめざす皆さんへ」1)を参照した。丸山氏は，研究を個別の問題を解く「問題解決型」と今までにないシステムを作ってみる「設計型」に大別している。筆者の解釈では，「問題解決型」はその問題を解決したいという発信者のモチベーションにより研究が開始される。逆に「設計型」は企業など外部からの依頼に応じて取り組むことが多いのではないか。ここでは発信者主体の研究として「問題解決型」を念頭にワークフローを紹介する。\n1.1 研究の入口:良い問題(研究課題)を選ぶ 1.2 研究本体:問題を解く 1.2.1 問題の分割 1.2.2 仮説生成と検証 1.2.3 仮説の検証 1.2.4 関係の推論 1.2.5 因果の推論 1.2.6 改善を行う 1.2.7 ソリューションを設計する 1.3 研究の出口結果を価値につなげる 1.3.1 技術移転 1.3.2 間接的な貢献 1.3.3 研究をまとめること データ可視化の関わり方としては研究本体における「1.2.2 仮説の生成と検証」〜「1.2.5 因果の推論」における探索的分析や確証的分析といったデータ分析の結果として，および「1.3.3 研究をまとめること」における研究結果を他人にもわかるようにまとめる際に付随するデータ可視化であろう。\n3.1.2 研究(問題解決型)におけるデータ可視化のニーズ 前項で述べた通り，探索的分析や確証的分析における分析結果としてのデータ可視化と，研究成果のプレゼンテーションやアウトリーチのためのデータ可視化に大別する。\n前者においては，データ分析の成果が出ることがゴールとなり，これを見逃さない可視化が重要となる。利用するRやPythonといったプログラミング言語でのデータ分析パッケージの完成度が高ければ，可視化について注意すべきことは少ない。パッケージの完成度が低いものについては利用を予め避けるか，問題を認識した上で対処する必要がある。たとえばPythonのためのチャート描画ライブラリであるMatplotlibにおいて，ヴァージョン1.*までは，デフォルトのプロパティサイクルの色は‘r’，’g’，’b’，’c’，‘m’，’y’，’k’(つまり液晶ディスプレイ用発色方式RGBと，印刷用発色方式CMYKでの色の単色利用)であった2)が，これは出力媒体の発色方式であり，データの性質との整合性は何もなかった。これはヴァージョン2.0以降改善されている。\n後者においては，前者をそのまま掲出する場合と，より広範なアウトリーチを求めて異なる表現が必要とされることがあり，表現伝達のプロフェッショナルではないため，悩む研究者も多いと推察する。\n3.1.3 研究(問題解決型)におけるデータ可視化を用いたコミュニケーション 受信者による発信内容の理解と行動変容をコミュニケーションのゴールと捉える。受信者側の認知を大きく変えたい場合，もしくは発信内容への興味関心が薄い受信者へ働きかけたい場合，たとえば食料廃棄の問題を広く訴える際は廃棄量をチャートで示すよりも廃棄される膨大な食料を写真で提示した方が受信者側の認知が増すこともある。同様のことをデータ可視化による伝達で実現を目指す場合，たとえばインフォグラフィックとして多用されるようなグラフィック表現とする前提で，数値の表現においてビジュアル変数として長さを選ぶのか，面積を選ぶのか，色を選ぶのかによって受信者側の認知は変わる。\n3.2 情報デザインやアート表現 3.2.1 情報デザインやアート表現のワークフロー ウェブコンテンツとしてのインタラクティブなデータ可視化の情報デザイナーとして有名なBen FryやMoritz Stefanerなどのワークフローを踏まえて，Data Visualization Handbook 3)において，Juuso Koponen, Jonatan Hildenは以下のようなワークフローを提案している。\n1-a. 定義…コミュニケーションの目的，ターゲットグループ，グラフィックのためのコンテキストを整理。 1-b. 発見\u0026amp;収集…使用するデータを確認する。データの信頼性と技術的品質を確保し，必要に応じて他の情報源からのデータで補完する。 2. 探索と整理…収集したデータを様々なツールを使って調べ，使える形に整理する。設定された目的に照らし合わせて，興味のない，あるいは適切でないデータをフィルタリングする。 3. スケッチ\u0026amp;実験…様々な方法でデータ提示していく。 4. 作成と精緻化…提示方法が選択されたあと，公開用のグラフィックを作成，精緻化していく。 5-a. 評価…公開後，使用状況やリーチに関するフィードバックを収集し，コミュニケーションの目的が達成されているかどうかを確認する。 5-b. 更新と拡張…Webコンテンツの開発・メンテナンスなので，公開後も継続して行う。必要に応じて，更新や拡張を行う。 3.2.2 情報デザインにおけるデータ可視化のニーズ 情報グラフィックにおけるデータ可視化は，「3.スケッチ\u0026amp;実験」にある通り様々な可能性を探る際に，探索的な可視化を素早く反復しながら試すことが求められる。その際，スタンダードなグラフィックアプリケーション，たとえばAdobe Illustratorなどにおいて，十分な探索的データ可視化が行える機能が付属しているとは言い難い。そこで一から探索的な表現を探ることが可能なデザイナー向けクリエイティブコーディング環境を用いることが多く，代表的なものとして，Processing，D3.js，Three.jsなどが挙げられる。これまで存在していたチャートがデータ表現のテンプレートだとすると，これらを用いることによってテンプレートに収まらない新しいチャート表現が生まれる可能性がある。近年ではエリア・チャートの欠点を克服したストリーム・グラフ 4)という新しいチャートが開発され，定着している。\n3.2.3アート表現におけるデータ可視化のニーズ アート作品にコンセプトを込める際，データの扱いにもコンセプトとの整合性が求められる。データ・プロダクトの成果物としては必ずしも可視化とは限らず，視覚以外の感覚へ訴える作品化も多く，その場合はデータ・フィジカライゼーションと呼ばれる。またテクノロジーを生かした即応性(リアルタイム性)を求められることもある。あらかじめ蓄積されたデータや即時的にセンサーから入力されたデータが組み合わされ，視覚表現や，感覚表現のためのアクチュエーターへの出力として活用される。エンドユーザーがデータの数値を正確に認知することよりも，エンドユーザーの生体的な反応を引き出すような演出が優先されることも多い。\n3.2.4 情報デザインやアート表現におけるデータ可視化を用いたコミュニケーション 一言で語れるものではないが，情報デザインであれば扱うデータや情報が誤解されることなく受信者へ伝達されること，アート表現であればコンセプトや作品としての完成度を受信者が体感することがコミュニケーションになり得る。\n3.3 データジャーナリズム 3.3.1 データジャーナリズムのワークフロー ここでは，既存のデータジャーナリズムの取り組みをバランスよくまとめている資料である，マイクロソフトによる「DataJournalismPlaybook」5)を参照する。「データジャーナリズムとは，そのデータを調査し，理解し，形にして，説得力のあるストーリーとして伝えるプロセスのことだ」とし，プロセスは直線的ではなく，反復するものだという前置きのあと，以下のワークフローを紹介している。\n1. アイデアと仮説の生成 2. データ収集 3. データクリーニング 4. データのインポートとモデリング 5. データ探査 6. ストーリーボードとデータの可視化 7. データの可視化の洗練8.出版と共有 3.3.2 データジャーナリズムにおけるデータ可視化のニーズ 報道機関のコンテンツを速報ニュースと調査報道に大別する。\n前者においては，たとえばAIによるアラートシステムが挙げられる。データ可視化が使用されるのは，速報性の高い出来事の日時や場所の把握や提示などだろう。\n後者においては，政治・社会・経済・スポーツなどの報道機関が扱うジャンルごとの「5.データ探索」や「6.ストーリーボード」のほかにも，社会に広く流通する情報媒体としての紙や写真，動画など膨大な量のバイナリー形式の非構造データをデータ・レコグニションして報道すべきインサイトを発見することや，テキストデータのマイニングが挙げられる。社会に多くみられるネットワーク関係(人間関係や企業の取引関係)からインサイトを発見するため，膨大なバイナリー形式の非構造データを構造化した上でグラフ構造をもたせて，検索機能やネットワーク可視化を提供し調査報道に活用しようとする，ICIJによる「パナマ文書」の調査報道 6)やMicrosoftによる「JFKFiles」7)といった事例が存在する。\n3.3.3 データジャーナリズムにおけるデータ可視化を用いたコミュニケーション ジャーナリズムの舞台が新聞やテレビといったマスメディアのみだった時代は媒体の特性もあり一方的な表現伝達にならざるをえなかった。インタラクティブなデータ可視化を通じたコミュニケーションは受信者たる読者の行動変容を促し，情報探索を通じて，社会的な問題を個人的な問題として捉え直すことを促進する。それはジャーナリズムが自ら規定した役割，つまり社会課題を伝達するが社会課題の解決そのものの行為には関わらない，という従来の線引きに揺らぎをもたらす。\n3.4 発信者主体のまとめ 発信者主体のモチベーションやニーズから始まるデータ可視化のワークフローと，そこで必要とされるデータ可視化のニーズ，必要とされるコミュニケーションについて，領域ごとに考察した。\nデータの中から如何に伝えるべきインサイトを漏れなく発見し，発信者が信じる効果的な方法で表現・伝達すべきかに注目しているかがわかる。伝達後については，データ・プロダクトの完成度という観点での反復的な更新が語られるのみであることが多い。\n4.受信者主体のコミュニケーション 受信者のモチベーションやニーズが中心にあって成立するデータ・プロダクトは課題解決型であるといえる。以下の領域から選出した。\n研究(設計型) ビジネス(データビジネス) ビジネス(経営指標トラッキング) 公共サービス 以下，領域ごとに代表的なワークフローを紹介し，データ可視化のニーズとコミュニケーションのあり方を考察する。\n4.1 研究(設計型) 4.1.1 研究(設計型)のワークフロー Tamar Munznerが「四レベルのバリデーション」(Four Levels For Validation) 8)として提唱している。データ・プロダクトの制作に伴う複雑な問題を四レベルに分割することで，異なる懸念事項を個別に解決できる分析フレームワークとしても機能する。以下の四レベルに分割している。\n1. ドメイン状況(Domain situation)…対象ドメイン，対象ユーザーを定め，解くべき要件を定義する。その際，インタビュー，観察，調査などを行うこともある。ただ，対象ユーザーからいくら詳しくヒアリングしても真の課題が明らかにならない場合もある，としている。 2. データ/タスク抽象化(Data/task abstraction)…ドメイン固有の問題とデータを，ドメインに依存しない汎用的なタスクとデータへ定義し直す。 3. ビジュアル・エンコーディング/インタラクション慣用句(Visual encoding/interaction idiom)…ビジュアル・エンコーディングとインタラクション方法の設計を指す。 4. アルゴリズム(Algorithm)…それらのイディオムを計算機でインスタンス化するアルゴリズムの設計を指す。これらはカスケードな関係にあり，上位レベルの出力は，下位レベルへ影響を与える。工程が上位から下位へ進み，あるレベルのブロックをよりよく理解することで，他のレベルのブロックを精緻化するためのフィードバックとなり，反復することもある前提である。 まずは受信者の課題を如何に解決するかがゴールであり，そのために必要なタスクとデータを明らかにした上で汎用なそれらへと変換する。その上で適切なビジュアル・エンコーディングとインタラクションを定義する，というのが大まかな流れだ。\n上位から下位へ工程が進んでいく問題駆動型(problem-driven)と，下位から上位へ工程が進んでいく技術主導型(technique-driven)と提案されている。技術主導型は発信者主体寄りの考え方だが，ここでは論旨に合わず省略しても論旨を損ねないため省略し，問題駆動型のみを前提とする。\n4.1.2 研究(設計型)におけるデータ可視化のニーズ 対象となる業務分野固有の課題を，如何に汎用的なタスクとデータ処理に置き換えるかが重要となる。ここでのタスクはビジュアル・エンコーディングとインタラクションで実行することになるため，データ可視化はユーザー・インターフェイスそのものの役割を果たす。またコンピュータで全自動に行うことが可能な処理はデータ可視化の必要は必ずしもない。Munzner氏が書いているように，人間がタスクに介在するからこそ，データ可視化はユーザー・インターフェイスとして重要な役割を果たす。\n4.1.3 研究(設計型)におけるデータ可視化を用いたコミュニケーション 研究(設計型)においては，開発開始時や開発中に，発信者と受信者でコミュニケーションをしっかり取り，本当に必要なタスクとデータ処理は何なのかをよく突き詰める必要がある。Katy Börnerによると，受信者が自身の課題を正しく言語化できるとは限らないが，それでも受信者やエンドユーザーの開発への参加は，成功の必須要件だ9)という。\n4.2 ビジネス(データビジネス) 4.2.1 ビジネス(データビジネス)のワークフロー ここでいうデータビジネスは，データそのものが重要な資産であるサービスを提供するビジネスを指す。データビジネスにおいてワークフローは様々あるが，山本大祐「AIプロジェクト実践読本」10)に標準的なものが掲載されていたので引用する。「課題解決とサービス実装のための」という副題がついている通り，実社会でAIを活用するための実際的な知識や産業別ケーススタディを紹介している。開発プロセスとして以下をあげている。\n1. プロジェクト・プランニング 2. PoC(机上実証→フィールド実装)…仮説検証 3. 製品開発 4. 導入・運用…反復的な追加学習 2は「AIを作るフェーズ」と，3・4は「AIを使うフェーズ」と言い換え可能で，データ可視化の観点では，2は数理モデルを作成する際の各種データ分析結果としてのデータ可視化であり，3・4においては，実際のサービスのUXやユーザー・インターフェイスの一部としてのデータ可視化である。\n4.2.2ビジネス(データビジネス)におけるデータ可視化のニーズ 開発されたAIサービスを現場で活用するエンドユーザーのリテラシーに合わせて設計することが重要となる。SaaS(Software as a Service)とよばれるB2Bサービスでは受信者・エンドユーザーの行動をデジタル的に追跡できることが，既存のB2Bサービスと比べた際の圧倒的なメリットであり，利用状況を継続的に観察しながらUXやユーザー・インターフェイスを改善し，カスタマーサクセスを実現していくことが求められる。その際の観察はデータ可視化を通じて行われる。\n4.2.3 ビジネス(データビジネス)におけるデータ可視化を用いたコミュニケーション 実際のサービスのUXやユーザー・インターフェイスの一部としてのデータ可視化について述べる。使い手であるエンドユーザーは幅広く，ときに一般消費者や一般消費者向けサービスの店頭販売員であることもある。データ分析の際に用いるような抽象度の高いデータ可視化やユーザー・インターフェイスよりも，現実に存在している何かを模している(たとえば店舗レイアウト)ことや，一画面あたりのタスク数や選択肢が限定されていること，パソコンではなくスマートデバイスで操作できること，などが求められることがある。\n4.3 ビジネス(経営指標トラッキング) 4.3.1 ビジネス(経営指標トラッキング)におけるワークフロー ここではセルフB.I.(Business Intelligence)の大手Tableauのワークフローを参照する。TableauではTableau Blueprint 11)として，ワークフローの雛形が提供されている。それによると，\n1.分析戦略 2.エグゼクティブアドボカシーとプロジェクトチーム 3.アジャイル性，スキル，コミュニティを確立することで，Tableauの導入と運用を支援 3-1.アジャイル性…導入，監視，メンテナンス 3-2.スキル…教育，評価，分析のベストプラクティス 3-3.コミュニティ…コミュニケーション，エンゲージメント，サポート であり、プランナーのゴールは，利用企業が「データドリブンな組織になる」こととしている。ビジネス上のニーズに応じた様々なデータ活用が事業部・課など組織内のグループ単位で行われる。その際必要なデータが様々な場所やサービスに点在することから，それら多様なデータソースを一元的に集約し，それぞれの課題に合わせた柔軟なダッシュボード作りを行うことが可能であるセルフB.I.ツールが用いられることが多い。\n4.3.2 ビジネス(経営指標トラッキング)におけるデータ可視化のニーズ 標準的には二十種類程度のいわゆる統計チャートが可視化に用いられ，受信者・エンドユーザーによるドリルダウンのためのフォーム要素(プルダウンやラジオボタン，チェックボックス)などと共に用いられることが多い。\n4.3.3 ビジネス(経営指標トラッキング)におけるデータ可視化を用いたコミュニケーション データ可視化はコミュニティにおいて，シェアすべき欠かせない主役的存在である。組織内であれば意思決定のための共通認識やエビデンスとして，組織外ではアメリカを始め日本においてもたとえばTableauコミュニティが活発にデータ可視化作品やその技法をシェアしあい，所属組織を超えて対話を生み出すコミュニケーションとして用いられている。\n4.4 公共サービス 4.4.1 公共サービスにおけるワークフロー 総務省が地方公共団体向けに「地方公共団体におけるデータ利活用ガイドブック」12)を公表している。この中でワークフローに近い「第3章データを活用した行政サービス開発の進め方」から引用する。\nステップ1: 目的を定めよう ステップ2: サービス内容を考えよう ステップ3: 実現方法を考えよう 3-1: どのようなデータが必要か明らかにしよう 3-2: データを使うための手続を確認しよう 3-3: データの入手・共有方法を確認しよう 3-4: データを使った後に行うことを確認しよう ステップ4: サービスを開発しよう ステップ5: 効果や課題を確認しよう ステップ1，2に関連して，サービス設計十二箇条が定められており「利用者のニーズから出発する」「全ての関係者に気を配る」などが挙げられており，受信者のニーズを念頭に作られていることがわかる。ここでは各地方自治体において，データを活用してその地域特有の課題解決に資するサービスを構築することが求められていることがわかる。別途公表されている「総務省ICTスキル総合習得プログラム」13)と合わせて考えると，データのクレンジングと可視化，分析，実際のサービスにおいて，データ可視化が用いられることが予想される。\n4.4.2公共サービスにおけるデータ可視化のニーズ ガブ・テックにおいてはデジタルトランスフォーメーションを含めた行政手続きのデジタル化の一部としてのデータ可視化，シビック・テックにおいては自助や共助のための行政資源や地域資源の顕在化としてのデータ可視化，地方公共団体においては地方創生のための地域資源の発見と活用のためのデータ可視化がある。「RESAS(地域経済分析システム)」14)はそのために開発運用されている。\n4.4.3 公共サービスにおけるデータ可視化を用いたコミュニケーション 発信者と受信者の役割が固定的ではなく，時に入れ替わる。自助や共助のための行政資源や地域資源の顕在化としてのデータ可視化は，セクターを超えた，発信者・受信者間だけでなく、発信者同士や受信者同士のコミュニケーションをも促進する。\n4.5 受信者主体のまとめ受信者主体のモチベーションやニーズから始まるデータ 可視化のワークフローと，そこで必要とされるデータ可視化のニーズ，必要とされるコミュニケーションについて，領域ごとに考察した。\nどれも受信者のニーズ，つまり課題解決などの価値提供ありきであり，それが実現できるデータ・プロダクトを完成させることを成功と定義しているかがわかる。\n5.ニーズ及びコミュニケーションという観点からみたデータ可視化 5.1ニーズという観点からみたデータ可視化 これまで考察したデータ可視化のニーズを，発信者主体・受信者主体別に一覧する。\n(1) 発信者主体 研究成果のプレゼンテーションやアウトリーチの一部として 新しい表現のためのデザインスケッチや実験として テクノロジーを生かした入力データの即応性ある表現として 人間社会に多く流通する非構造データを元に，人間関係や企業の取引関係を描き出す手段として (2) 受信者主体 課題解決のために実行するタスクのユーザー・インターフェイスとして サービスのUXやユーザー・インターフェイスそのものもしくはその一部として 組織内のデータ集約と，利用者それぞれの課題に合わせて作成可能な柔軟なダッシュボードとして 自助や共助のための行政資源や地域資源の顕在化として (3) 共通 データ・レコグニション，データ・クレンジング，探索的分析，確証的分析に付随するデータ可視化 5.2 コミュニケーションという観点からみたデータ可視化 これまで考察したデータ可視化のコミュニケーションのあり方を，発信者主体・受信者主体別に一覧する。\n(1) 発信者主体 発信内容の興味関心が薄い層への働きかけ データや情報，コンセプトの発信者の意図通りの伝達 情報探索を通じて，社会的な問題を個人的な問題として捉え直すことを促進 (2) 受信者主体 開発時における継続的な意思疎通やその成果物として 開発後サービス提供時におけるカスタマーサクセスの一部として 発信と受信の役割が固定的ではなく対話を生み出す手段として 6.おわりに データ可視化を発信者と受信者によるコミュニケーションの媒介物と捉え，そこで必要とされるニーズとコミュニケーションのあり方について考察した。\n発信者主体のコミュニケーションは，表現伝達型として，発信者側での伝えるべきインサイトの発見及び表現と時には受信者側での行動変容をも念頭に置くべきである。\n受信者主体のコミュニケーションは，課題解決型として，受信者側の課題解決に資するために，受信者側と発信者側での十分なコミュニケーションが必須となる。\nいずれにしてもデータ可視化は人間社会において，人が人に何かを伝えたり，誰かの課題を解決することをサポートしたりと，今後も重要な役割を担うことは間違いない。\n参考文献 丸山宏. 新 企業の研究者をめざす皆さんへ. 近代科学社. 2019. \u0026ldquo;Colors, color cycles, and color maps\u0026rdquo;. The Matplotlib development team. https://matplotlib.org/3.2.1/users/dflt_style_changes.html#colors-color-cycles-and-color-maps, (accessed 2020-06-16). Koponen, Juuso,: Hilden, Jonatan. Data Visualization Handbook. Aalto University , 2018. Byron, L.; Wattenberg M. Stacked Graphs – Geometry \u0026amp; Aesthetics. 2008 https://doi.org/10.1109/TVCG.2008.166 Microsoft. Data Journalism Playbook. https://news.microsoft.com/uploads/prod/2018/11/Microsoft-Data-Journalism-Playbook.pdf, (accessed 2020-06-16). \u0026ldquo;The Panama Papers: Exposing the Rogue Offshore Finance Industry\u0026rdquo;. the International Consortium of Investigative Journalists. https://www.icij.org/investigations/panama-papers/, (accessed 2020-06-16). \u0026ldquo;JFK Files\u0026rdquo;. Microsoft. https://www.microsoft.com/en-us/ai/ai-lab-jfk-files, (accessed 2020-06-16). Munzner, Tamar. Visualization Analysis and Design. CRC Press, 2014, 67-93p. Börner, Katy. Atlas of Knowledge: Anyone Can Map. MIT Press, 2015, 24p. 山本大祐. 課題解決とサービス実装のためのAIプロジェクト実践読本 第4次産業革命時代のビジネスと開発の進め方. マイナビ出版. 2019. Tableau. “Tableau Blueprint”. https://www.tableau.com/ja-jp/learn/blueprint, (参照 2020-06-16). 総務省. “データ利活用の促進”. https://www.soumu.go.jp/menu_seisaku/ictseisaku/ictriyou/bigdata.html, (参照 2020-06-16). 総務省. “総務省 ICTスキル総合習得プログラム”. https://www.soumu.go.jp/ict_skill/, (参照 2020-06-16). RESAS 地域経済分析システム. https://resas.go.jp/, (参照 2020-06-16). ","date":"2020-09-01T00:00:00Z","image":"http://localhost:1313/data-visualization-as-a-medium-for-communication/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/data-visualization-as-a-medium-for-communication/","title":"コミュニケーションの媒介としてのデータ可視化"},{"content":"FTのAlan Smith氏が公開している、チャートの分類や種類を視覚的にまとめた一覧です。\nVisual Vocabulary Finantial Times インタラクティブ版 Tableau Public版 Power BI版 Vega版 ","date":"2020-08-30T00:00:00Z","image":"http://localhost:1313/visual-vocabulary/images/Visual-vocabulary-JP_hu_9048d1a81564404d.png","permalink":"http://localhost:1313/visual-vocabulary/","title":"Visual Vocabulary"},{"content":"データ・タイプ別チャート分類です（後日追記します）。\nInfographic Taxonomy Infographic Taxonomy\nDifferent Types of Analysis Atlas Of Knowledge by Katy Borner\n","date":"2020-08-28T00:00:00Z","image":"http://localhost:1313/chart-catalogue-by-types/images/charts-by-types_hu_c84dac320db6994c.png","permalink":"http://localhost:1313/chart-catalogue-by-types/","title":"データ・タイプ別チャート分類"},{"content":"代表的な Visual Vocabulary を除いて、タスク別にチャート分類しているものをご紹介します。\nThe Data Visualization Catalogue The Data Visualization Catalogue\nData Viz Project Data Viz Project\nJuice Labs – Chart Chooser ExcelやPowerpointで利用可能なチャートをタスク別に分類しています。テンプレートファイルのダウンロードも可能。\nJuice Labs – Chart Chooser\nThe Visual Reference for Microsoft Power BI The Visual Reference for Microsoft Power BI\nThe Chart Chooser The Chart Chooser\nThe Chart Chooser The Slide Chooser Chart Chooser in MATLAB The Chart Chooser Dissected The Chart Chooser Dissected\nChart Chooser and Chart Designer Poster Graphic Cheat Sheet Graphic Cheat Sheet\nThe Graphic Continuum The Graphic Continuum\n公式デスクトップ版 公式ポスター版 ","date":"2020-08-28T00:00:00Z","image":"http://localhost:1313/chart-catalogue-by-tasks/images/chart_chooser_hu_32e5ee90f7bba6ac.jpg","permalink":"http://localhost:1313/chart-catalogue-by-tasks/","title":"タスク別チャート分類"},{"content":"（後日更新いたします）\n","date":"2020-08-28T00:00:00Z","image":"http://localhost:1313/splom/images/1_bPYf9c07ZBLRvgxCbCkPSQ_hu_bf8fcf963f6042d6.png","permalink":"http://localhost:1313/splom/","title":"散布図行列"},{"content":"階層データを可視化するチャートです。 ノードとリンクではなく、空間充填技術を用いて、親と子の関係を表現します。モザイクグラフよりも、より深い階層構造を表現することが可能です。任意の階層数にも対応可能な再帰的な構造が特徴です。各矩形の面積と色は、データセットの属性を表現しています。\n主な作例 FinViz S\u0026amp;P 500 Map\n2008年ごろのデザイン Treemaps: Data Visualization of Complex Hierarchies 株式市場へのTreemap適用例：FINVIZ.com Map of the Market Map of the Market 1998年から10年以上にわたって株式市場のライブデータを表示してきました。長方形の面積はその企業の時価総額に対応し、色で前回の終値から株価がどのように変化したかを知ることができます。「より読みやすく、対話しやすい表示」ため、正方形に近いタイルを作成する独自のアルゴリズムを開発したとのことです。\nNewsmap Marcos WeskampさんがFlashで実装した、株式市場ではなくニュースリーダーをテーマとしたツリーマップ。\nNewsmap Newsmap.JS Marcosさんのnewsmapにインスパイアされた作品をJSで実装。\nNewsmap.JS Every AlgoRiThm has ART in it: Treemap Art Project Treemap Art Project Truck Sales Slip, Tripping Up Chrysler Truck Sales Slip, Tripping Up Chrysler Stock Market Overview in Tableau Stock Market Overview in Tableau HistoryWired: A Few of Our Favorite Things SmartMoneyの「Map of the Market」をベースにしており、ユーザーが博物館のコレクションの一部を探索できるように設計されていました。現在のウェブ標準との互換性がなくなったため、2016年8月にサイトは閉鎖されました。\nHistoryWired: A Few of Our Favorite Things 誰が作ったのか 1990年、Ben ShneidermanとMaryland Human-Computer Interaction Labの学生たちが、空間充填技術を使ってファイルの階層を視覚化する方法として考案しました。\n1994 年に Mountaz Hascoet と Michel Beaudouin-Lafon が、「二乗化」アルゴリズムを発明しました（後に Jarke van Wijk によって普及しました）。\n1999年にMartin Wattenbergが、株式市場における可視化に利用しました。SmartMoney の “Map of the Market” というサービスのUIとして実装されました。その際は従来のツリーマップの欠点として二つをあげています。\nVisualizing the Stock Market 1.「スライス・アンド・ダイス」レイアウト “slice-and-dice” layoutでは、アスペクト比が大きすぎて比較が困難。なるべく正方形に近い矩形を創出するようにした。\n2.類似した企業やセクターを隣り合わせに配置したい。過去のレイアウト方法では、階層情報のみを使用していたため、それが実現できなかった。\nこれらを解消するアルゴリズムを独自に実装し「ピボット＆スライス」レイアウトと名付けています。\n類似する手法 モザイク・プロット（Mosaic Plot） ","date":"2020-08-22T00:00:00Z","image":"http://localhost:1313/treemap/images/Stock-Market-Treemap_hu_d86c84f825cd969c.png","permalink":"http://localhost:1313/treemap/","title":"ツリーマップ（Treemap）"},{"content":"フローレンス・ナイチンゲールによって開発された歴史に残るチャート、当時は、“coxcomb” 、現代では “polar-area diagram” というチャート類型として認識されています。\n端的にいうと、病院における兵士の死亡率は、実際の戦闘 （赤）やその他の原因（黒）で死亡したよりも、予防もしくは軽減可能な伝染病（青色）で死亡したことを示しており、当時のイギリス政府へ現状を訴えるために、データを自身で記録し、のちに制作したレポートに挿入されました。\nナイチンゲール自身が直接ヴィクトリア女王に接見できる身分だったり、知人の夫が当時の戦時大臣だったりしたこともあって、相談しながら行動を起こしているのですが、レポートの甲斐あって実際に改善されたということです。\n1854年3月、フランス、イギリス、サルデーニャ、オスマン帝国とロシアの間で戦争が勃発しました。戦争での戦闘のほとんどはクリミア半島で起こりましたが、負傷したイギリス軍は黒海を越えたトルコの病院に運ばれました。\nナイチンゲールは、ボランティア看護師としてほかの女性たちと一緒にトルコに同年10月に到着します。最初は病棟への立ち入りを拒否され、ナイチンゲールと仲間の看護師たちが患者との接触を許されたのは、病院が危機的な状態になった翌年1855年3月だったとのことです。\n負傷した兵士の環境を改善しようと努力していく中で、患者の福祉の重要性を示す証拠として、病院での死亡者数を綿密に記録しました。その結果を当時のイギリス政府へ訴えるために作られたのが、この著名なチャートでした。\n戦争が二年間に渡って行われたことをうけ、チャートの一つが一年を指します。右が一年目、左が二年目です。時計でいうと九時の箇所から始まり、時計回りにぐるっと一周すると一年間を一ヶ月ごとに示しています。一年目の終わりの箇所から点線が引き出され、左の二年目へとつながっています。\nよくみると、ナイチンゲールと仲間の看護師たちが患者との接触を許された1855年3月を境に、左と右、二つのチャートに分けていることが見て取れます。\n作品画像の左下に記載されている文章の日本語訳を以下に掲載します。\n青、赤、黒のウェッジの領域は、それぞれ中心から共通の頂点として測定されます。 円の中心から測った青いくさびは、予防可能または軽減可能な伝染病疾患（Zymotic Diseases）による死亡者の面積を、中心から測った赤いくさびは、負傷（Wounds and Injuries）による死亡者の面積を、中心から測った黒いくさびは、その他（All other Causes）のすべての原因による死亡者の面積を表しています。 1854年11月の赤い三角形の上の黒い線は、その月の他のすべての死因による死亡者の境界を示している。1854年10月、1855年には、黒の部分が赤と一致し、1856年1月、2月には、青の部分が黒と一致しています。 全体のエリアは、青、赤、黒のラインで囲まれているので、比較することができます。 the Causes of Mortality in the British Military during the Crimean War\nこれより以前に作成したチャートでは、面積ではなく、原点からの長さを数値で示しているため、その誤りに気づき、撤回されています。\n参考文献 UCLA Elmer Belt Florence Nightingale Collection Nightingale’s ‘Coxcombs’ | Understanding Uncertainty report by Hugh Small ナイチンゲールは統計学者だった！-統計の人物と歴史の物語- 丸山健夫2008.\n","date":"2020-08-14T00:00:00Z","image":"http://localhost:1313/nightingale-chart/images/Nightingale-mortality_hu_2131e9b3315c5193.jpg","permalink":"http://localhost:1313/nightingale-chart/","title":"ナイチンゲールによる「鶏冠」チャート"},{"content":"ライシャワー元駐日大使「ザ・ジャパニーズ」という著書の中で、彼自身が作成したというカルトグラムで描いた日本地図が掲載されています。原書は1978年、翻訳書は翌1979年に出版されています。\nE・O・ライシャワー「ザ・ジャパニーズ」 カルトグラムというのは、データ値を国や行政区域の示す面積に反映させ、データ値を地図として眺めることを試みる手法です。\nE・O・ライシャワーによる「国の大小が人口に比例して描かれている地図」 E・O・ライシャワーによる「国の大小がGNPに比例して描かれている地図」 ご本人はこのように説明しています。\n「その地図の一つは国の大小が人口に比例して描かれており、いま一つはGNPに比例している。筆者がこの二つの地図をはじめて考えついたのは、一九六四年のことであった。第二次大戦の敗戦が尾を引き、実勢をはるかに下回る評価を蒙っていた日本人に対し、日本がかなりの大国であることを指摘するのが、そのもくろみであった。」\nE・O・ライシャワー「ザ・ジャパニーズ」 アイデア誌（2007年9月号）の特集記事で、杉浦康平さんがインタビューに応じて、この地図からの影響を明かしています。\n「統計は全てのものを数量化し、デジタル化する。だから、庶民一人ひとりの生活感情は切り捨てられて、単なる一個の人間、生きるための消費エネルギーの数量化へと還元されてしまう。計量化しないと、統計図や主題地図というものは描けないんです。だから誰もが疑うことなく計量化し地図化することで、国の活力の全体像が掴めると思っていた。 ところが一方で、1965年に元駐日大使のE・O・ライシャワーによる国民総生産地図や人口地図のようなものが現れた。これはアメリカのGNPがいかに世界を制覇しうるほどに大きくなっているかの説明するための地図なのですが、同時に、主題をとりかえ見方を変えることで、見なれた地形がものの見事に変化し、動きうることを示す地図でした。動かない地表の地図ではなく、その上で人が生き、笑い、動き回って自分たちの文化を築いている、人びとのふるまいを映しだすような、動く地図の可能性があることを示してくれた。人間のアクティビティーを主題にした地図表現があるということ。じつに新鮮な、晴天の霹靂のような地図でした。」 アイデア誌（324 2007年9月号）\nライシャワーさんによる地図の主旨と杉浦さんの受け取りのすれ違い、現在からみるとある種ほほえましいですが、こういった刺激が直後の杉浦康平さんの素晴らしい時間軸変型地図をはじめとした主題地図群を生み出していったことにドキドキしますね。杉浦さんの上記のコメントは現在も古びることなく、むしろ今こそ改めて噛み締めたいものです。\n杉浦康平さんの時間軸変形地図。『時間のヒダ、空間のシワ…［時間地図］の試み─杉浦康平ダイアグラム・コレクション』鹿島出版会\n","date":"2020-08-14T00:00:00Z","image":"http://localhost:1313/reischauer-cartogram/images/%E3%83%A9%E3%82%A4%E3%82%B7%E3%83%A3%E3%83%AF%E3%83%BC_Japanese_GNP_hu_4dd222f594eb3e32.png","permalink":"http://localhost:1313/reischauer-cartogram/","title":"ライシャワー元駐日大使が日本に向けた眼差しとしてのカルトグラム地図"},{"content":"U.K.で利用されている、民間企業ZOEによる COVID Symptom Tracker というアプリがあります。これは体温、疲れやコロナウイルス感染の可能性のある他の症状を含む健康状態を日常的に記録するアプリで、利用者（当時で150万人、2020年8月時点で400万人）がアプリを通じて報告してきた症状をデータとしてとりまとめた結果がNature誌に紹介されていました。\nCoronavirus: the first three months as it happened\n「3月24日から29日の間に収集されたデータを分析したところ、COVID-19で陽性と判定されたユーザーは、ウイルスの症状はあるが陰性であったユーザーよりも、嗅覚と味覚の喪失を報告する可能性が三倍高かった。COVID-19の検査で陽性となった人々が経験するその他の一般的な症状は、発熱、持続的な咳、疲労、下痢、腹痛、食欲不振でした。」\nCoronavirus: the first three months as it happened\nNature誌に掲載されていたチャートがあまりに読みづらいのではないかと、Nilsさんという方が指摘しています。\nhttps://twitter.com/ngehlenborg/status/1250307095200555015\nhttps://twitter.com/ngehlenborg/status/1250307095200555015\n「パターンを見つけることはおろか、読むこともほとんど不可能です。」\nNilsさんはオイラー図と書いていますが、ベン図かもしれません。両者の違いは、オイラー図は現実にあり得る組み合わせのみを検討したものになりますが、ベン図は数学的にすべての項目を総当りで示すことです。六つの項目（症状）を総当りでベン図として示そうとすると、このように複雑にならざるを得ません。\nNilsさんが自分で別なチャートとして作り直してみたとのことです。\nCOVID-19による症状にはどのようなものがあるかということで、報告数が多い順に左から右へ並べられています。\nhttps://twitter.com/ngehlenborg/status/1250307072861720583\n同じデータを用いつつ、左からの並び順を、同時に報告された症例数が少ない順に並べたものです。一番左に症例が同時に一つのみのもの、その右が同時発症が二つの症例…、と続きます。こちらをみると、同時に発症することが少ない症状は何か、ということがわかりやすくなります。\nhttps://twitter.com/ngehlenborg/status/1250307087667572737\nこのチャートはUpSetと呼ばれるチャートです。Nilsさんが利用したツールはこちらにあります。これらをみると、実際に発症している人数が多い症状はどういうものなのか、同時に発症する症状はどういう組み合わせがありえるのか、がグッとわかりやすくなっています。\n","date":"2020-08-14T00:00:00Z","image":"http://localhost:1313/covid-symptom-upset/images/EVn7qUfVAAAF-uY-scaled_hu_4741d254f37e1967.jpeg","permalink":"http://localhost:1313/covid-symptom-upset/","title":"三つ以上の項目の重なりはベン図では理解できない…COVID-19の場合"},{"content":"ツリーマップに階層構造（親子関係）を可視化しますが、座標系がツリーマップとは異なり、極座標という座標系をとります。データ値は「矩形の幅と高さ」ではなく「半径と円弧の長さ」で示されます。面積は階層内での相対的なサイズとなります。一番中心が最も親の階層となり、外側へ一段階進むごとに一階層下のデータとなります。\n作例 わずか90社で人為的な地球温暖化の3分の2を排出 Just 90 companies caused two-thirds of man-made global warming emissions | Environment | The Guardian\n政府の形態 https://www.reddit.com/r/dataisbeautiful/comments/f4eky8/oc_forms_of_government_sunburst_chart/\nIBM WatsonによるPersonality Insights 作例はOprah Winfreyのツイートを元にした分析結果。\nPersonality Insights\nメルボルン モナッシュ大学での研究に使われたチャート 下図のサンバーストが半分になっているものを、彼らはサンダウン（Sun Down）と呼んでいる。\nInteractive Visualisation of Hierarchical Quantitative Data: an Evaluation\nコーヒーの味 サンプルのデータセットとして、階層構造（親子関係）のみを示している。\nSoftware development | Sunburst chart | Data Integration | Aculocity\nタンパク質をコードする遺伝子がクラスター化している割合を種ごとに示した https://www.researchgate.net/publication/335847129_Evolutionary_and_functional_patterns_of_shared_gene_neighbourhood_in_fungi/figures?lo=1\n他の呼び名 Radial Icicle、Radial Treemap、Ring Bracketなどと呼ばれることもあります。\n","date":"2020-08-11T00:00:00Z","image":"http://localhost:1313/sunburst/images/personality-insights_OprahWinfrey_hu_f691c19c37e08387.png","permalink":"http://localhost:1313/sunburst/","title":"サンバースト（Sunburst）"},{"content":"コロプレスマップは、行政区域の境界とデータ集計単位地区の境界が一致している前提でした。デイシメトリック・マップでは、これら二つの境界が一致させない処理をした地図を指します。\n理由として、アーサー・H・ロビンソンらは以下のことを挙げています。\nデータを入手するために用いた単位地区の大きさが非常に異なっていたり効果的でない場合 地理的に不連続な分布を示す事象 リモートセンシング画像などを利用して、テーマデータを面で表現するのにより適切な領域を設定します。その結果、元の行政区域がより小さく、そして適切な空間単位に分割されます。たとえば人口密度のデータであれば、住宅地として土地利用されているエリアのみを対象にしてデータを描画します。\n処理を自動化する地図の可視化アプリでは扱いづらいため、広くは利用されていませんが、科学分野の研究者が、クリティカルなGISの利用が必要なときに利用しているケースが多いようです。\n作例 リスボンの人口密度。コロプレス（左）とディシメトリック（右）。 https://www.arcgis.com/apps/Cascade/index.html?appid=fde9d5cc2716490faf1e861d171a6fdd\nウィーン市の人口密度。コロプレス（前者）とディシメトリック（後者）。 GIFアニメーションで切り替わるように処理されている画像\nhttps://anitagraser.com/2012/11/18/improving-population-density-maps-using-dasymetric-mapping/\nベオグラード市のデータを対象にした研究 (PDF) Dasymetric modelling of population dynamics in urban areas\nフロリダ州タンパにおけるコロプレス・マップ（左）とディシメトリック・マップ（右）の比較 https://www.epa.gov/enviroatlas/dasymetric-toolbox\n2011年 ロンドンの人口密度 Dasymetric map of London’s population density, 2011 – James Gleeson\n人口密度のマッピング。国勢調査データと土地被覆の統合 http://sites.tufts.edu/gis/files/2013/02/Nelson_Jason.pdf\nサンフランシスコ・ベイエリアの地図 https://www.usgs.gov/centers/wgsc/science/dasymetric-mapping?qt-science_center_objects=0#qt-science_center_objects\n誰が作ったのか 1911年にTyan-Shanskyが名付け、J.K. Wrightが有名にした、と wiki.gis.comにあります。\n以前の似た作例 Henry Drury Harness (1838)\nhttps://digital.ucd.ie/view-media/ivrla:45724/bookView#40a90816-2189-4a97-8c09-bb6c3ebf5c2b http://www.complexcity.info/files/2011/06/harness-1837-flowmap.pdf\n類似する地図 コロプレスマップ（Colopleth Map） 等充線図（Isoplethic Map）\n他の呼び名 特になし。\n参考文献 アーサー・H・ロビンソンら「地図学の基礎」\n","date":"2020-08-11T00:00:00Z","image":"http://localhost:1313/dasymetric-map/images/dasymetric-map-2048x1448_hu_71452f67199e79aa.png","permalink":"http://localhost:1313/dasymetric-map/","title":"ディシメトリック・マップ（Dasymetric Map）"},{"content":"ベクター・フィールド・マップは、連続的な位置において、多変量のベクター（ベクトル）を持ちます。幾何学的には各点は、方向と長さを持っています。この方向と長さを、グリフ（例えば、長さと幅にデータ値を反映させた矢印）を使用して、場の力と方向を示すための地図です。\nある点での（外向きの）拡散と（内向きの）吸収の傾向を予測するために使用することができます。\n作例 wind map Wind Map\nフェルナンダ・ヴィーガス（Fernanda Viegas）とマーティン・ワッテンバーグ（Martin Wattenberg）による個人的なアートプロジェクト。\nエネルギー源としての風の視覚化を目的としています。\n「目に見えない古代のエネルギー源が、私たちを取り囲んでいます。これは、世界の最初の探検を推進するエネルギーであり、将来の鍵となる可能性があります。」\n全米デジタル予測データベース（the National Digital Forecast Database）のデータを使用して、北米における風力を示し、1時間ごとに更新されています。 過去のエピックな日付へのリンクも用意され、その特定の日時の風の様子を再現することが可能です。\nEarth earth :: a global map of wind, weather, and ocean conditions\nキャメロン・ベッカリオ（Cameron Beccario）による個人作品。”wind map”にインスピレーションを受けて制作されました。数時間ほどのタイムラグがあるデータを反映しており、様々なデータを、様々な地図投影法で可視化しています。\n2008年9月1日のハリケーン・グスタフによる風速 https://www.wolfram.com/mathematica/newin7/content/VectorAndFieldVisualization/VisualizeWindVelocityData.html\n2Dベクトルフィールド可視化手法の比較 ある実験では、異なる可視化イディオムを６つ用意し、これに対する人間の応答を比較したものがあります。\nhttps://www.cs.unc.edu/Courses/comp715-s14/papers/laidlaw_vector_vis_user_study_01359732.pdf\nGRID: 通常のグリッド上のアイコン JIT: ジッタード・グリッド上のアイコン LIT: 油絵の概念を借用している可視化手法のレイヤー LIC: 線積分畳み込み OSTR: イメージガイド流線（積分曲線） GSTR: 規則的なグリッドにシードされた流線 誰が作ったのか 不明。\n以前の似た作例 コンピュータによるマイグレーション・マッピングの実験\n(PDF) Experiments In Migration Mapping By Computer\n類似する地図 特にありません。\n他の呼び名 Migration Maps\n参考文献 Katy Börner — Atlas of Knowledge Katy Börner — Atlas of Science Tamara Munzner — Visualization Analysis and Design\n","date":"2020-08-11T00:00:00Z","image":"http://localhost:1313/vector-field-map/images/null_earth_hu_bb9cc23fdd5d60e4.png","permalink":"http://localhost:1313/vector-field-map/","title":"ベクター・フィールド・マップ（Vector Field Map）"},{"content":"1983年にKruskal and Landwherによって開発されました。彼らの論文「Icicle Plots：Better Displays for Hierarchical Clustering」で発表されました。つららに似ていることからこのような命名になったとのことです。\nIcicle Plots: Better Displays for Hierarchical Clustering Icicle Plots 作例 dotMemory分析チャート dotMemory: a Memory Profiler \u0026amp; Unit-Testing Framework for .NET by JetBrains\nメルボルン モナッシュ大学での研究に使われたチャート Interactive Visualisation of Hierarchical Quantitative Data: an Evaluation\nCore Flow CoreFlow: Extracting and Visualizing Branching Patterns from Event Sequences CoreFlow-EuroVis17.pdf\n手描きのつららチャート Icicle Chart – Lamar Elimbo\n","date":"2020-08-09T00:00:00Z","image":"http://localhost:1313/icicle-chart/images/MonashUniversity_IcicleChart_hu_68f28e724c3e2d35.png","permalink":"http://localhost:1313/icicle-chart/","title":"つららチャート（Icicle Chart）"},{"content":"通常、行政区画単位によって集計されたデータを、色やテクスチャで表現する地図です。\nこういったコロプレス・マップの問題の一つとして、データをエンコーディングのための領域（行政区画）のサイズが、表現されるデータ量の認識に影響を与えることがあげられます。\nデータ値と地理的領域を混同するのを避けるために、データは絶対値ではなく正規化（例えば、密度、比率、平均）を使用することが推奨されます。\n色やテクスチャでデータ値を表現する際に、データをいくつかにグルーピングする手法が取られることがあります。これを階級分類といい、ヒストグラムにおけるビンとはまた別の概念です。階級分類の数と手法が、見た目に大きく影響を与えるため、その選択には作り手による細心の注意が求められますし、作り手が「嘘をつく」ことも可能ではあります。ですので階級分類の数と手法を凡例に掲載しておくことが望ましいです。\n階級分類数は、データの分類数として意味がある最適な数が求められる一方、大量の色を用いすぎても人はそもそも区別して認識できないため最大でも、マジックナンバー7に則れば5～9、5に則れば3〜7つほどに分類することが現実的でしょう。\n離散データを面（領域）として表現するため、行政区画という領域の分割方法が、テーマとなるデータとしてふさわしいかどうかも検討する必要があるでしょう。たとえば日本の首都圏における人の行き来を含めた経済活動であれば、島しょ部を含めた東京都のみだけでなく、首都圏や東京圏とよばれる周辺都道府県も含めて評価する必要があるでしょう。\n連続的な現象（例えば自然現象でいえば年間降雨量、気温など）は、その分布が政治的または行政的な境界ではないため、この方法ではマッピングすることはふさわしくありません。 その場合は、連続データを活用するための手法である、Dasymetric MapかIsarithmic Mapなどを利用してください。\n作例 過去7日間のアメリカにおける郡（county）別COVID-19人死亡者数 Covid-19 fatalities per capita by US County for the previous seven days\nイングランドとウェールズにおける人口密度 England and Wales population density\nイングランド・ウェールズにおける人口分散 おそらくイギリスの最も初期の人口密度マップです。\nDispersion of the Population in England \u0026amp; Wales\n人に対する犯罪地図 Andre-Michel Guerryによって1833年に作成されました。1825年から1830年までのフランスの犯罪を描いています。犯罪のレベルを表す7つの陰影があります。濃い色がより多くの犯罪がある県で、より白に近い薄い色が犯罪の少なさを示します。\n犯罪の多い順に県がランキングされ、地図上に番号で示されます。地図の下にランキング順に実際の犯罪数が示されています。\nCrimes contre les personnes\nアメリカにおける非雇用者 2009年 U.S. unemployment in 2009\nミレニアム開発目標マップ The Millennium Development Goals Map\n参考文献 Katy Börner — Atlas of Knowledge Isabel Meirelles — Design For Information ","date":"2020-08-06T00:00:00Z","image":"http://localhost:1313/choropleth-map/images/1_vCq7XE-jQGK_OxfmIUiA7w_hu_c586a0441334688e.png","permalink":"http://localhost:1313/choropleth-map/","title":"コロプレス・マップ（Choropleth Map）"},{"content":"一次元の散布図で、ドットは重なりません。ストリップ・チャートやヒストグラム、箱ひげ図などと同様に、分布を可視化するために使用されます。異なる点としては、データポイント一つひとつの大きさや色で、データ属性を表現することができ、存在感を確認することが可能です。一方、統計要約量は描かれません。\n作例 人種別世帯収入の比較 Educate Your Child\nアメリカの80都市で報告された銃窃盗事件（2010-15年） Reported Gun Theft in 80 American Cities, 2010–15\nタイタニック号の乗客 Alan Smith on Twitter.\nCOVID-19関連の検索語の推移 searchingcovid19\n","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/beeswarm-plot/images/searchingcovid19_2_hu_9f08d39ebf52463e.png","permalink":"http://localhost:1313/beeswarm-plot/","title":"ビースウォーム・プロット（Beeswarm Plot）"},{"content":"1つのドットが1つの観測値を表します。 個別の現象が、どのような地理的分布をしているのかを確認します。\n分布に注目するため、ドットの大きさをデータに連動して変更しません。付随して、データを階級分類しないことになります。\n何らかの質的特徴を確認するために、着色することもあります。\n見た目が似たドット密度マップは、何らかの集計値を表し、ドットの表示位置が実際の発生位置を表しませんので、その点で明確に異なるデータ地図といえます。\n作例 地元民と観光客 写真撮影場所の違い（東京編） Flickrにアップロードされた写真を分析し、フォトグラファーを以下のように3つのグループに分類し、撮影地点をそれぞれ異なる色の点で示しています。\n地元民（青い点）：同じ都市で1ヶ月以上撮影した人の写真 観光客（赤い点）：観光客は2つの基準によって定義されます。この都市で1ヶ月未満で写真を撮った人で、かつ別の都市の写真の枚数からそこの都市が地元であると推測される人の写真 未定義（黄色い点）：地元民か観光客かを判断することができなかった人の写真 Locals and Tourists #5 (GTWA #20): Tokyo\n地元民と観光客 ツイート場所の違い（東京編） Locals \u0026amp; Tourists – Tokyo\nRacial Dot Mapプロジェクト Racial Dot Map Project\n白人至上主義のリンチの歴史の地図 Map of White Supremacy’s history of lynchings\nJohn Snow’s map of cholera outbreaks ロンドン南部の1854年のコレラ流行を描いています。 コレラが、当時信じられていたように、空気感染の病気ではなく、水で感染する病気であると主張するための地図です。円で表されているのが水源で、個々の死亡者数はバーで表されています。ドット分布マップと比例シンボル・マップの手法の組み合わさったものといえそうです。\nJohn Snow’s map of cholera outbreaks\n問題点 同一の緯度経度を持つデータポイントが複数ある場合、注意が必要です。使用するツールによっては、同一の緯度経度であっても、重ならないように表示するアルゴリズムを採用しているものがあります。\n同一の緯度経度を持つデータポイントが複数あって上手く処理できなかったり、あるエリアに固まってまともに描画できない、などの場合、点のデータを面（サーフェイス）に変換する方法を使います。その場合、長方形や菱形、六角形などのグリッド化や、行政区割のデータを用いたりします。\n","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/dot-map/images/racialdotmap_hu_e2ec2aaf3f1f6c15.png","permalink":"http://localhost:1313/dot-map/","title":"ドット・マップ Or ドット分布マップ（Dot Map Or Dot Distribution Map）"},{"content":"1つのドットが複数の観測値の集計値を表します。集計値の単位は地図の作り手により調整され、例えば1000人を1つのドットで表すなどとします。凡例にそのことを示します。\nデータは、実際の発生位置ではありません。そのため、地図上のどこに配置するのかについて、メソッドや考え方が様々存在します。統計単位に該当する地物の重心や、地形や都市にとって意味のある地理情報に関連付けることが多い印象です。\n何らかの質的特徴を確認するために、着色することもあります。\n見た目が似たドット分布マップは、集計値ではなく観測値をそのまま表し、表示位置が実際の発生位置を表しますので、その点で明確に異なるデータ地図といえます。\n作例 2010年 アメリカでの国勢調査 – ニューヨーク・タイムズ Flashによる作成のため、現在閲覧することができません。2010年の国勢調査の結果を用いて、アメリカの人種と民族の分布を描いています。1ドット=25,000人です。前回2000年からの変化もわかります。\nMapping the 2010 U.S. Census — New York Times\nDencity — Ben Fry Dencity — Ben Fry\nThe map by Frère de Montizon, 1830 フランスの人口を行政区割によって表しています。\nThe map by Frère de Montizon, 1830\n参考文献 Isabel Meirelle — Design For Information 谷村 晋 (著), 金 明哲 (編集) — 地理空間データ分析 (Rで学ぶデータサイエンス 7) ","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/dot-density-map/images/dencity_ben_fry_hu_6d8d3fc11405f2cc.png","permalink":"http://localhost:1313/dot-density-map/","title":"ドット密度マップ（Dot Density Map）"},{"content":"離散データを階級分類して、シンボルの大きさという視覚的変数で表現する地図です。階級分類しないものは比例シンボル・マップと呼ばれます。\nシンボルの形状は円がよく利用されますが、円だけに限定されるものではなく、三角形や四角形も利用されます。円グラフが用いられる場合もあり、その場合はチャート・マップと呼ばれます。\nサイズは、表現されるデータ値に比例しますが、それが存在する地理的領域に依存しないため、コロプレスマップで発生してしまうデータ値と地理的領域の大きさの混乱問題を回避することができます。\n選択する階級分類数と階級分類の手法により、可視化される結果やその印象が大きく異なるため、作り手は探索的に色んな条件で試す必要があり、同時に最終的に作品が与える印象について責任を持つ必要があります。そして凡例として、階級分類数と階級分類の手法を示すのが望ましいです。\n作例 自然災害を避けるためにはどこに住むべきか\nWhere to Live to Avoid a Natural Disaster\n参考文献 Isabel Meirelles — Design For Information ","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/graduated-symbol-map/images/1_7DBQfNEPvNWGiIlMr2rLFw_hu_779d9c650b310d3a.png","permalink":"http://localhost:1313/graduated-symbol-map/","title":"等級シンボル・マップ(Graduated Symbol Map)"},{"content":"統計チャートを地図上に重ねて表示することで、地理的分布と統計的分析を同時に行うことを目指したものです。\n配置が上手くいかないことがあったり、比較が困難であったりと、今となっては一般的には使用を推奨することはありません。\n同様の意図を実現したい場合はスモール・マルチプルを利用することを検討してみてください。\n作例 ナショナルアトラス（日本国勢地図帳） 国および都道府県の歳入 ナショナルアトラス（日本国勢地図帳） 国および都道府県の歳入\n各地方からパリへ送られてくる食用牛肉の量 1858 map by Charles Minard\nPie Chart Map — Belfast http://cain.ulst.ac.uk/victims/gis/maps/gismaps-16.html\nBar Chart on a Map — Tableau https://www.dataplusscience.com/BarChartMaps.html\nPie chart on a symbol map — Tableau http://arunethan.com/?p=270\nパイ・チャート・マップ（Pie Chart Map） — ArcGIS http://desktop.arcgis.com/ja/arcmap/10.3/map/working-with-layers/drawing-features-to-show-quantities-drawing-pie-ch.htm\nhttps://www.e-education.psu.edu/natureofgeoinfo/c3_p17.html\nパイ・チャート・マップ（Pie Chart Map） — Coloremaps https://coloremaps.com/visualization-map-types/chart-maps/\n100 biggest cities in 2010 https://www.behance.net/gallery/4610471/100-biggest-cities-2010-infographic\nコラム・チャート・マップ（Columns chart maps） — Coloremaps https://coloremaps.com/visualization-map-types/chart-maps/\n参考文献 谷村 晋 (著), 金 明哲 (編集) — 地理空間データ分析 (Rで学ぶデータサイエンス 7) ","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/statistical-symbol-map/images/1064px-Minard-carte-viande-1858_hu_fb9199d2ee6d0b7f.png","permalink":"http://localhost:1313/statistical-symbol-map/","title":"統計記号マップ（Statistical Symbol Map）"},{"content":"どんな地図？ 離散データを階級分類せず、シンボルの大きさという視覚的変数で表現する地図です。階級分類するものは等級シンボル・マップと呼ばれます。\nシンボルの形状は円がよく利用されますが、円だけに限定されるものではなく、三角形や四角形も利用されます。円グラフが用いられる場合もあります（その場合、チャート・グラフと呼ばれます）。\nサイズは、表現されるデータ値に比例しますが、それが存在する地理的領域に依存しないため、コロプレスマップで発生してしまうデータ値と地理的領域の大きさの混乱問題を回避することができます。\n作例 大統領選挙の結果：ドナルドJ.トランプ氏が勝利 Presidential Election Results: Donald J. Trump Wins\nカリフォルニアの各郡（county）にはコロナウイルスの症例がいくつあるのか？ How Many Coronavirus Cases Are in Each California County?\n参考文献 Isabel Meirelles — Design For Information ","date":"2020-08-04T00:00:00Z","image":"http://localhost:1313/proportional-symbol-map/images/1_sVDldGcKHfB10ZU31PfgWg_hu_5d114fd199c30dbc.png","permalink":"http://localhost:1313/proportional-symbol-map/","title":"比例シンボル・マップ(Proportional Symbol Map)"},{"content":"ある文章に含まれる単語の重み付け（たいていは頻出度合い）をフォントサイズで表現します。起源は、1990年代後半にウェブサイトで一般的に使用されていたタグクラウドにあります。\n問題 その単語の元々持っている文字数による長さによる視覚的な影響を、重み付けが影響を受けてしまうことです。たとえ同じ重み付けであっても、元々の単語の文字数によって視覚的なインパクトは異なってしまいます。\nこの問題は、単語を円の中に配置し、円の面積で重み付けを表現すれば解決することが可能です。これらはWord Bubblesと呼ばれます。\nストップワード 通常、”です” や “しかし” などの非常に一般的でありながら、単語だけではあまり意味がない単語はあらかじめ取り除いておきます。こういった単語は総称して「ストップワード」と呼ばれます。\n辞書 また英語のように分かち書きではない日本語は、一旦文章を単語ごとに分割しなければなりません。その際、辞書を利用しますが、辞書が古いと近年活用されるようになった単語が抽出されないので注意が必要です。「くまもん」や「Apple Watch」ががうまく抽出できないでしょう。\n色 文字色として、定性的な情報（文字の属性値）を反映させることが可能です。\nツールによっては文字を見分けるためにランダムに色を割り振る例も散見されますが、色をランダムに割り振るべきではなく、何らかのデータ値に基づかせるべきでしょう。\n全体の形 ワードクラウド化した単語群の全体のなにかの形に模す作例もあります。この場合は文章の内容を表しているものが良いでしょう。\n単語へのインタラクション 単語に対してハイパーリンクを付与し、クリックをきっかけにデータセットをファセット分割するなどのインタラクションを付与してもよいでしょう。\nワード・クラウドの作例 Levitated | Emotion Fractal\nhttp://scimaps.org/mapdetail/visualizing_trends_a_155\nhttps://sebastianraschka.com/Articles/2014_twitter_wordcloud.html\nhttps://amueller.github.io/word_cloud/auto_examples/frequency.html#sphx-glr-auto-examples-frequency-py\nワード・バブルの作例 全国大会で使われた言葉 At the National Conventions, the Words They Used\n共和党大会で使われている言葉 At the Republican Convention, the Words Being Used\nこのグラフはどうなっているでしょうか？ What’s Going On in This Graph? – New York Times\n使われた言葉 The Words They Used – New York Times\n参考文献 Beautiful Visualization 第3章 Participatory Visualization with Wordle ","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/word-clouds-bubbles/images/State-of-the-Union-2_hu_776d3fb9fcfcb698.png","permalink":"http://localhost:1313/word-clouds-bubbles/","title":"ワード・クラウドとワード・バブル（Word Clouds \u0026 Word Bubbles）"},{"content":"ベン図ときくと、たとえばSQLデータベースにおいて、二つのテーブルを結合する際の、結合の仕方について説明した図を思い浮かべる方も多いと思います。\nFour different types of JOINs\n作者のジョン・ベンにちなんだ名称で、閉曲線（閉じた曲線で作られた閉じた図形）を使って集合理論的な関係を示す図として知られています。\nこの図に登場するデータセット（テーブル）は二つですが、登場するセットが最大3つまでであれば、これはベン図といえます。それ以上のデータセットにおいては、ベン図といえないかもしれません。\n同様のチャートで、レオンハルト・オイラーにちなんだオイラー図というものがあり、オイラー図とベン図の関係を図で示すとこのようになります。\nFour different types of JOINs\nつまり、より一般的なものがオイラー図であり、そのうちある要件を満たすものをベン図と呼びます。その要件とは「集合のすべての交差を示さなければならない」ということで、現実的にありえない組み合わせであっても数学的に示すことが求められます。\nFrom Data Visualization Handbook.\n四つのセットを対象にした際、現実的にありえる組み合わせのみを考慮すればよいオイラー図（左）と、すべての交差（組み合わせ）を示さなければならないベン図（右）の違いです。\n実際には、数学や論理学などの特定のトピックを除き、ほとんどの場合はオイラー図と呼ぶ図を使用することになりそうです。\n四つ以上のデータセットを対象にしたベン図 四つの場合 https://science.sciencemag.org/content/sci/324/5926/522.full.pdf\nhttps://www.gliffy.com/blog/venn-diagram-types-templates\nhttps://www.researchgate.net/publication/50304549_Exact_and_Approximate_Area-Proportional_Circular_Venn_and_Euler_Diagrams\n五つの場合 https://thenode.biologists.com/venn-euler-upset-visualize-overlaps-in-datasets/education/\nhttps://thenode.biologists.com/venn-euler-upset-visualize-overlaps-in-datasets/education/\n六つの場合 https://www.nature.com/articles/d41586-020-00154-w\nhttps://thenode.biologists.com/venn-euler-upset-visualize-overlaps-in-datasets/education/\n七つの場合 7 sets Venn Diagram (interactive version)\n参考文献 Exact and Approximate Area-Proportional Circular Venn and Euler Diagrams Data Visualization Handbook ","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/euler-venn-diagram/images/93480617_10157150544363201_5537643846042648576_n_hu_c0c900ecfacdfbae.jpg","permalink":"http://localhost:1313/euler-venn-diagram/","title":"オイラー図とベン図（Euler Diagram \u0026 Venn Diagram）"},{"content":"スロープグラフとは、異なるカテゴリーデータについて、定量値が2つの時点でどのように変化したかを示す、簡略化された折れ線グラフです。その結果、折れ線ではなく直線のみで構成されるため、通常の折れ線グラフよりも読みやすく、多くの系列が乱雑にならずに済みます。二軸はそれぞれ共通の値範囲を持ちます。\n三軸以上で構成される場合もありますが、折れ線グラフではなくあえてスロープグラフを使う意味を考え、わかりやすさを失わずに抑制的であることが求められます。\n色の属性は、別な異なるカテゴリーデータを用いるか、線としてプロットされた項目間の傾向を表すために使用されることもあります。\n作例 Edward Tufteの書籍に掲載の作例 Slopegraphs for comparing gradients: Slopegraph theory and practice\nニューヨーク・タイムズ紙 1960年から2004年までの乳児死亡率の比較 The New York Times \u0026gt; Health \u0026gt; Image \u0026gt; Infant Mortality Rates World Wide\nヘルスケアにお金を費やしても、人生が最も長くなるとは限らない Spending more on health care may not lengthen life the most\nアメリカの医療費 The Cost of Care National Geographic\nオランダの様々な州の経済データと雇用の伸びを示すグラフ A Slopegraph Update\n2007〜2013年におけるEU加盟国のGDP時系列変化 E. Tufte Slope Graphs contest\n","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/slopegraph/images/infant_mortality_hu_e1888ac236801510.gif","permalink":"http://localhost:1313/slopegraph/","title":"スロープグラフ（Slopegraph）"},{"content":"バンプ・チャートは、折れ線グラフの特別なタイプで、時間の経過とともに変化するランキングやパフォーマンスを比較し観察する際に利用します。その際、定量データを用いる際も、順序データへ変換して利用します。\nスロープグラフに似ていますが、スロープグラフは、（たとえ何らかの基準でソートされていたとしても）比較する定性データが、経年でどの位置にいるかを比較します。バンプ・チャートは順位を基準とします。\n作例 #Election2016 米大統領候補のTwitterバズ #Election2016: US Presidential Candidate Twitter Buzz\n過去20年間におけるアメリカで人気の犬種ランキング America’s favorite dog breeds for the past two decades, ranked\nワールドカップ・ランキング World Cup Ranking\nG20諸国別 CO2排出量ランキング Ranking G-20 Nations by CO2 Emissions\n1996-2013年の間で、最も人気のある20のウェブサイトを追跡 From Lycos to Ask Jeeves to Facebook: Tracking the 20 most popular web sites every year since 1996\n他の呼び方 Bumps Chart, Rank Chartと呼ばれることもあります。\n","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/bump-chart/images/Dogchangev4_hu_8be901fda2d61cd8.jpeg","permalink":"http://localhost:1313/bump-chart/","title":"バンプ・チャート（Bump Chart）"},{"content":"二つ以上のカテゴリーデータ（質的変数）を可視化するチャートです。表示エリアの長方形を、再帰的に垂直・水平に分割によって作成されたタイルで構成されます。\nこの一つひとつのタイルの高さと幅は、それぞれ別のカテゴリーデータの属性ごとの集計値を示しています。これによって、カテゴリーデータ間の関係を示すことが可能となります。タイルの色は、カテゴリーデータ間の関係の大きさを示すことも可能です。\nツリーマップとの違いとしては、モザイク・プロットは一階層のみのデータとなることと、縦横にカテゴリーデータの属性値を取ることがあげられます。\n作例 タイタニック号で事故に遭遇した人たち Data Visualization with R\nggplot2による作例 https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html\n識別テストへの回答結果 (PDF) Effect of Product Involvement on Panels’ Vocabulary Generation, Attribute Identification, and Sample Configurations in Beer\nHair and Eye Color of Statistics Students http://www.sthda.com/english/articles/32-r-graphics-essentials/129-visualizing-multivariate-categorical-data/\n他の呼び名 モザイク・グラフ（Mosaic Graph）やマリメッコ・プロット（Marimekko Plot）と呼ばれることもあります。\n参考文献 A Brief History of the Mosaic Display User’s Guide for MOSAICS ","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/mosaic-plot/images/image-27_hu_c246d68dbf4d517f.png","permalink":"http://localhost:1313/mosaic-plot/","title":"モザイク・プロット（Mosaic Plot）"},{"content":"沖積図（沖積グラフとも呼ばれます）は、時間の経過とともに、対象が合併したり分裂したりする様子を示すのに使用することができるチャートです。\nある時点における定量的な値（ノード）と、それらをつなぐ線（リンク）は、ノードの値を線の太さや色に反映させます。\nたいてい、横軸に時間の流れを示します。縦軸に対象の大きい順に並べられていることが多いでしょう。\nサンキー・ダイアグラムは時間の流れを表さないため、 沖積図とは明確に異なるチャートになります。\n作例 科学に起こった大きな構造的変化 過去10年間に科学に起こった大きな構造的変化を示しています。\nMapping Change in Large Networks\nゲーム・オブ・スローンズ(シーズン1-7)における所属の変化 A Game of Data Visualizations: Making Alluvial Diagrams Without Code | by Matthew Lunkes | Medium\nアフリカ都市の人口（1960年～2025年） AFRICA – Big Change / Big Chance\n","date":"2020-08-03T00:00:00Z","image":"http://localhost:1313/alluvial-diagrams/images/image-24_hu_e7d3f3e9b51bede2.png","permalink":"http://localhost:1313/alluvial-diagrams/","title":"沖積図（Alluvial Diagrams）"},{"content":"Mario Schmidt の調査によると、19世紀後半当時、新興工業国の技術者たちは、蒸気機関をさらに改良し、それぞれの用途に最適化するために、科学的手法を応用しようとしていました。蒸気機関の熱効率を分析するために、アイルランドのエンジニアRiall Sankeyによって、1898年に開発されました。\nEurostatではサンキー・ダイアグラムの意義をこう説明しています。\n「サンキー・ダイアグラムは、エネルギーの収支を視覚的に表現するための非常に実用的なツールです。エネルギー収支は、経済のさまざまなセクター（供給、変換、消費など）におけるさまざまなエネルギー商品（燃料、熱、電力、すなわち市場性のある形でのエネルギーキャリア）の貢献度と相互関係をエネルギー単位でまとめたものです」 Energy flow diagrams – Eurostat\nエネルギー収支でいう、エネルギー商品と経済活動という、インプットとその結果としてのアウトプットを説明し、かつ入出力が一対一対応していない大量の物事が関連している様を示しつつ、その仕組み（システム）を概観するのに向いているといえます。\nネットワーク・ダイアグラムの一種といえ、対象とする物事（エネルギーや経済活動など）をノードとし、その間の流量をリンクとして線の幅やときには色も用いて示します。\n明示的に時間軸を伴う流れを説明するチャートは別のチャート、Alluvial Diagramsを用います。サンキー・ダイアグラムは、インプットとその結果としてのアウトプットを説明しながらも、時間の情報は持ちません。有向グラフ的であり、矢印が一方向のみに向いていることのみを示します。\n時間が経つにつれて、熱バランス、エネルギー、マテリアルの流れの可視化に用いられ、1990年代以降はライフサイクルアセスメント（LCA）における「代謝」の複雑さを示すためにサンキー・ダイアグラムを頻繁に使用していると、 Mario Schmidt はレポートしています。\n近年では「インプットとその結果としてのアウトプット」を説明するチャートの特性を活かし、集めた税金とその使いみちに使われる事例がたくさんあります。\n過去、エネルギー関連をテーマに用いられてきた事例 20/30馬力のルノー車の走行速度60km/hの場合のエネルギー図 Source: Riedler, A. 1911. Wissenschaftliche Automobil-Wertung. Mario Schmidt. 2008. The Sankey Diagram in Energy and Material Flow Management.\nセメント製造における理論的な熱消費量（左）と実用的な熱消費量（右） Source: Schott, E. 1933. Waermewirtschaft in der Zementindustrie. Mario Schmidt. 2008. The Sankey Diagram in Energy and Material Flow Management.\nドイツの鉄鋼業のための鉄のフローチャート。鉱石中の鉄分100％に関連する数値 Source: Reichardt, P. 1937. Rohstofflage, Roheisen- und StahlSortenfrage. Mario Schmidt. 2008. The Sankey Diagram in Energy and Material Flow Management.\nエネルギーとマテリアルのフローによる管理 Source: Schmidt, H. 1936. Grundsaetzliche Fragen zur Rohstoffbewirtschaftung. Mario Schmidt. 2008. The Sankey Diagram in Energy and Material Flow Management.\n鉄鋼工場における材料の年間価値の流れを模式的に示す Source: Schmidt, H. 1936. Grundsaetzliche Fragen zur Rohstoffbewirtschaftung. Mario Schmidt. 2008. The Sankey Diagram in Energy and Material Flow Management.\n近年、エネルギー関連をテーマに用いられてきた事例 米国天然ガス 2019年の米国の天然ガスの供給（生産、輸入、貯蔵からの引き出し）と処理（消費、輸出、貯蔵への追加）の大きさを示しています。\nU.S. Energy Information Administration (EIA) – Issuestrends\n国際エネルギー機関（International Energy Agency） IEA Sankey Diagram\nEurostat Energy Flow Diagrams\nLMDI Decomposition of Energy-Related CO2 Emissions Based on Energy and CO2 Allocation Sankey Diagrams: The Method and an Application to China (PDF) LMDI Decomposition of Energy-Related CO2 Emissions Based on Energy and CO2 Allocation Sankey Diagrams: The Method and an Application to China | Sustainability\nLLNL – Energy Flow Charts アメリカにおけるエネルギーのリソースとその使用先を示しています。ローレンス・リバモア国立研究所（LLNL）が1970年代に開発したもので、彼らは独自にEnergy Flow Chartsと呼んでいます。\nLLNL – Energy Flow Charts\n動画によるEnergy Flow Chartsの解説\nThe flow of water in the hydrologic cycle The flow of water in the hydrologic cycle\n生産プロセスにおけるエネルギー効率化のための実践ガイド ‘A Practical Guide to Energy Efficiency in Production Processes’\nエネルギー以外の分野でも 2008年のスペインの主な収益と支出 Infographics Experts on Sankey Diagrams (Part 2) – Sankey Diagrams\nG07 – Environmental Migration 2013年から2015年までの自然災害による人の移動を示しています。各大陸で影響を受けた最初の4カ国を考慮に入れています。大陸・国・災害・被害規模を示しています。\nG07 – Environmental Migration\n気候変動ファイナンスフローの複雑性 The Complexity of the Climate Change Finance Flow\n外国人戦闘員のシリアとイラクへの旅路 G08 – Travel the Distance\n禁書 Banned books – Visualoop\n異形・変型タイプ EU28カ国における移民の最終的な庇護先の決定結果 Outcome of final asylum decisions by year, eu28 countries #frankensankey Migration: the riddle of Europe’s shadow populations トランプさんのツイートの怒りの矛先 サンキー・ダイアグラムかといわれると微妙ですが…。\nWho Trump attacks the most on Twitter – Axios\n参考文献 The Sankey Diagram in Energy and Material Flow Management – Schmidt – 2008 – Journal of Industrial Ecology – Wiley Online Library Sankey Diagrams – A Sankey diagram says more than 1000 pie charts ","date":"2020-08-02T00:00:00Z","image":"http://localhost:1313/sankey-diagram/images/image-13_hu_452cbff67099194.png","permalink":"http://localhost:1313/sankey-diagram/","title":"サンキー・ダイアグラム（Sankey Diagram）"},{"content":"「パラレル・コーディネイト（平行座標）」から着想を得ていますが、カテゴリーデータの頻度を表現していること、折れ線ではなく面で表現しているという違いがあります。2つ以上のカテゴリーデータの頻度を相対値（合計で100%になるように）で集計したデータを用います。\n研究開発チームの一人、Robert Kosaraによると、何らかの属性データ（たとえば沈没したタイタニック号に乗っていた人の集団に対して、一人ひとりの属性値）を可視化する手段が限られていたことをあげています。\n「扱おうとしているデータが離散的であるにもかかわらずビジュアライゼーションでのパラメータ(位置や長さなど)は連続しており、両者が不整合である 」 Beautiful Visualization 12章 表のツリー表現 P183-193\n少しやわらかく言い直すと、属性値自体は文字のデータ、年齢…大人か子供か、性別…男性か女性か、であり、これらを集計して扱う際には数値として扱う必要がでてくる、ということになります。またこういったデータは、名義スケールであり順序スケールではない、つまり順序に意味を持たず、さらには階層構造を持つことがあることも指摘しています。\nこのようなデータを可視化することができるチャートとしては、それまでツリーマップ（Treemap）とモザイク・プロット（Mosaic Plot）しか存在なかった、そしてParallel Setsは三番目のチャートだとRobertさんは述べています。\n一つの軸には一つのデータ属性を割り振る データを集合として表現するアイデア以外に、ParSetsは平行座標系(Parallel Coordinates)[Inselberg 2009] に大きな影響を受けています。平行座標系は高次元の数値データを表すためによく使われるビジュアライゼーションのテクニックです。値を表現する軸を平行にレイアウトして表示することにより、ツリーマップやMosaic Plotのような入れ子構造よりもデータの理解や比較が容易になっており、特に変数の数が多い場合に有効です。また、この種のレイアウトは、効果的なインタラクションをデザインするのが容易です。 Beautiful Visualization 12章 表のツリー表現 P183-193\n階層構造を表す 新しい視覚的構造を探し始めた のですが、そこでようやく我々が求めているのはツリー構造に他ならない(つまり、Standard 方式をとるべき)ということに気づきました。 Beautiful Visualization 12章 表のツリー表現 P183-193\n流れや時系列は表現しない 物事の流れや時系列変化の表現には使用しません。つなぐ線は直線、曲線のどちらもありえますが、流れや時間を示さないため、矢印は使用しません。無向グラフ的ということですね。\n一番優先度の高い軸の値に応じて着色 カテゴリーデータの値ごとに色が割り振られる場合があります。その場合は、一番重要な軸を一番上に配置し、そのデータ属性の値を色へ適用することが多いでしょう。チャートが入り組んできても、色を手がかりにチャートを探索することが可能となります。\n作例 ミネソタ州（上）とノースカロライナ州（下）の住宅データを比較 Kosara,Robert，FabianBendix, HelwigHauser(2006): “ParallelSets: Interactive exploration and visual analysis of categorical data”. IEEE Transactions on Visualization and Computer Graphics 12，no.4: 558-568.\n寒い気候の人々は、暖房燃料として電気よりもガスを好み、移動式の家もあまり好きではありません。南部の住宅は平均的にベッドルーム数がやや少ないが、3ベッドルームの一戸建て住宅は北部よりも多いことがわかります。\n国民戦線の躍進はフランスの伝統的な政党を揺さぶる｜フィナンシャル・タイムズ National Front breakthrough stuns France’s traditional parties | Financial Times\nピッツバーグの橋梁の構造材別、長さ別、建設年代別、橋梁が架かる河川別の内訳 Fundamentals of Data Visualization\nTRACKING THE EARTH’S 300 NANO-SATELLITES TRACKING THE EARTH’S 300 NANO-SATELLITES by Valerio Pallegrini\nドローンが空から落下してくるとき | The Washington Post When drones fall from the sky | The Washington Post\nRotem Blinder of IBM “Hierarchical Parallel Sets” Rotem Blinder – YouTube\nPANTHEON Corriere della Sera – La Lettura #181 PANTHEON Corriere della Sera – La Lettura #181\nNews Use Across Social Media Platforms News Use Across Social Media Platforms\nインタラクション マウスポインタのホバーなどでユーザーの興味を示すと、該当する面が強調表現（もしくは該当しない箇所の可読性を落とす）ことで、その面がどんなデータを取っているのかが見やすくなります。\nParSets ではインタラクションが重要な役割を果たしています。ユーザーがマウスカー ソルを重ねると実際の値が表示されるほか、属性や値の並べ替え、値の追加や削除も可能です。また、軸上の各属性は並べ替えることもでき、より大きな属性へと結合させることも可能です。例えば、すべての船室を結合させて船員と比較することができます。 Beautiful Visualization 12章 表のツリー表現 P183-193\n参考文献 Riccardo Mazza「情報を見える形にする技術」 P63 Parallel Sets VRVis: Parallel Sets: Visual Analysis of Categorical Data Bendix, Fabian，Robert Kosara，Helwig Hauser(2005): “Parallel Sets: Visual analysis of categorical data”. Proceedings of the IEEE Symposium on Information Visualization, 133-140.Los Alamitos, CA: IEEE Press. Kosara,Robert，FabianBendix, HelwigHauser(2006): “ParallelSets: Interactive exploration and visual analysis of categorical data”. IEEE Transactions on Visualization and Computer Graphics 12，no.4: 558-568. ","date":"2020-08-02T00:00:00Z","image":"http://localhost:1313/parallel-sets/images/image-15_hu_cb760654b877389d.png","permalink":"http://localhost:1313/parallel-sets/","title":"パラレル・セット（平行セット）」(Parallel Sets もしくは ParSets )"},{"content":"Fineoは、連続データを可視化するために利用されるサンキー・ダイアグラムの視覚モデルを元に、多次元のカテゴリカルなデータの、ディメンション間の関係を表現するために使うことができるのではないかという考えから生まれました。\nFINEO\nhttps://www.flickr.com/photos/densitydesign/albums/72157627029953749\nhttps://www.flickr.com/photos/densitydesign/albums/72157627029953749\nCRISP (Centro di Ricerca Interuniversitario sui Servizi di pubblica utilità alla Persona)の保持するデータセットを適用したもの\nつまり、カテゴリカルなデータ値を集計し、その間の関係を接続する線の幅と色で表します。ノードが黒い実線で、リンクが様々な色で着色された流れとその大きさを示す線で示されています。\nまた、リンクは明示的な方向を持ちません。サンキー・ダイアグラムが有向グラフを表現しているのに対して、Fineoは無向グラフを表現しているといえます。\nスタンフォード大の Mapping the Republic of Letters プロジェクトにて利用されているそうです（ただし内部的に）。\nMapping the Republic of Letters\n誰が作ったのか？ ミラノのデザインスタジオ、DensityDesign Research Labによって2010年に開発されました。\nDRMプロジェクトの一部として制作した静止画版を得て、これは二軸しかデータを保持できなかったことがあり、複数軸を持ち、かつインタラクティブに操作可能なものとして、Fineoの開発が進められました。\nDRM research\nhttps://www.flickr.com/photos/densitydesign/2655862596/in/album-72157624265861504/\nFineoはFlashで制作されWebアプリケーションとして公開されていたようですが、現在は公開終了しています。\nhttps://web.archive.org/web/20110711013919/http://fineo.densitydesign.org/custom/\n類似するチャート Fineoを開発したDensityDesign自ら述べている通り、また sankey-diagrams.com で論評がある通り、Parallel Sets (ParSets)とかなり似ています。\nFineo and ParSets\n違いとしては、Parallel Sets (ParSets)はデータを階層構造（ツリー）として扱うのに対し、Fineoはデータを（階層構造を持たない）ネットワークとして扱っている点にあります。\nParallel Sets (ParSets)は、最上部の軸をプライマリーとして、リンク部分の着色に利用されるほか、軸の並び順にデータを分割していきます。\nJason Daviesのd3.parsetsより\nただし、Parallel Sets (ParSets)作者のRobert Kosara自身はこう述べています。\n「Fineoのようにカテゴリカルデータのクロス集計に基づいてチャートを作成する場合、それはParallel Setsですが。同じモデル、似たような考えだ」\n筆者自身は、階層構造の内部を探索的に辿ることができるParallelSetsと、あるシステム全体を貫くカテゴリカルなデータの流れや存在感を把握するFineoは別のものだと考えています。ですので、現在Fineoが公開修了という状態は残念です（RawGraphsに引き継がれたとのことですが、インタラクティブなチャート生成という仕組みのみであり、Fineo自体はそれに含まれていません）。\n参考文献 DensityDesign Lab | Fineo Fineo and ParSets – Sankey Diagrams ","date":"2020-08-02T00:00:00Z","image":"http://localhost:1313/fineo/images/5950577682_6066025bc0_o_hu_19b8d949a657d9b7.jpg","permalink":"http://localhost:1313/fineo/","title":"フィネオ（Fineo）"},{"content":"人類学者のBrent BerlinとPaul Kayさんの研究成果 (Basic Color Terms: Their Universality and Evolution. 1969) として、\n「多様な文化を持つ世界の100以上の言語において、色の名称の発明順序がほぼ一緒」\nであったとしています。\n1, 2番め：白と黒 3番め：赤 4, 5番め：緑と黄、もしくは、黄と緑 6番め：青 7番め：茶 8-11番め：ピンク、紫、オレンジ、グレイ 原語では以下のとおりです。\nStage I: Dark-cool and light-warm (this covers a larger set of colors than English \u0026ldquo;black\u0026rdquo; and \u0026ldquo;white\u0026rdquo;.) Stage II: Red Stage III: Either green or yellow Stage IV: Both green and yellow Stage V: Blue Stage VI: Brown Stage VII: Purple, pink, orange, or gray これはデータ可視化の世界でも意味がある研究成果で、Colin Wareさんが、**\u0026ldquo;Information Visualization - Perception For Design\u0026rdquo;**の中で、データ可視化のコンテクストとして参照しています。そしてこのうち、1〜6番目の色（白、黒、赤、緑、黄、青）が、様々なカラーモデルの主要な軸を定義しているのは、これらの色が人間の生得的な性質によるものではないか、としています。\nColin Ware \u0026ldquo;Information Visualization - Perception For Design\u0026rdquo; の挿入図\nVoxがBerlinとKayさんの研究成果を6分ほどの映像にまとめていますので、そちらもぜひご覧ください。\nThe surprising pattern behind color names around the world | Vox\n","date":"2020-07-23T00:00:00Z","image":"http://localhost:1313/color-name-appearance/images/c736840e7ae1809abbe9ed7a2915627e_hu_57611b03625fb350.png","permalink":"http://localhost:1313/color-name-appearance/","title":"多様な文化を持つ世界100以上の言語において、色名の発明順序がほぼ一緒"},{"content":"\n配色の設計 ―色の知覚と相互作用（”Interaction of Color”）\nジョセフ・アルバースさんによる色彩の研究成果をまとめた書籍「配色の設計 ―色の知覚と相互作用（”Interaction of Color”）」は、彼のキャリアの晩年、勤めていたイェール大学から出版されています。\nこの中で、**「ウェーバー - フェヒナーの法則」（Weber-Fechner Law）**を紹介しています。これは、\n「等差数列的な変化を視覚的にとらえるためには、物理的には等比級数的に増えてゆかねばならない」（翻訳書より抜粋）\nことを示した法則です。等差数列と等比数列を補足します。\n等差数列（Arithmetical progression）…「はじめの数に、一定の数を足し算し続けて、その結果出来た数列」 等比数列（Geometric progression）…「はじめの数に、一定の数を掛け算し続けて、その結果出来た数列」 書籍中では、1.白い紙の上で、薄い黄色を塗り重ねていった場合、2.赤に黒を段階的に足していった場合の二例について、実際の結果が掲載されています。\nこれを概念的に示しているのが下の二画像です。横軸が時系列（重ね塗りした回数）になり、縦軸は少しややこしいですが左図がの場合は物理的事実、右図の場合は心理的効果の大きさ、という解釈になるかと思います。\n等差数列（arithmetical progression）で物理的に描かれたもの（左）は、過小評価、実際よりも削減されて知覚される（右）。\n等比数列（Geometric progression）で物理的に描く（左）ことで、やっと等差数列（arithmetical progression）のように知覚される（右）。\n実際の色の変化と、人間の知覚が、線形（等差数列）ではないことを示しています。\nジョセフ・アルバースさんによるこの書籍（配色の設計 ―色の知覚と相互作用）は1963年の出版。\n参照している「ウェーバー - フェヒナーの法則」（Weber-Fechner Law）は1860年の初出。\n近い内容を示す、「スティーヴンスのべき法則」(Stevens’ Power Law) は1975年の論文であり、「ウェーバー - フェヒナーの法則」よりもずっとあと、この書籍よりも少し後のことでした。\n","date":"2020-07-21T00:00:00Z","image":"http://localhost:1313/interaction-of-color-weber-fechner-kaw/images/Weber-Fechner-law_all_1_hu_e2ae182ace1ee301.jpg","permalink":"http://localhost:1313/interaction-of-color-weber-fechner-kaw/","title":"色の変化、その物理的事実と心理的効果の違い"},{"content":"数日前（2020年7月17日）こんなツイートがバズっていました。アメリカのジョージア州の行政組織が公開している公式COVID-19データ可視化コンテンツについての批評（デザイン上の操作への疑義）です。\n「最初（左）のマップは7月2日、二番目（右）は今日（7月17日）です。50％の増加が見えますか？どうやって隠しているか分かりますか？」\nhttps://web.archive.org/web/20200720003152/https://twitter.com/andishehnouraee/status/1284237474831761408\n（現在ツイートは、投稿者により非公開もしくは削除になっており、下記はいわゆる魚拓サイトへのリンクです）\n地図画像の下半分にある、データ着色のルール、つまり凡例に注目すると、凡例のルールが7月2日と17日で変わってしまっており、そのことによって、赤で表示される地域を過小評価されることを意図した改変ではないか、ということでした。\nこういった、地図におけるデータ値を視覚要素へ変換する際の数値の幅によるグルーピングのことを、**階級分類（英語ではClassification）**といいます。ヒストグラムにおけるビン（bin）は、それよりも小さい単位です。1階級に複数のビンが含まれるようなイメージです。\n今となっては元ツイートが非表示もしくは削除されてしまっているので、Twitter上でのリプライにどんなものがあったのか、わかりません。\n五年前から**PolicyVizという個人ブログサイトを運営しているJonathan Schwabishが、”Critiquing a Data Visualization Critique” （データ可視化批評を批評する）**と題して、件のツイートを批判する内容の記事を掲載しています。これを読むと、ツイートに対してヒステリックな反応が大量にあったことが伺えます。\n彼の論点整理によると、件のツイートの内容を以下の二つに整理しています。\n1.データの可視化は、ビンが変化している（筆者注：階級分類のこと）ため、州全体でのケースの増加を覆い隠しており、正しくなく、誤解を招くものである。 2.可視化を作成した人の意図は、意図的に誤解を招くようなことをした。 これに対して彼自身はこう反論しています。\n1.データ可視化提供者は地図を並べて表示しておらず、時系列に比較することを意図していない。 2.一般的に、私が不適切なデータや誤解を招くようなデータ可視化に出くわした場合、それが間違いか知識不足によるものだと考える。もちろん、明らかに誤解を与えようとしている、あるいは誤解を与えようとしているビジュアルの例は数多くあり、GDPH（Georgia Department of Public Health\u0026hellip;件のサイトのこと）も例外ではない。 その上で、階級分類の操作はツールが自動的に行ってしまうことがあり、別な人のツイートを参照し、たとえばTableauでは最小値・最大値にあわせて自動的に階級分類が調整されることが語られています。\nhttps://twitter.com/ugamarkj/status/1284486596235071489\nこれらを全部読んだ上での私の個人的な意見は、2はほぼ同意見ですが、1については、あまり同意できません。階級分類が動的に変わってしまうのはツールの仕様だとしても、誤解を招く恐れがあります。理由なくコロコロ変更すべきではありません。Tableauであってもツールの設定、たとえば最小値・最大値を決め打ちの固定値にしてしまえば避けられるはずです（多分）。\nまたこのデータ可視化提供者が地図の比較を掲載せず、また意図していなかったとしても、閲覧者がキャプチャをとって、地理的特性と時系列特性を同時に観て把握したいと思うのは自然な欲求であり、これを否定することは過剰反応であると思います。\n元ツイートに対するSNS上での反響を全くみていないのですが、少し感情的になってしまっているようにも思えます。**PolicyViz**は志もって運営している良質なサイトだという印象は今も変わりません。\n","date":"2020-07-20T00:00:00Z","image":"http://localhost:1313/critique-of-the-critique/images/coronavirus_georgia_hu_d13c3e2cd566b9e1.png","permalink":"http://localhost:1313/critique-of-the-critique/","title":"データ可視化への批評への批評への批評"},{"content":"コロナ禍は経済に大きなダメージを与え、それは日本だけでなく、他の諸国でも同様です。\n日本でいうところの日経平均にあたる、アメリカS\u0026amp;P500の時価総額の増減をツリーマップ形式で提供しているFinVizというサイトがあります。\nこれが本日（2020年7月20日）時点での市場の様子です。\nFinviz Maps\n右下に凡例があり、増減幅が、最大プラスマイナス3%で定義されています。これは、このサイトを運営していくにあたって、時価総額の増減が最大でも3%程度であろう、というところから来ています。\nところが、コロナ禍において、この凡例が破綻している時期がありました。\nhttps://web.archive.org/web/20200503183217/https://finviz.com/map.ashx\n上記は、5月3日時点のものです。全体的に真っ赤になっており、業種を選ばず時価総額が全体的に下がっていることがわかります。\nこのうち、AMZN（Amazon）が-7.6%の下げを記録していますが、凡例として-3%までしか想定されていないため、-3%（たとえばNVDA…Nvidia）と-7%の視覚的区別がつかない状態になってしまっています。\n凡例は、平常時における増減幅の想定であり、コロナ禍がその想定を軽く超えるくらい経済に影響があったことが、こんなところからもみてとれます。\n","date":"2020-07-20T00:00:00Z","image":"http://localhost:1313/corona-finviz-map/images/finviz_red-2048x1507_hu_129ce6ba3486eba0.png","permalink":"http://localhost:1313/corona-finviz-map/","title":"コロナ禍による凡例の破綻"},{"content":"データ可視化の有用性を示すために、 Anscombe’s Quartetが参照されることがよくあります。\nAnscombe’s Quartet\nこれは何かというと、要約統計量（平均、標準偏差、相関）が同一のデータセット4つが、実際に散布図として可視化してみると全く異なる姿を描くところから、要約統計量が同一もしくは近似していても、まずは一度は可視化してみるべし、というお話です。\nここで、発想を逆さまにして、要約統計量が小数点２桁まで同一でありながら、散布図化してみると様々な視覚的特徴を描くデータセットを生成するアルゴリズムを考えた人がいます。\nその名も The Datasaurus Dozen（12匹のデータ・ザウルス）。恐竜がモチーフになっているのは、Alberto Cairo氏のいたずらのような楽しめる投稿記事に由来します。\nDownload the Datasaurus: Never trust summary statistics alone; always visualize your data どうやっているのか\n共通の要約統計量を持つデータセットをゼロベースから生成するのは難しいと考え、既存のデータセットからスタートし、それらの統計的特性を維持しながら、望みの視覚的印象に近づくまで、少しづつ繰り返し修正を行う、というアプローチをとっています。\nAnimation showing the progression of the Datasaurus Dozen dataset through all of the target shapes. Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing Rのパッケージ化もなされています。R Studioで試してみた様子です。これはシミュレーションではなく、すでに算出されたデータを表示しているだけです。\n","date":"2020-07-11T00:00:00Z","image":"http://localhost:1313/the-datasaurus-dozen/images/AllDinosGrey_1-2048x1431_hu_6909f7c9de4f18f1.png","permalink":"http://localhost:1313/the-datasaurus-dozen/","title":"12匹のデータ・ザウルス"},{"content":"どんなチャート？ Tamara Munznerさんの “Visualization Analysis and Design”においての紹介文が的確なのでこれを引用します。\n『その名が示すように、軸は直角に垂直ではなく、互いに平行に配置される。散布図では、項目がドットで表示されるのに対し、平行座標では、1つの項目が平行軸をジグザグに移動するギザギザの線で表現され、関連する属性の項目の値の位置で各軸を1回だけ正確に横断します。』\nTamara Munzner “Visualization Analysis and Design”\n一見、折れ線グラフにも似ていますが、時系列データを扱っておらず、あくまで多変量の定量データを一度に表示することに特化したチャートです。\n設計意図と実際の活用のされ方のズレについても、Tamara Munznerさんの指摘が的確なので引用します。\n『平行座標の設計者による当初の動機の一つは、属性間の相関関係をチェックするという抽象的な作業に利用できるということでした。（中略）しかし、実際には、相関を見つける作業に使用するにはSPLOM（Scatterplot Matrix）のほうが簡単です。パラレル座標は、すべての属性の概要、個々の属性の範囲の特定、項目の範囲の選択、外れ値の検出など、他のタスクに頻繁に使用されます。』\nTamara Munzner “Visualization Analysis and Design”\n『平行座標によって容易に見えるパターンは、隣り合う軸の対の関係です。したがって、平行座標の決定的な制限は、軸の順序をどのように決定するかということです。ほとんどの実装では、ユーザが対話的に軸の順序を変更することができます。しかし、体系的な手動インタラクションを通して軸のすべての可能な構成を探索することは、可能な組み合わせの爆発的な数のために、軸の数が増えるにつれて法外に時間がかかるでしょう。』\nTamara Munzner “Visualization Analysis and Design”\n作例 1970年から1982年までに発売された車種についての、燃費（MPG）、気筒数、馬力、重量、発売年の相関 Parallel Coordinates | eagereyes\n3 つの種のアヤメの花による 4 種類の測定値 (萼弁の長さ、萼弁の幅、花弁の長さ、花弁の幅) parallelcoords | MathWorks\n主要研究領域における質の高い論文のシェア推移 一見折れ線グラフにみえますが、これも実はパラレル・コーディネイトなのです。\n中国の科学論文シェア急上昇　米国と「2強」に　日本は急落、3位が2領域だけ\n問題点 以下のような問題点・課題をかかえています。これらの課題を改善するためのインタラクションが実装されている場合があります。\n近く、もしくは隣接しない軸同士の直接的な相関がわかりづらい。インタラクションを用いて解決することが提案されています。 データをすべて、表示に利用すると、線が重なりすぎて視認性を損ねることがあります。 出力される画面解像度にも寄りますが、軸の数はせいぜい十数個程度が限界でしょう。 インタラクション 問題点を解決できるようなインタラクションが提案されていることがあります。\n軸の並び順と並び替え 軸の並び順ですが、データセットからデータを読みだした際の収録順、類似しているなどなんらかの基準を元にした並び順、属性名の五十音／アルファベット順などが考えられます。\n軸を並べ替えることができるようにすれば、ユーザーが知りたいと思う任意の属性を近くに並べることで、相関がわかりやすくなります。ユーザーが手動で行う、軸の性質に応じてなんらかの方法で並び順がシステムから提案されることが考えられます。\nブラッシング 軸ごとにブラッシングを行うことができるようにして、その範囲でデータをフィルタリングします。これにより探索的なデータ可視化が可能となります。\n軸の最大値と最小値の入れ替え（軸の上下反転） Robert Kosaraさんがブログ記事で可能性として提案しています。\n歴史的な作例 Alfred Inselbergさんによる論文以前に、作成されたチャートをここでは指すものとします。\nHenry Gannett “General Summary, Showing the Rank of States, by Ratios, 1880” Scribner\u0026rsquo;s statistical atlas of the United States, showing by graphic methods their present condition and their political, social and industrial development\nバリエーション 3D 3D Parallel Coordinates\n階層構造を持つ Hierarchical Parallel Coordinates for Exploration of Large Datasets\nラディアルなレイアウト 軸の配置をラディアルなレイアウトにすると、パラレル・コーディネイトというよりレーダーチャートですね。\nParallel Coordinates (circular layout + straight lines)\nフィジカルなインスタレーション Live survey on physical parallel coordinates.\nほかのチャートとのコンビネーション Force-Directed Parallel Coordinates Force-Directed Parallel Coordinates\nパラレル・コーディネイト + アーク・ダイアグラム パラレル・コーディネイト + アーク・ダイアグラム\nパラレル・コーディネイト + 散布図 パラレル・コーディネイト + 散布図\n誰が作ったのか？ 19世紀から、パラレル・コーディネイトと呼べそうなチャートは存在していました。ただ、コンセプトとして文書化されたものは、1981年、IBM研究者のAlfred Inselbergによるものです。\nA Inselberg. “N-dimensional graphics part I : Lines \u0026amp; hyperplanes”. Technical report, IBM Scientific Center, Los Angeles, CA., 1981. その後、論文として提案されるのは1990年ですが、同じ年に、統計家が単独で研究した結果を発表しています。\nA. Inselberg \u0026amp; B. Dimsdale：Parallel coordinates: a tool for visualizing multi-dimensional geometry Edward J. Wegman（統計家）による提案：Hyperdimensional Data Analysis Using Parallel Coordinates 他の呼び名 平行座標\n参考文献 A. Inselberg \u0026amp; B. Dimsdale：Parallel coordinates: a tool for visualizing multi-dimensional geometry\n","date":"2020-07-07T00:00:00Z","image":"http://localhost:1313/parallel-coordinates/images/1_3-NrFUaSTYJHquNYv0P6Ag_hu_1dca0457b5973866.jpeg","permalink":"http://localhost:1313/parallel-coordinates/","title":"「パラレル・コーディネイト」(Parallel Coordinates)"},{"content":"別名 ThemeRiver、Stream Graph、Stacked Graphs\n特徴 時間の経過とともに変化する数値を、総体と個別を同時に、流れとして把握できることを意図したチャート。流れとして全体感を把握するところから、名称にstreamやriverといった単語が用いられている。初出は2000年ごろで比較的最近登場したチャート。\nベースラインとしての水平軸が存在しないため、データの総体と個別が生み出す造形は、予想できない美しさと傾向や発見の手がかりを生み出す。\n議論 正確な数値の読み取りやすさが足りないと指摘する声もあり、視覚的な美しさと正確な数値の読み取りやすさのバランスについて、議論になることが多い。レイヤーをどの順序で積み重ねるかはアルゴリズム次第で、データのどの属性を用いるかによって印象は相当変わる。この点も、正確な数値の読み取りやすさのバランスについて懸念される原因の一つとなっている。\nディメンションやメジャー 時系列（ディメンション）…水平軸 数値（メジャー）…（水平・垂直軸を考慮した）面積 カテゴリー（ディメンション）…色（基本的にはベタ塗りが多いが、記号やテキストで埋め尽くす作例も存在する） ※チャート全体が90度回転させた場合は、時系列と数値の軸が逆になる。\n作例 「映画の辺境と流れ：ボックスオフィスの領収書 1986–2008」 The Ebb and Flow of Movies: Box Office Receipts 1986–2008\nStream graph of the most-played music month-by-month Stream graph of the most-played music month-by-month\nWhat A Hundred Million Calls to 311 Reveal About New York What A Hundred Million Calls to 311 Reveal About New York\n年代・性別・人種別一日の過ごし方 How Different Groups Spend Their Day\nEuro 2012 Streamgraph B-sides Euro 2012 Streamgraph B-sides\nTop Ten Cars in the UK Top Ten Cars in the UK\nミームトラッキングとニュースサイクルのダイナミクス Meme-tracking and the Dynamics of the News Cycle\n誰が作ったのか？ Susan Havreらが2000年に出願登録したThemeRiverという名称で論文を発表しています。\nThemeRiverTM*: In Search of Trends, Patterns, and Relationships それとは別に、last.fmのユーザー・リスニング履歴を制作したLee ByronとMartin Wattenbergによって、2008年に書かれた論文が存在します。\nStacked Graphs – Geometry \u0026amp; Aesthetics\nStacked Graphs – Geometry \u0026amp; Aesthetics\n現在はストリームグラフ（Streamgraph）と呼ばれることが一般的です。\n","date":"2020-07-07T00:00:00Z","image":"http://localhost:1313/streamgraph/images/1_8-t2eXWZyBAQ90tCjZEfvA_hu_d6a42387928740f4.png","permalink":"http://localhost:1313/streamgraph/","title":"ストリームグラフ（Streamgraph）"},{"content":"チャートのスタイルではなく、ビューのあり方の一つです。\nSmall Multipleとは、変化、違いなどを比較したい変数を一つ選び、それ以外のデータ変数やチャート表現はすべて揃えた上で、比較した変数のみが異なるチャートを並置する表示形式を指します。特定のチャートの名称ではなく、このような表示形態を指します。このような表示形態の結果、多次元の変数をもつチャートの比較が容易になります。\n複数のビューへとファセット分割（ファセットを利用して疎に分けること）したものを並置して表示する例の一つに、Tamara Munznerは位置づけています。\n誰が作ったか？ 作品形態としては1870年の作品など19世紀から存在していましたが、エドワード・タフテが著作の中で用語を定義し、一般に広く知られるようになりました。彼自身はこんな風にメリットを説明しています。\n『定量的な推論の中心にあるのは「何と比較するか？」という一つの質問です。多変量でデータが豊富なSmall Multipleデザインは、変化の比較、オブジェクト間の違い、代替案の範囲の比較を視覚的に適用することで直接答えます。データ提示の幅広い問題には、Small Multipleが最適な解決策です。』 Edward Tufte, “Envisioning Information”, 1990. 訳は筆者。\n質の比較 アメリカの州ごとの職業別人口の割合 おそらく最古の例としては以下の「1870年のアメリカの統計アトラス」(1870 Statistical Atlas of the United States)に掲載されている図版があります。1870年の国勢調査による、アメリカの州ごとの職業別人口の割合を示しています。並び順としては左から右へ、上から下へ、順に並んでいます。\nFrancis A. Walker, ”Persons with gainful occupations and attending school”, 1874.\nデビュー作から名作まで イギリスのModern Libraryによってランク付けされた英語の小説ベスト100の著者について可視化して作品です。一周が100年として円周に沿って時系列が設定されており、デビュー作と名作が生まれたタイミングを示しています。三角は生まれた年と亡くなった年と、作品が出版した年を結んで三角形を構成しています。そしてデビュー作と名作が生まれたタイミングを一つのチャートの中で出来るようになっています。一つひとつのチャートが一人の作家を示しており、作家ごとの人生における作品出版のタイミングを比較する意図で作成されています。\nFrom first published to masterpieces\nGitHubでアクティブなプログラミング言語は？ プログラミング言語別に、時系列でアクティブなリポジトリを比較しています。ここでの比較対象はプログラミング言語です。表示データを絶対数と相対数（割合）で切り替えるUIも用意されています。\nGiHut\n時系列の比較 アメリカと日本、出生率の時系列比較 こちらはエリアチャートを用いて、ある年の出生率を描いたものです。横軸が年齢、縦軸が女性の人数あたりの出生数です。時系列の変化に注目したので、どの年を対象とするかをづらして、並置しています。\n一年ごとにみている場合\n五年おきにみている場合\n量の比較／縦横両軸 バウチャーに対する公的なサポートの見積もり 横軸に収入、縦軸に人種をとり、公的バウチャー制度がどのくらいサポートされているかをコロプレスマップのSmall Multiplesで示しています。この場合、並び順は横軸と縦軸に対応するものとなっています。\nestimate of public support for vouchers, broken down by religion/ethnicity, income, and state.\n質ごとの時系列の比較／地理空間 赤vs青。共和党対民主党 大統領選の投票行動 1964-2012 ここでは、並び順は北米の州の位置関係をできるだけ尊重したタイル状のグリッドとして描かれています。\nSmall Multiple Tile Grid Map – Policy Viz\nスコットランドの政治が地理的にどのように変化したか タイトル通りの内容ですが、ひとつひとつがSankey Diagramというチャートになっています。さきほどの例と同様に、地理的な位置関係を尊重したタイル状のグリッドとして描かれています。\nHolyrood elections see rise of ‘Team Ruth’ and demise of Labour vision | Politics | The Guardian\n結果的に、擬似連続カルトグラム（Pseudocontinuous cartograms/Dorling cartograms）と表現的に近くみえる。\nインタラクティブ Jim Vallandinghamがインタラクティブ版Small Multipleについて考察しています。4つに分類しています。\nHow to Make Interactive Linked Small Multiples\n1. 更新可能 UIへのユーザーのアクションにより、利用データ自体が一斉に更新されること。\nHow Americans Spend Their Day\n2. ソート可能 Small Multipleの並び順自体を何らかの変数によって行い、さらに変更可能なこと。\nKepler’s Tally of Planets – Interactive Feature – NYTimes.com\n3. ハイライト可能 チャートの一部をハイライトすると、Small Multipleのほかのチャートの同一箇所も同様にハイライトされること。\nThe American Middle Class Is No Longer the World’s Richest – The New York Times EU unemployment tracker | FT Data 4. スクラブ可能 マウスポインタなどで示した箇所のデータ値が、そのチャートだけでなく、すべてのSmall Multiple内チャートで表示されること。\nHow the Tax Burden Has Changed – Interactive Graphic – NYTimes.com Ambulances for Dialysis Patients on Rise How Likely Is It That Birth Control Could Let You Down? – The New York Times ","date":"2020-07-04T00:00:00Z","image":"http://localhost:1313/small-multiples/images/03892018723903.5634a9e2d28bf_hu_200f4cd54c1c31b0.jpg","permalink":"http://localhost:1313/small-multiples/","title":"Small Multiplesとは何か？"},{"content":"どんな地図？ 統計チャート（円グラフや棒グラフなど）を地図上に配置することで、地理的分布と統計的分布を同時に把握することを目的とした地図です。地図の位置情報に限定したSmall Multipleともいえそうです。\n主な作例 ナショナルアトラス http://www.gsi.go.jp/atlas/atlas-etsuran.html\nPie Chart Map — Belfast http://cain.ulst.ac.uk/victims/gis/maps/gismaps-16.html\nBar Chart on a Map — Tableau https://www.dataplusscience.com/BarChartMaps.html\nPie chart on a symbol map — Tableau http://arunethan.com/?p=270\nパイ・チャート・マップ（Pie Chart Map） — ArcGIS http://desktop.arcgis.com/ja/arcmap/10.3/map/working-with-layers/drawing-features-to-show-quantities-drawing-pie-ch.htm\nhttps://www.e-education.psu.edu/natureofgeoinfo/c3_p17.html\nパイ・チャート・マップ（Pie Chart Map） — Coloremaps https://coloremaps.com/visualization-map-types/chart-maps/\n100 biggest cities in 2010 https://www.behance.net/gallery/4610471/100-biggest-cities-2010-infographic\nコラム・チャート・マップ（Columns chart maps） — Coloremaps https://coloremaps.com/visualization-map-types/chart-maps/\n類似する手法 チャート・マップではうまくチャートの比較ができない場合もあり、その場合はSmall Multiplesという手法を用います。\n参考文献 谷村 晋 (著), 金 明哲 (編集) — 地理空間データ分析 (Rで学ぶデータサイエンス 7) ","date":"2020-07-04T00:00:00Z","image":"http://localhost:1313/chart-map/images/1_bUT8E8oOLmX_my3TTFhHfA_hu_be2d8e0fcac31a0b.png","permalink":"http://localhost:1313/chart-map/","title":"チャート・マップ（Chart Map）とは？"},{"content":"2019年12月に開催したイベント「Data Visualization meetup 2019」にて筆者（矢崎）が登壇した際のスライドです。\n","date":"2020-06-26T00:00:00Z","image":"http://localhost:1313/data-humanity/images/dvj2019_yazaki_hu_fdb3d1858904b4c0.png","permalink":"http://localhost:1313/data-humanity/","title":"残された我々のための「データ・ヒューマニティ」"},{"content":" 筆者（矢崎）の修論公聴会でのスライドです。本修論をもってデザイン科学の修士を修了しました。\n","date":"2020-06-26T00:00:00Z","image":"http://localhost:1313/sender-oriented-vis/images/md_yuichiyazaki_hu_270d5ac841703e97.png","permalink":"http://localhost:1313/sender-oriented-vis/","title":"発信者主体の情報可視化作品作りにおけるスケッチの行い方考察"},{"content":"内閣府委託事業の一部として、2019年10月ごろに筆者が実施したリサーチレポートです。一般公開の許可をいただけましたので共有します。何かしらお役に立ちましたら幸いです。\n目次 自メディアでのコミュニケーション 民間のデザイナーを活用する オープンイノベーション 民間サービス ガイドライン整備 行政が考えるデータビジュアライゼーションの価値 データビジュアライゼーションの活用提案 ","date":"2020-06-24T00:00:00Z","image":"http://localhost:1313/world-gov-infoviz-report/images/gov_viz_hu_bbb157430550714c.png","permalink":"http://localhost:1313/world-gov-infoviz-report/","title":"世界の行政機関 情報可視化 事例"},{"content":"テレビで放映されたはじめての火星画像はデータドリブンな絵だった話を、当時の関係者からアーティストのDan Goodsさんが聞き出して記事化しています。初めてわかる事実も多いので、これを元に紹介します。\nDon Goods “FIRST TV IMAGE OF MARS, Interplanetary color by numbers” 彼の記事によると、火星を探索していた宇宙探査船マリナー4号から、火星の様子を撮影した画像データが、NASAジェット推進研究所（Jet Propulsion Laboratory）へ送られてきました。22のクローズアップイメージと520万ビットのデータは正常に送信されてきたのですが、コンピュータが計算して実際の写真画像として描画するまでには結構時間がかかることがわかりました。\nマリナー4号は3号の故障により急遽出番となったそうで、カメラの調子が万全かどうかわからなかったこともあり、テープに出力されていた生のバイナリーデータを基に、NASAの職員たちが手動で着色をはじめました。つまり送信データを画像化されることを待っている間に、データ値を元に、手書きで写真現像を始めたということです。この手法が、まさにデータ可視化の手法でした。\n地元の美術館へ行ってグレースケールのチョークを買いにいったところ、チョークは売っていないということで、かわりに売っていたカラフルなパステルを買って帰り、火星の実際の色味を知る前に、茶・赤のカラースキームで値ごとに着色する色を決め、塗っていったということです。\n画像の印象とは異なり、写真と見比べてもらうとわかりやすいのですが、暗い茶色が宇宙空間で、明るい茶色が火星の表面、その間にあるオレンジ色の部分は火星表面に漂う雲となっています。当初はマスコミにばれないように、武装警官に守られながらパテーションを設置して、着色していったそうですが、最終的にバレてしまい、テレビで放送されるに至ったということです。\nあるデータをいくつかに分類しその分類ごとに表現を当てはめることを階級分類といいます。定量データは慣習として、値が大きくなるごとに色の明度が暗くなっていきます。このNASAの職員たちが自分たちできめた着色ルールは、可視化の定番手法に合致しています。\nDon Goods “FIRST TV IMAGE OF MARS, Interplanetary color by numbers”\n","date":"2020-06-23T00:00:00Z","image":"http://localhost:1313/first-mars-on-tv-dataviz/images/1_FaYbeQRYIS7-C7hF-gNXYA_hu_c499cec82554cbac.jpeg","permalink":"http://localhost:1313/first-mars-on-tv-dataviz/","title":"はじめてテレビで放映された火星の写真は、データ可視化作品だった話"},{"content":"筆者が非常勤で半期受け持っている、多摩美術大学 情報デザイン学科 メディアデザイン三年生に聞いた「よかったデータ可視化／インフォグラフィック作品」をリストしました。従来のインフォグラフィックから、最近流行りのBar Chart Raceまで。まだ観たことないものがあれば、ぜひ楽しんでください。\nCalorieMate commercial from Japan - OyatsuCafe.com MONSTER HUNTER 10th Anniversary Monsters Size Comparison ドミノ・ピザ GPS DRIVER TRACKER https://www.dominos.jp/tracker/gps\n絵と言葉の一研究 「わかりやすい」デザインを考える 絵と言葉の一研究 「わかりやすい」デザインを考える\n100のインフォグラフィックで世界を知る 〈世にも美しい教養講義〉超図解・宗教 100のインフォグラフィックで世界を知る 〈世にも美しい教養講義〉超図解・宗教\nYouTubeチャンネル登録者数推移 https://twitter.com/kazuki8kki28/status/1217291500251279360\n【2009-2019】コミック別年間売上げランキング TOP10 https://www.youtube.com/watch?v=NQQT9U3xQio\nエイゴラボ エイゴラボ\nBASIC WINE GUIDE https://shop.winefolly.com/products/basic-wine-guide\nBeer\u0026rsquo;s Periodic Table https://visual.ly/community/Infographics/food/beers-periodic-table\nNO YOUTH NO JAPAN NO YOUTH NO JAPAN\n","date":"2020-06-23T00:00:00Z","image":"http://localhost:1313/recent-interest-art-school-2020/images/3minutesCalorieMate_hu_79e5abbf7b8605e2.png","permalink":"http://localhost:1313/recent-interest-art-school-2020/","title":"美大生に聞く、今気になるデータ可視化／インフォグラフィック作品"},{"content":"日本でも大いに話題になったワシントン・ポストによる「曲線を平らにする」ための啓蒙記事。主に制作過程について、まとめてみます。\nhttps://www.washingtonpost.com/graphics/2020/health/corona-simulation-japanese/ 記事内容の紹介 記事の公開は3月中旬。\n人口200人の町で、1人の感染者が現れたあと、ソーシャル・ディスタンシング（社会的距離）をどの程度とるかによって、事態がどのくらい変わってしまうのかをシミュレーションで示しています。\nYour browser does not support the video tag. https://www.washingtonpost.com/graphics/2020/health/corona-simulation-japanese/ より引用\n数理モデルには基づいておらず、ランダム（プログラムよる乱数）に過ぎません。また悲観的なことを表現したくないという意図から、人が死ぬ（減る）表現は省略されています。\nそのため、あくまでCovid-19ではなく、ニセの病気Simulitisをシミュレーションしたという体裁をとっています。\nソーシャル・ディスタンシングの取られ方で、4つのシミュレーションがなされています。\nhttps://www.washingtonpost.com/graphics/2020/health/corona-simulation-japanese/ より引用\nそして時系列での増減をエリアチャートでも示しています。このエリアチャートが、当時のキーフレーズだったFlattern The Curveをそのまま再現していたことから、キーフレーズの理解を促進したという側面もありました。\nだから、SNS上での、家にいよう、ソーシャル・ディスタンシングが大事だという呼び掛けの際にリンクが添付されることが多く、ワシントン・ポストのメディア・レポーターPaul Farhiのツイートによると、同紙史上最も読まれた記事となったとのことです。作者はまだ同社入社半年のHarry Stevensさんでした。\n制作過程 いくつかの記事から、制作過程を掘り起こしてみます。\nhttps://datajournalism.com/read/longreads/simulating-a-pandemic https://www.poynter.org/reporting-editing/2020/how-a-blockbuster-washington-post-story-made-social-distancing-easy-to-understand/ 1.プロトタイピング（3月上旬） コロナウイルスの広がりを視覚化する方法を模索していたグラフィックチームにそのアイデアを持ってきました。そのときのコードは公開されています。\n元々スタディしていたコード プロトタイプとして提示したコード 2.ジョンズホプキンス大学の研究者が作り上げた数理モデルを利用して可視化を検討したが諦めた ジョンズ・ホプキンス大学の准教授であるローレン・ガードナー（Lauren Gardner）さんの作成した複雑な数理モデルを可視化しようとしていたが、最終的には、複雑すぎてグラフィックによる説明は無理だと伝達。 実際のモデル計算を行うと、スーパーコンピュータで何時間も計算集中的な数学モデルを実行する必要があって一晩かかるようなものもあり、しかしそれでも、多くの不確実性が存在することを、ローレン彼に警告したとのこと。 そこで彼は、数理モデルを再現する方向のアイデアを諦め、ボールがランダムに移動するというシンプルなアイデアにこだることにしたそうです。 3.プロトタイピング 三回の変更を経て、完成版へたどり着いたとのことです。 一つ目のヴァージョンはユーザーのスクロールに合わせてテキストやグラフィックの塊が現れたり消えたりするストーリーテリングを使用していましたが、グラフィックが見づらくなっていました。 二つ目のヴァージョンは、ドットがSimulitisから回復しないようにしたもので、荒涼とした感染症の暴走を引き起こしました。 ほぼ十数人の人々からのフィードバックを集めた後、40～50時間かけて記事を仕上げ、最終的な作品に着地しました。 シミュレーションが仮想ウイルスで死ぬ人々を示していないのは、意図的に行ったとのことです。グラフィックチームは、すべてのドットが死んでいくことで不必要に暗い視覚化を望んでいませんでした。 画面上部のエリアチャートの方は、データ収集の精度が最も高いと判断して、ジョンズホプキンス大学のCOVID-19データセットを選択しました。 反響 電子メール、Facebook、Twitter、LinkedInを通じて受け取った何百ものメッセージに今も対応しており、多くの人が、可視化-社会的な距離感がどのように「曲線を平坦にする」ことができるかを見て、実際にコロナウイルスに対する不安を鎮めたと言っています。\n読者が自発的に翻訳してから新聞がそれを校正してくれたおかげで、ストーリーは13か国語で利用できるようになったとのことです。\nオバマ前大統領は1億1400万人のフォロワーにこの話をツイートし、13万5000のリツイートを生み出しています（2020年6月20日現在）。\nXユーザーのBarack Obamaさん: 「Watch this. It shows why we should all do the right thing and stay home to the fullest extent possible. All of us can help slow the spread of the virus, protecting the elderly, the vulnerable, and each other.\n","date":"2020-06-20T00:00:00Z","image":"http://localhost:1313/wp-corona-simulation/images/corona-simulation_hu_1d29be270cd3567c.png","permalink":"http://localhost:1313/wp-corona-simulation/","title":"ワシントン・ポストによる「曲線を平らにする」ための啓蒙記事の制作過程"},{"content":"データジャーナリズムにおける第一人者であるサイモン・ロジャースが提唱しているワークフローを紹介します。明確なステップに分かれていないため、筆者による意訳が含まれています。\n入手データの精査…ブレイキングニュース、定期的に行われるイベント、探求される研究、その他データなど、シェアされたデータについて、「何と比べるべきか・どんな変化を示すべきか」「データにはどんな意味があるか」「どんな他のデータと組み合わせるべきか」といった点を精査する データのクレンジング…「間違ったフォーマット、マージされたセル、不必要な列、異なる単位の混入」をクレンジングする データに対する計算…結果に対する検証、必要に応じて再計算を行う 公表…「社内グラフィックチームによる可視化」「フリーツールによる可視化」「そのまま公表」「読み物コンテンツ」などの手段による公表 オリジナルの初稿は2013年に公開されたもので、かなり初期の提唱であることがわかります。図化はご本人ではなく、Mark McCormickさんが担当しました。\n","date":"2020-05-26T00:00:00Z","image":"http://localhost:1313/simon-rogers-workflow/images/guardian-data-workflow-001_hu_397e82f7412cdca3.jpg","permalink":"http://localhost:1313/simon-rogers-workflow/","title":"サイモン・ロジャースの提唱するデータジャーナリズム・ワークフロー"},{"content":"研究者のKaty Boernerさんがデータ可視化のワークフローとして「ニーズドリブンなワークフロー設計」を、著書Atlas of Knowledgeの中で提案しています。以下の四大タスクを順に行っていく想定で、フィードバックを踏まえて、完成度が上がるまでグルグル繰り返すこともある想定です。\n取得（Acquire）…ユーザーのニーズ分析とデータの取得と準備 分析＆ビジュアライゼーション（Analyze \u0026amp; Visualize）…データを読み取り、計算アルゴリズムを適用してデータを視覚的な洞察に変換する デプロイ（Deploy）…出力デバイスの選択、インタラクティブなユーザーインターフェイスの設計 解釈（Interpret）…視覚化の解釈と検証を行う ワークフロー全体が、ユーザーのニーズからスタートすることと、「データの編集、分析、および視覚化にユーザーを参加させることが、結果の正確性と関連性を確実にする唯一の方法」だとしています。\n","date":"2020-05-22T00:00:00Z","image":"http://localhost:1313/katy-boerner-workflow/images/AofK_Workflow_hu_1d8f80b6d0bc0167.png","permalink":"http://localhost:1313/katy-boerner-workflow/","title":"Katy Boernerさんの提案する「ニーズドリブンなワークフロー設計」"},{"content":"MITの研究者デブ・ロイさんが研究として、人が生まれてから、言語を獲得していく様子をすべて動画として記録し、あとで分析できたらどんなことがわかるか。\nビッグデータの性質の一つ、リアルタイムに近い記録タイミングでデータを保存しつづけるため、結果テラバイトなどの膨大なデータ量になる、全量データの取得という方法論があります。\n人の行動記録を全記録することでそこから新しい事実がわかるのか。時系列の生データから、こどもの言語習得の過程を分析的に把握することができるか。\nTEDでその結果を発表しています。\n自分の子供が生まれたタイミングで、自宅のすべての部屋の天井にカメラとマイクを設置。赤ちゃんがどうやって言語を習得するのか解明すべく、その記録は3年間に及び、9万時間の映像、14万時間の音声、ファイルサイズは200テラバイトにもなったとのことです。\nたとえば「ウォーター」（水）と最初は発話できず、「ガガ」としか言えないのが、正確な発音の「ウォーター」になるまでの半年間の言葉の変化の軌跡を、連続的に把握することが可能になりました。また習得には一緒にいることが大きくかかわっていたとのこと。緑色が大人の動線で、赤色が子供の動線です。\nウォーターをはじめ、最初の二年で覚えた単語を、覚えた順に並べてみたそうです。\nすべての単語に言える話として、そこにいた大人が三人とも、子供が話せるようになるまではできるだけシンプルな言葉使いをし、子供が話せた瞬間から、無意識的に大人が使うような複雑な言い回しに戻ってたということがわかったそうです。つまり、子供の話し方自体が周りの人へも影響を与え、子供が言葉を話せるようになるフィードバックループをいつのまにか作り上げていた、と。\nこの三年間で、子供が「ウォーター」と発音した回数を、自宅空間にプロットしてみると、やはりですが台所であることが多かったり、玄関で「バイ」が多かったようです。\n","date":"2020-05-20T00:00:00Z","image":"http://localhost:1313/ted-birth-of-word/images/The-birth-of-a-word_2_hu_ea8db57bf433ca9.png","permalink":"http://localhost:1313/ted-birth-of-word/","title":"人が言葉を覚えるとき"},{"content":"BuzzFeed Newsが報じた2016年の記事で、アメリカ連邦政府機関のFBIやDHSが、スパイ目的で飛行させていた約200機の連邦航空機の機種を特定し、飛行追跡ウェブサイトFlightradar24が収集している航空機の位置情報データから、対象機種のみを絞り込み、地図に可視化してみたところ、スパイ飛行している機体の飛行パターンがはっきりわかったと報じました。\n左の画像は容疑者の後を追っていると思われる飛行機、右の画像は旋回を繰り返しているところ。https://www.buzzfeednews.com/article/peteraldhous/spies-in-the-skies より引用。\n特徴としては、以下があげられるとのこと。\n（週末を除く）平日のみ、数十機の米政府専用機がアメリカの都市の上空をゆっくりと旋回している。 ほとんどの飛行機は小型で、地上1マイル（1.6km）ほどの高さを飛行しており、多くの飛行機はエンジンの音を消すために排気マフラーを使用しているため、スパイをしていることはわかりづらい。 FBIとDHS（国土安全保障省）の捜査官が操縦するこの飛行機には、高解像度のビデオカメラが搭載され、多くの場合「拡張現実」ソフトウェアを使って、通りや会社名から個人の家の所有者まで、あらゆるものを映像に重ね合わせることができた。 少なくとも数機の飛行機には、下にいる人の携帯電話を追跡できる装置が搭載されていた。 たとえば2015年12月にカリフォルニア州サンバーナーディーノで起きた大量銃乱射事件。それまでそのエリアで飛行機が周回することはなかったのですが、テロ事件の後、90分以内に、2機の飛行機（1機はFBIのセスナ機、もう1機はDHSの偵察機）が現場を旋回していました。\nFBIはBuzzFeed Newsの取材に対して、人種、民族、宗教に基づいて捜査を開始することは出来ないと語ったが、飛行機の飛行パターンをみていると、犯罪容疑者個人ではなく、特定宗教の人口が多い他の地域の上空を旋回する機体もあったことがわかりました。\nそれらの航路を地図上に示し、旋回の様子が明らかになりました。\nhttps://www.buzzfeednews.com/article/peteraldhous/spies-in-the-skies より引用。\n機種が不明なスパイ機をランダムウォークで特定 調査報道はこれだけでは終わらない。後追い記事も公開しています。そこでは既知のスパイ機だけでなく、正体を隠すために架空の会社に登録していた飛行機があることもわかったため、既知の飛行何千もの飛行パターンを用意。飛行特性を記述するために、旋回率、飛行した速度と高度、各飛行経路の周りに描かれた長方形の面積、飛行の持続時間、航空機メーカーや機種、航空機のトランスポンダから発せられる4桁のscoawkコードの情報までを用意しました。\n「ランダムフォレスト」と呼ばれるアルゴリズムを用いて、これまでに同定された「100機近くのFBIとDHSの飛行機」と「500機の無作為に選ばれた飛行機」の2つのグループの特徴を区別するため、モデルのトレーニングを行いました。そのモデルを使って、全ての飛行機を評価し、各飛行機がFBIとDHSによって飛行された飛行機と一致する確率を算出したとのことです。\nhttps://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes より引用。\nリンク先の記事に、そこでわかった中で最も興味をそそられる5つの事例が紹介されています。\n","date":"2020-05-20T00:00:00Z","image":"http://localhost:1313/buzzfeed-spyfly/images/BuzzFeed_SpyFly_hu_4d61503c4a9296cd.png","permalink":"http://localhost:1313/buzzfeed-spyfly/","title":"全飛行機の飛行情報からスパイ機を特定したBuzzFeedのデータジャーナリズム"},{"content":"311発生から、普段の5倍以上のツイート量が日本でなされました。家族、友人、知人へ安否を確かめるコミュニケーションが飛び交っていました。\nTwitter社内のConsumer Data Science担当のミゲルさん（Miguel Ríos）がツイートデータを用いて、311発生一時間後の、日本にまつわるツイートをデータ可視化した作品映像を作成、公開しています。\nVisualization: RTs (Archive) 正確には、日本から発せられたオリジナルのツイートがピンク、そのツイートがリツィートという形で拡散されたものがグリーンで、ダークグレイのベースマップ上に示されています。\nVisualization: RTs (Archive) リンク先で動画が視聴できます。\n公式ブログ ","date":"2020-05-19T00:00:00Z","image":"http://localhost:1313/twitter-global-pulse/images/5884626815_d851598b9a_c_hu_43eaa9b44f364424.jpg","permalink":"http://localhost:1313/twitter-global-pulse/","title":"311の際の世界からの応援ツイート"},{"content":"AirBnBがOSS（オープンソースソフトウェア）のBusiness Intelligenceツール、Supersetを公開しています。\nなぜAirBnBのような会社がなぜBIツールを作ったのか？というところですが、公式ブログによると、「すべての従業員がデータに基づいた意思決定を行えるようにする」というのが、原理的信念の一つだから、とのことです。\nその際、データ民主主義に伴う課題の1つとして、さまざまなレベルのデータリテラシーを持つユーザーがデータにアクセスできるようにすることだとして、そこでSQLが一つの障壁になるということと、単にSQLが実行できるだけでなく、インサイトを探索して発見する必要もあるところから開発された。そのため、ユーザーインターフェイスとしては下記の２つを持ちます。\nデータへの高速かつ柔軟なアクセスを可能にするリッチSQL IDE (インタラクティブ開発環境) データテーブルをリッチな視覚的洞察に変換するデータ探査インターフェース 最初はハッカソンから誕生し、徐々にコミュニティドリブンに多機能になっていっているとのことです。\n開発を主導したのは、Apache Airflowなども開発した、Maxime Beaucheminさん。\n講演の際、Maximeさんは、\nApache Druidと組み合わせてリアルタイムデータ可視化できるBIツールが存在していなかったから。 どんなデータベースとも接続できて、D3.jsを使った可視化の制作負荷を下げたい。 ダッシュボードとライフサイクルはとても短いため、Supersetが役に立つ（筆者注：おそらくOSSという意味で）。 とも挙げています。\n関連リンク\nApache Superset How Superset and Druid Power Real-Time Analytics at Airbnb | DataEngConf SF \u0026lsquo;17 - YouTube Superset: Scaling Data Access and Visual Insights at Airbnb ","date":"2020-05-19T00:00:00Z","image":"http://localhost:1313/airbnb-superset/images/bank_dash_hu_3aa4712e1983dbe3.png","permalink":"http://localhost:1313/airbnb-superset/","title":"AirBnBが開発したOSSのB.I.ツール、Superset"},{"content":"2010年の作品で、まだケンブリッジ・アナリティカの件で個人情報が問題になる前の話。インフラエンジニアのインターンできていた人が、試作としてデータウェアハウスからデータを取得し、世界中の友達のつながりを約1000万組、世界地図への可視化を試みています。\nVisualizing Friendships\n当初はまともに、個々人の住んでいる場所を点で描画し、それらを線でつないだそうですが、つながりの数が多すぎてまともな描画にならなかったそうです。\nそこで個々人として扱うのではなく、その人が住んでいる都市同士の繋がりとして扱うことにして、そのつながりの強さを、都市間のユークリッド距離と都市間の友達の数の関数として定義し、つながりに重みをつけて、線の太さと色を調整し、重なり順にも反映させたら描画が上手くいったとのこと。\nいわゆるベースマップは表示せず、テーマデータの描画だけで世界地図が浮かび上がっています。\n最適な線の太さや色の濃さなどの表現は、最終的な出力先＝画面解像度をはじめとした環境に依存します。一般的なディスプレイサイズと、展示やプロジェクションマッピングの場合には最適な美しさというのは異なってきます。解像度もそうですし、鑑賞者がどの距離からどの角度で眺めることになるのかにも依存します。\nビッグデータの可視化といったときに問題になるのがこの点です。データ量が膨大の場合、1.概観と詳細のビューを分ける、2.データ自体をあらかじめ絞り込む、3.画面にデータ全体を一度に描画することは諦め、スクロールを前提にする、などが考えられます。\n","date":"2020-05-19T00:00:00Z","image":"http://localhost:1313/friendship-facebook/images/163413_479288597199_8388607_n_hu_d63deb8ea6497189.png","permalink":"http://localhost:1313/friendship-facebook/","title":"Facebookで友達のつながりを可視化"},{"content":"数年前、モサック・フォンセカというパナマの法律事務所から大量の機密文書が流出しました。タックスヘイブンなどでの企業設立支援を扱う法律事務所として有名だったことから調査報道に値するのではないかと「国際調査報道ジャーナリスト連合」（ICIJ）が流出文書を元に調査を主導、データのラングリングを行い、世界中100の報道機関の記者とコラボレーションを行いました。いわゆる「パナマ文書」として知られている調査報道です。\n流出文書の全体的なファイルは、モサック・フォンセカが1977年から2015年の長い間に渡って作成・収集したほぼすべての文書、合計ファイルとしては2.6テラバイト、1,150万ファイル。ファイルの種類も多様で、スプレッドシート、電子メール、PDFからもはや使用されていない曖昧で古いフォーマットまで存在したとのこと。\nデータ量がビッグデータとも呼べるサイズで、構造やつながりを維持していない。この状態から如何に、調査報道を記者が行ったり、一般人が気軽にブラウズできる状態を作り上げたのでしょうか。\nICIJのメンバーでデータユニットのリーダーであるMar Cabraがインタビューに応えて明らかにしています。\nモサック・フォンセカから流出した文書は、構造やつながりを維持しておらず、リバースエンジニアリングを行っていったとのこと。まずはOCR化、そしてデータベースに保存して検索できる状態にし、さらには関係のあるドキュメント同士を接続していきました。その作業にはオープンソースが役に立ったとのことです。\nOCRといった文書処理にはApache TikaとTesseractを使用。データベース化する際のインデックス作成にはApache Solrを用い、そのユーザーインターフェイスとしてProject Blacklightを採用しました。ここまですべてオープンソース・ソフトウェア。\nつながりを示すために、グラフデータ化したほうがよいだろうということで、SQLデータベースからETLソフトウェアTalendを用いて、Nep4Jデータベースへと変換し、データ可視化のためにLinkuriousという商用サービスを用いました。これを使うとグラフ構造のデータを、グラフ構造として表示することが可能になります。Linkuriousにはウィジェット機能が組み込まれているので、インタラクティブな状態でレポートへ組み込むことも出来ました。\nこうして、データベースとして公開し、これを元に世界中のジャーナリストが調査報道を行いました。 約21万5000社と1万4153人がモサック・フォンセカの顧客となっていたことが明らかになりました。政治家、経営者、著名人などがタックスヘイブンを利用していることが明らかになり、アイスランドとパキスタンでは首相辞任。日本は439の企業や個人が明らかになり、日本の国税当局が調査を行い、所得税など総額31億円の申告漏れがあったと朝日新聞が報じています。\n単にOCRかけてデータベースに投入するだけでなく、ひと手間をかけて、通常のリレーショナルデータベースからグラフデータ化を行っていることも大きなポイントで、これで個々の企業や個人だけでなく、そのつながりにも注目することが可能となります。\nhttps://linkurio.us/blog/panama-papers-how-linkurious-enables-icij-to-investigate-the-massive-mossack-fonseca-leaks/ より引用\n","date":"2020-05-19T00:00:00Z","image":"http://localhost:1313/panama-papers-wrangling/images/160403-overview-01-2-1280x640_hu_d0878680ba0db635.jpg","permalink":"http://localhost:1313/panama-papers-wrangling/","title":"パナマ文書におけるデータの構造化"},{"content":"Uberが、地理空間上のビッグデータを効率よく扱うためのフレームワークであるh3を公開しています。こちらをご紹介します。\nH3: Uber’s Hexagonal Hierarchical Spatial Index 彼ら自身の課題を解決する目的から生まれています。というのも、提供するサービスにおいて、毎日何百万ものイベントが発生しており、これらを利用して、マーケットプレイス全体の分析と最適化するために活用したい、と。たとえば、需要と供給の関係によって、ダイナミックに価格を変更したりといったことです。\nデータから情報や洞察を導き出すには、都市全体のデータを分析する必要があります。そのために地理空間のインデックス（グリッドシステム）が必要ですが、緯度経度で管理するのは計算コストが高すぎる。\nそのためのグリッドシステムとしてH3を開発しました。h3は、六角形を単位とし、さらに階層構造を持っています。地表を六角形のグリッドで覆ってしまうことで、\n計算量を削減する 六角形であれば、接するグリッドとの距離が均等。三角形や四角形ではそうはいかない。 グリッドセルをクラスタリングすることで、近隣地域を効率的に表現することができる。別なクラスタリング方法、たとえば郵便番号では行政の都合である時突然変更してしまうが、そのようなこともない。 紙の地図でいうところの縮尺、グーグルマップでいうところのズームレベルも、六角形で表現できる。 六角形であれば、接するグリッドとの距離が均等。三角形でも四角形でもそうはいかない。\n紙の地図でいうところの縮尺、グーグルマップでいうところのズームレベルも、六角形で表現。 グローバルグリッドシステムには、通常、地図投影と地図の上に敷き詰められたグリッドの2つが必要です。グリッドはすでに説明した六角形で、地図投影にはメルカトルなどの歪みがある地図投影法ではなく、正二十面体の面を中心とした心射方位図法を採用しています。\n正二十面体の面を中心とした心射方位図法を採用。\nC言語だけでなく、Python、Goなど様々な言語版も開発され、すべてオープンソースで公開されています。\n","date":"2020-05-18T00:00:00Z","image":"http://localhost:1313/uber-h3/images/Twitter-H3_hu_5763fe363ec1c15.png","permalink":"http://localhost:1313/uber-h3/","title":"Uber H3"},{"content":"このページでは、Yahoo!ニュース個人での記事のフォローアップ記事として、データをアップデートしたチャートを掲載しています。週一度程度で更新していますのであらかじめご承知おきください。\n東京都公式と厚労省公式で二倍異なる、東京都での COVID-19 死亡者数(矢崎裕一) - 個人 - Yahoo!ニュース データは4月20日更新です。\n","date":"2020-04-21T00:00:00Z","image":"http://localhost:1313/covid19tokyo/images/covid19tokyo_200420_hu_643a1f461ae85a42.png","permalink":"http://localhost:1313/covid19tokyo/","title":"東京都公式と厚労省公式で異なる、東京都での COVID-19 死亡者数"},{"content":"タマラ・ムンズナーさんがまとめた、なぜ可視化を行うのか？そのアクションとターゲットという図があります。ターゲットについて個別に図として独立させ、翻訳したものをご紹介します。\n「全データ」 「一つの属性」 「複数の属性」 ","date":"2020-03-26T00:00:00Z","image":"http://localhost:1313/tamar-targets/images/tamar-targets-alldata_hu_3732999901b6b503.png","permalink":"http://localhost:1313/tamar-targets/","title":"タマラさんによるタスクの定義（ターゲット）"},{"content":"北米においてもコロナウイルスが広がりをみせています。\n「コロナウイルスは、これまでの検査で示されているよりもはるかに多くの人々に感染しており、今後数ヶ月で病気や死の流れを大幅に食い止めるためには、まだ多くの症例を見ない国の一部での社会的接触を制限するための厳しい措置が必要だ」とNew York Timesの記事が伝えています。\nCoronavirus Could Overwhelm U.S. Without Urgent Action, Estimates Say\nアウトブレイクがどのように広がるかについて、州による管理措置がどの程度取られるかによって、\n・管理措置なし\n・いくつかの管理措置\n・厳しい管理措置\nの3つのシナリオで、アウトブレイクの広がりを推測したチャートをNew York Timesが記事化しています。\n・ニューヨークタイムズ[既知の症例のデータベース]\n・国勢調査局の輸送データ\nのデータを利用して、コロンビア大学の研究者が、モデル化しました。\n前提として、州によって発生状況や管理措置の対応が異なる、ということがあります。\nニューヨーク市、シアトル、ボストン、およびカリフォルニアの一部ではすでに大規模なアウトブレイクが発生しており、カリフォルニア州、ニューヨーク州、イリノイ州では「厳しい管理措置」を実施しています。\n一方他の州では管理措置に対する抵抗もみられているとのこと。多くの企業は、依然として労働者がオフィスに来ることを要求している、としています。\n（とてもむずかしい注文である）国が感染率を半分に抑えることができたとしても、今後2か月で約65万人が感染する可能性がある、としています（北米での話です）。\nそのことを示すために、3つのシナリオで4月1日〜8月1日までの推測を地図で確認できるインタラクティブ・コンテンツが用意されています。\n推論モデルの構築 コロンビア大学のSen Peiさんらがモデル構築しています。以下のように述べています。\n私は高次元モデルデータ同化（M / D / A）フレームワークを採用しました。これは、新しいウイルスの伝播動態をより良く理解するために、私たちのグループが長年にわたって感染症の予測と推論に開発し使用してきた方法論です。\n人間の動きのデータを使用して、数学モデルを構築し、中国の375の都市と米国の3,000を超える郡の間でSARS-CoV-2の時空間的伝播をシミュレートしました。\nこれらのモデルは、両国で報告された発生率データに合わせて調整され、主要な疫学的パラメーターが推定されました。\nその後、較正されたモデルを使用して、さまざまな規模での発生の進行を予測し、潜在的な介入の効果を評価しました。\nまた、米国の主要な疫学的パラメーターを推測し、封じ込め対策の影響をテストし、インフルエンザ様疾患をリアルタイムで予測するために、米国CDCが率いる共同作業に参加しました。\nSen Pei | Research （翻訳は筆者）\nNew York Timesと共同で、米国でのSARS-CoV-2の広がりのシミュレーションに取り組んでいます。\n私は、米国本土でのCOVID-19発生の広がりと成長をシミュレートするために、郡レベルのスケールで適用されるメタポピュレーションモデルを開発しました。\nこのモデルでは、2種類の動作-毎日の通勤とランダムな動作が考慮されました。\n昼間と夜間の伝送プロセスは別々にモデル化されました。\n私たちの予備的な結果は、通勤や場所間の移動の減少よりも、社会的距離が確認された症例の広がりと増加を大幅に遅らせることを示しています。\nSen Pei | Research （翻訳は筆者）\n関連するコードやデータはGitHubにあがっています。\n","date":"2020-03-21T00:00:00Z","image":"http://localhost:1313/nyt-corona-200320/images/nyt_colona_1_hu_90a9055bfdc33169.png","permalink":"http://localhost:1313/nyt-corona-200320/","title":"緊急の管理措置なしには、北米でコロナウイルスの圧倒的な広がりが起こってしまう、とNew York Times紙"},{"content":"タマラ・ムンズナーさんがまとめた、なぜ可視化を行うのか？そのアクションとターゲットという図があります。\nアクションの中でも、レベル感が三段階あります。そのうち一番高レベルのものとして「生産する」「消費する」の二つにわけられます。\n「消費する」分析 「生産する」分析 探す 一口に「探す」といっても、ターゲット（モノやコト）と場所について、未知と既知で４象限作り、それぞれの組み合わせについて、別な名称を提案しています。\n問い合わせる 単一のターゲットを対象とした識別、複数のターゲットを対象とした比較、全てのターゲットを対象とした要約に分けることを提案しています。\n","date":"2020-03-14T00:00:00Z","image":"http://localhost:1313/tamar-action/images/fig3-1-action-analytics-consume-1_hu_70d51f87d75b8d9b.png","permalink":"http://localhost:1313/tamar-action/","title":"タマラさんによるタスクの定義（アクション）"},{"content":"ワシントン大学の可視化の研究室とAdobe Reseachで共同研究した論文で、インタラクティブなチャートを利用していて、かつレスポンシブ対応（デバイスの解像度に自動的にフィットするような対応）している記事コンテンツを調査し、実際のところ、チャートのどの部分をどのように変更しているのか？代表的な12メディアの231コンテンツを調べたものがありましたので、引用しご紹介します。\nTechniques for Flexible Responsive Visualization Design\n左がポートレイト（縦長表示）で、右がランドスケープ（横長表示）時の、対応状況をカウントしたものです。ここからわかる傾向を筆者がまとめました。\nポートレイト（縦長表示） 軸のラベル、軸の目盛り、グリッド線は非表示化。 タイトルと凡例は配置位置を最適化。 幾何図形は非表示か、配置の最適化。 データラベルが一番対応がマチマチで、配置最適化、調整、非表示のいずれか。 全体表示はリサイズか配置の最適化。 インタラクションは変更なし。 ランドスケープ（横長表示） タイトルは配置位置を最適化。 幾何図形は非表示。 データラベルは非表示。 全体表示が一番対応がマチマチで、リサイズか変更なし。 インタラクションは変更なし。 調査対象のメディア 代表的な12メディアが選ばれています。2020年の論文で、その1〜数年前の調査のはずです。NYTがネットワーク図や表が多く、ロイターはドットプロットが多く、ブルームバーグはカートグラムが多い、といった傾向も伺えます。\n","date":"2020-03-13T00:00:00Z","image":"http://localhost:1313/desktop2mobile/images/Techniques-for-Flexible-Responsive_hu_48abf8486100745e.png","permalink":"http://localhost:1313/desktop2mobile/","title":"デスクトップ版からモバイル版を作成する際に、どこを変更する？"},{"content":"\nタマラ・ムンズナーさんがまとめた、なぜ可視化を行うのか？そのアクションとターゲットという図があります。\nまず先に右半分に掲載の「ターゲット」はデータの切り口や種類のことです。すこし異なる粒度のものが混ざっているので混乱するかもしれません。\n左半分の「アクション」ですが、上から下へ具体性を帯びていきますが、分析と探索、問い合わせはそれぞれ独立しています。\nある特定の課題を解決するためにデータ可視化を行う際、そのドメイン（分野）の言葉だけでタスクを言い表していると、事例を探す範囲が狭くなってしまいます。\nドメイン（分野）を超えて、汎用的な言い回しで「タスクとして何が実現できればいいのだっけ」（どんなターゲットに対してどんなアクションを起こしたいのか）と言い換えることで、参考になる事例がほかのドメイン（分野）から探し出せるとタマラさんは述べています。\nさらには、結局何を実現できればいいのかが言語化できるため、実装する際にシステム設計の詳細度をあげることが可能となりそうです。\n","date":"2020-03-13T00:00:00Z","image":"http://localhost:1313/task-abstraction-tamar/images/fig3.1_ja_hu_31e5051c19b28ddc.png","permalink":"http://localhost:1313/task-abstraction-tamar/","title":"なぜ可視化を行うのか？そのアクションとターゲット"},{"content":"GeoJsonとは、Jsonというデータフォーマットを用いて、空間データと非空間データを関連付けることができるファイルフォーマットです。\n空の状態から作り上げるというよりは、政府機関などから公開されているものを加工することが多いと思います。ファイルの内部構成をご紹介します。\nルート（最上階層） ルート（最上階層）には、GeoJsonのメタデータ的な部分と実体のデータの部分があります。\n筆者作成\ntypeは固定で、FeatureCollection（地物の集合の意）です。地物（feature）が集まってデータファイルになっているということですね。\ncrsは、Coordinate Reference System（空間参照系）のことです。\nbboxは地物がすべて収まる矩形の四隅の座標を格納しています。\nそして、featuresの中に、実際の地物（feature）データを格納しています。\n地物（feature） 地物（feature）は、geometry（ジオメトリ = 空間データ）とproperties（プロパティ = 非空間データ）が格納されています。typeは固定で”Feature”です。geometryは地図上に描かれるベクターデータを、propertiesは地図には描かれない表データを格納しています。\n筆者作成\n一つの地物（feature）の中にgeometryとpropertiesが格納されていますので、たとえばオープンソースのQGISというアプリケーションでGeoJsonファイルを開いてみると、同一の地物（feature）が同一選択範囲であることがわかります（画像の、地図上の黄色くハイライトされている箇所geometryと、表データのハイライトしている箇所propertiesです）。\n筆者作成\nデータ地図（主題地図）を作る際に、たとえば他のデータと結合する際には、propertiesに格納されたデータフィールドを活用します。\ngeometry ジオメトリはベクター形式で様々な地物を描きます。\nproperties プロパティは任意の表データです。geometryとセットで格納されることで、空間（位置）情報と関連づきます。\n","date":"2020-03-12T00:00:00Z","image":"http://localhost:1313/geojson/images/GeoJson_3_hu_20c31867e65b8353.png","permalink":"http://localhost:1313/geojson/","title":"GeoJsonとは"},{"content":"データ-インク比という言葉があります。エドワード・タフテがこのように定義しています。\nData-ink ratio = Data-ink ÷ total ink used to print the graphic データ-インク比 = データ-インク ÷ グラフィックの印刷に使用される全インク 紙に印刷されたグラフィックを想像していただいて、データインクとは、データ（測定された量）を伝えるためにインクの滴をさします。そして、グラフィック全体の印刷にかかったインク量のうち、データ（測定された量）を伝えるために用いられたインク量の比率を、データ-インク比と定義しています。\nそして、この比率ができるだけ1.0に近い状態を「良いグラフィック」として定義しています。タフテの著書、The Visual Display of Quantitative Informationからご紹介していきます。\nグリッドや軸の表現を軽減させる エドワード・タフテ／The Visual Display of Quantitative Informationより引用\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\nモアレ効果を多用しない 光学技術を元に多用なテクスチャの生成が可能になりましたが、モアレ効果を生み出し、ノイズが情報の流れを曇らせます。\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\n自己装飾が目的になってしまっている エドワード・タフテ／The Visual Display of Quantitative Informationより引用\n左右対象な図形 高さを示す棒グラフは、高さを示す要素以外を極限まで減らす。\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\nボックスプロット、棒グラフの棒、チャーノフの顔のように、シンメトリー（左右対称性）なチャートについては、左右対称であるがゆえに、半分は冗長であるとします。\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\n一見、幾何図形のみで成立しているチャートであっても、極限まで無駄を省いてみる。 通常の箱ひげ図も、この観点に立つと、極限までデータ-インク比を上げられます。\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\n適切な繰り返しは許容する 無意味な左右対称形は否定していますが、逆に、列車の時刻表や世界地図などは、スムーズな情報取得のため、意図的に繰り返す方が優れている、としています。\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\nエドワード・タフテ／The Visual Display of Quantitative Informationより引用\n現代において、どこまで有効な考えか？ 左右対称な図形や幾何図形を極限まで削る様は、やや過剰に潔癖すぎるきらいもなくはないです。エドワード・タフテ本人も「統計グラフィックスの設計には、効率だけでなく、複雑さ、構造、密度、さらには美しさまで、他の多くの考慮事項が残っています。」（翻訳は筆者）と述べています。\nデータ-インクの部分、非データ-インクの部分、それぞれにおいて、データを元に表現したいことのうち、データが根拠になっていない表現、データを曲解しかねない表現については極力避けなければならないことは言うまでもありません。\n","date":"2020-03-09T00:00:00Z","image":"http://localhost:1313/data-ink-ratio/images/DataInkRatio_Playfair_generated_hu_7b44d35b95bb0c8b.png","permalink":"http://localhost:1313/data-ink-ratio/","title":"データ-インク比"},{"content":"データの分類方法は色々あります。\nそのうち、四則計算や代表値を求める計算のうち、適用可能範囲で分類する考え方があります。\nスタンレー・S・スティーブンスが1946年の論文で提案し、参照されることが多い分類方法です。\n質的データが文字データ、量的データが数値データを、それぞれ指します。それぞれが2種類づつに分類されます。呼び方にスケールを付けずにデータと付け、名義データ、順序データなどと呼ぶ場合もあります。\n図の上から下へ、名義スケールが情報量が一番少なく、比例スケールが情報量が一番多いです。大は小を兼ね、情報量が少なくなる方向でのスケールの変換が可能ですが、逆は出来ません（例：順序スケールは名義スケールに変換可能ですが、名義スケールは順序スケールに変換することはできません）。\n名義スケール（Nominal Scale） 単に区別するためだけに用いられる。 五十音順、アルファベット順でソートすることは可能だが、大小関係ではない。 データの個数を数えることはできる。 グループ化することができ、その結果、最頻値を得られる。ただし、中央値、平均値は得られない。 具体例：\n性別、職種、血液型、 出身地、電話番号、 型番、 スポーツ選手の背番号、バスの系統番号など\n順序スケール（Ordinal Scale） 順序や大小関係に意味がある。 任意の2つのデータの間隔(距離)の等しさは保証されていない。 二分法、非二分法のそれぞれに該当するデータがある（二分法とは物事をAと非Aの二つに分けることを指す）。 心理学や社会科学の測定値の大部分は順序スケールで行われている。 データ値が数字であってもそれは序数であり、平均や標準偏差を算出することはできない。 **具体例（二分法）：\n**健康と病気、有罪と無罪など。\n具体例（非二分法）：\n五段階評価の成績、 金銀銅などの順位、松竹梅などの階級、 おみくじ(大吉〜大凶)、 星の明るさ(等級)、職位、満足度など。\n間隔スケール（Interval Scale） 任意の2つの隣接値または間隔の距離が等しい。 原点(ゼロ点)は便宜的に存在するが、特別な意味を持たない。 時間的な期間を測定することができる。 掛け算、割り算はできない（20℃は10℃の「2倍の熱」とは言えない）。 具体例：\n気温、偏差値、相対的な標高、知能指数、西暦、カレンダーの日付など。\n比例スケール（Ratio Scale） 意味のある均一な間隔を持つ。 順序に意味がある。 値の差と比率に意味があるため、四則計算(加算、減算、乗算、除算)ができる。 任意ではない固有の原点(ゼロ点)を持つ。値がゼロの場合、そのものが存在しないことを表すことが多い。 具体例：\n身長、体重、年収、金額、絶対温度、金利、(ある時点からの)経過日数、年齢、収入など\nThe Grammer of Graphicsより\n使い道 データの性質を把握するのに利用し、データを視覚的に表現する際に考慮します。名義・順序・量的データと分類する考え方はわかりやすく、色の選定やビジュアル変数を分類する際に用いられます。具体的には、面積や色で表現する際に、この分類にあわせて、表現ルールを設定します。その際、間隔スケールと比例スケールを区別しないで、量的データ（定量スケール）一つとして扱う人もいます。\n別なスケールへデータを変換することもできます。ただし、四則計算や代表値を求める計算が少なくなる方向へのみ変換が可能です。\nまた「データがスケールの選択にほとんど役に立たず、間違った選択は発見を妨げる可能性がある」とするVelleman and Wilkinson（1994）や、 スティーブンスのものを含む多数の測定理論を比較したD. J. HAND(1996)などの研究があります。\n","date":"2020-03-07T00:00:00Z","image":"http://localhost:1313/data-scale/images/1_aHohRnwe6dmiqzsiRYEpug_hu_d203a6b73f9a4cbc.png","permalink":"http://localhost:1313/data-scale/","title":"データスケール（Data Scale）"},{"content":"1975年に発表された論文で、スタンレー・スミス・スティーブンス(Stanley Smith Stevens)は、「物理的刺激の大きさ」と「その知覚される強度」との間の関係は、べき乗関数に従うことを示しました。\n“Visualization Analysis and Design. Tamara Munzner, with illustrations by Eamonn Maguire. A K Peters Visualization Series, CRC Press, 2014.” 翻訳は筆者。\nS=Iⁿ\nSは知覚された感覚、Iは物理的な強さを、nは感覚の種類の応じて異なる指数です。\n最小は輝度の場合で0.5の線形を、最大は電流の場合で3.5の線形をとります。たとえば、視覚的な長さが1.0であり、実際と認知の差が限りなくない状態です。\nそれ以上に小さい指数では実際よりも過小評価し、それ以上に大きい指数では実際よりも過大評価するということになります。\nつまり、面積・奥行き・輝度については実際よりも過小評価し、彩度や電気ショックについては実際よりも過大評価するということになります。\nデータを可視化する際、こういった人間の持つ認知の特徴を考慮する必要があります、ということを示すために、データ可視化系の文献ではよく参照される法則ですが、手法に疑問を呈する声もあるようです。\nPsychophysics : introduction to its perceptual neural and social prospects / S. S. Stevens スティーヴンスのべき法則 - Wikipedia ","date":"2020-03-07T00:00:00Z","image":"http://localhost:1313/stevens-power-law/images/1_Y5WnsJQi9dPl2C-9LMtCpg_hu_94ac4ead1ab78386.png","permalink":"http://localhost:1313/stevens-power-law/","title":"スティーヴンスのべき法則(Stevens’ power law)"},{"content":"QGISでの階級分類をご紹介します。アプリケーション上では「モード」と呼ばれています。\n等間隔：各階級のサイズが同じです（例：0〜16および4つのクラスの値、各クラスのサイズは4）。\n分位（等量）：各階級の内部には同じ数の要素があります（箱ひげ図の考え方）。\n自然なブレーク（Jenks）：各階級内の分散は最小ですが、階級間の分散は最大です。\n標準偏差：階級は、値の標準偏差に基づいて構築されます。\nプリティブレーク：xの値の範囲をカバーする約n+1個の等間隔のnice値のシーケンスを計算します。値は、10の累乗の1、2、または5倍になるように選択されます（R統計環境の値に基づいています）。\n","date":"2020-02-27T00:00:00Z","image":"http://localhost:1313/qgis-classification/images/qgis_jenks_hu_b1b72093f2119677.png","permalink":"http://localhost:1313/qgis-classification/","title":"QGISにおける階級分類"},{"content":"様々なGISアプリケーションで階級分類する際に、Natural breaks (Jenks)やJenksなどという名称の分類があります。一体これは何か？ということで、いくつかのリソースから引用してみましょう。\nGeospatial Analysis 6th Edition, 2020 update Geospatial Analysis 6th Edition, 2020 update 「GISパッケージ内で広く使用されているこれらは、分散最小化分類の形式です。ブレークは通常不均一であり、値の大きな変化が発生する値を分離するために選択されます。選択された階級分類の数に大きく影響される可能性があり、通常ではない階級境界を持つ傾向があります。」\n「Jenks and Caspall（1971）で説明されているように、一般的に適用される方法はJenksによるもので、Fisher（1958）に続きます。」\nArcGISでの定義 ArcGISでの定義 「自然分類 (Jenks) では、クラスはデータ値の自然なグループ化に基づいています。クラス閾値は、類似している値を最適にグループ化し、クラス間の差異を最大化するように特定されます。フィーチャは、データ値の差異が比較的大きい部分に境界が設定されるようにクラスに分割されます。」\n「自然分類手法は、データ固有の分類方法で、異なる基礎情報から構築された複数のマップの比較には有用ではありません。」\nCartoでの定義 Cartoでの定義 「数値でマップレイヤーのスタイルを設定する場合、Jenks分類方法は、データに固有の自然なグループ化に基づいて、データをクラスに分割します。 グループは、クラス内の分散を減らし、異なるクラス間の分散を増やすこと（1D k-means）で形成されます。」\n「Jenksはデータ固有の分類であるため、異なる基になるデータから作成された複数のマップを比較するのには役立ちません。」\nQGISでの定義 QGISでの定義 「Natural Breaks（Jenks）：各クラス内の分散は最小ですが、クラス間の分散は最大です。」\n","date":"2020-02-27T00:00:00Z","image":"http://localhost:1313/classification-jenks/images/qgis_jenks_hu_b1b72093f2119677.png","permalink":"http://localhost:1313/classification-jenks/","title":"地図の階級分類におけるJenksって？"},{"content":"QGISのfToolsとGDALToolsの両プラグインはQGISのコアプラグインから削除され、Processingフレームワークへ統合されました。\nQGISをインストールしたタイミングによっては、お使いのQGIS上で利用可能かもしれませんが、今後はこの形態では提供されないことになります。\nQEP 54: Dropping fTools and GDALTools core plugins in favor of the Processing · Issue #54 · qgis/QGIS-Enhancement-Proposals\nメニュー項目として後ろから3番目あたりに「プロセッシング」というメニューが表示されていれば、そちらから利用できます。\n表示されていない場合は、「プラグインの管理とインストール」から入手します。\n","date":"2020-02-23T00:00:00Z","image":"http://localhost:1313/qgis-processing/images/qgis_processing_hu_f0631dfc07a54624.png","permalink":"http://localhost:1313/qgis-processing/","title":"QGISで、fToolsとGDALToolsが見当たらない?"},{"content":"コンピュータで地図を扱おうとする際に、空間参照系（Coordinate system）、測定単位（Unit）、測地CRS（Geodetic CRS）、基礎データ（Datum）、地球楕円体（Ellipsoid）、子午線（Prime meridian）など、たくさんの設定値を扱う必要があります。個別に扱うのは大変なので、これらをセットとして、IDを発番し、多くの地理情報システム（GIS）ではこれを使用しています。\n概念的には、空間参照ID、英語ではSRID（Spatial Reference System Identifiers）と呼ばれるもので、事実上の標準として、EPSGコードが使用されています。EPSGは、the European Petroleum Survey Group（欧州石油調査グループ）の略称です。\n日本でよく使用される測地基準系と座標系一覧（筆者調べ） TokyoJGD2000JGD2011WGS84地理座標系-461266684326UTM投影座標系3092〜30963097〜31016688〜669232651〜32656平面直角投影座標系30161〜301792443〜24616669〜6687-球面メルカトル図法---3857 ウェブで主流の地図タイルのEPSG ID 基本的には 3857 を用いればいいのですが、過去の経緯から、たとえば検索して探そうとするといくつか紛らわしいIDが見つかります。ご注意ください。\n3857\n現在、Google Maps、OpenStreetMap、Bingなどを描画する際に利用されるEPSGのID。\n900913\nかつて、Google MapsやBingはEPSGに却下された際に、GISツール側で対応するため非公式に発番されたもの。\n3785\n2008年中頃にEPSGに割り当てられたID。半年後にこのIDは非推奨とされ、新しいIDが発番されました。それが3857です。3785と似ていることには意味がない（はず）です。\n関連リンク 見やすい3rdパーティのリファレンス http://epsg.io/\n公式データベース https://www.epsg-registry.org/ http://www.epsg.org/ https://beta.epsg.org/home.html ","date":"2020-02-22T00:00:00Z","image":"http://localhost:1313/epsg-code/images/epsg_hu_c1f2ff59021c6f67.png","permalink":"http://localhost:1313/epsg-code/","title":"EPSGコード"},{"content":"「情報アーキテクチャ」「情報アーキテクト」という概念自体を定義した、リチャード・ソウル・ワーマン。彼は著述家としてだけでなく、TEDカンファレンスの創設者としても著名な人です。\n彼が1996年の著書「Information Architects」の中で、情報の整理原則を提案しています。略語としてLATCHです。\nLocation（場所） Alphabet（アルファベット、日本風には五十音順） Time（時間） Category（カテゴリー） Hierarchy（階層） データビジュアライゼーションの原理原則を学んでいる者からすると、LATCHは、1996年に作られたことや作者自身が否認していることもありますが、すべてを言い表せておらず、更新する必要性を感じています。\nアルファベットとカテゴリーはカテゴリーとして同一に扱えそうですし、階層以外のネットワークが存在しないですし、数値について明示的な扱いもありません。\nこれらをアップデートするとして、Juuso Koponenさん, Jonatan Hildénさんが、頭文字をすべてCで統一的に扱って新たに \u0026ldquo;The Seven C\u0026rsquo;s\u0026quot;という略語を提案しています（Data Visualization Handbook, 2019）。覚えやすい。素晴らしいですね。これで充分ですね。\nContinuum by magnitude（大きさによる連続体） Continuum by rank（ランクごとの連続体） Coordinates（座標） Chronology（年表） Category（カテゴリー） Connection（接続\u0026hellip;関係性） Convention（慣習・慣例） ","date":"2020-01-13T00:00:00Z","image":"http://localhost:1313/thesevencs/images/thesevencs_hu_af5bdd155a642a84.png","permalink":"http://localhost:1313/thesevencs/","title":"LATCHに代わる情報の分類法 the Seven C's"},{"content":"データビジュアライゼーションの作品を作ろうと思ったときに簡単に行かないのは「設計空間が膨大で、ほとんどの設計は効果がない」ことから、「ビジュアルデザインの複雑な問題を4つのカスケードレベルに分割することで、異なる懸念事項を個別に解決できる分析フレームワークを提供する」という意図で、Tamara Munznerさんが提示しているフレームワークをご紹介します。\n上から、「ドメイン状況」「タスクとデータの抽象化」「ビジュアル・エンコーディング／インタラクティブ・イディオム」「アルゴリズム」の4レベルとなっており、上位のレベルほど、下位のレベルを包含していることがポイントです。つまり上位のレベルでの決定事項が、下位のレベルの決定に影響を与えるという構成になっています。\n4レベルのそれぞれを紹介 ドメイン状況 ドメイン状況を検証するにあたって必要なのは、ターゲットユーザーのグループ、対象ドメイン、質問、およびデータなどです。\nドメインという用語は、ターゲットユーザーにとっての特定の関心分野を意味しています。\n各ドメインには通常、データと問題を記述するための独自の語彙があり、通常、データを使用して問題を解決するための既存のワークフローがあります。\n起こりうる間違いとしては、ターゲットユーザーのニーズを誤解していた、ということがあげられます。\nタスクとデータの抽象化 特定のドメインにおける質問とデータを、ドメイン固有のフォームから汎用表現に抽象化する必要があります。\nドメインに依存しない語彙に抽象化することで、全くかけ離れたドメインにおいて、その可視化が必要な理由（タスク）とそのデータが示すものが、同様である可能性があるからです。\n起こりうる間違いとしては、ターゲットユーザーへ間違ったものを見せようとしていた、ということがあげられます。\nビジュアル・エンコーディング／インタラクティブ・イディオム イディオムデザインには2つの大きな意味があります。\n1つ目は、ビジュアル・エンコーディング・イディオム。\nデータから1つの画像（に見えるもの）を作成するということです。\nユーザーが見るものを正確にコントロールします。\n2つ目は、対話のイディオムです。\nその表現を動的に操作する方法ということです。\nユーザーが見ているものをどのように変更するかをコントロールします。\n起こりうる間違いとしては、見せているものが機能していない、ということがあげられます。\nアルゴリズム アルゴリズムの作成に関連するすべての設計や選択です。\nコンピュータが自動的に目的の目標を実行できるようにする詳細な手順としての、アルゴリズムの新たな設計や既存のものからの選択を指します。\n起こりうる間違いとしては、実行速度が遅すぎる、ということがあげられます。\nアタックする順序 Tamaraさんは、これらのレベルを進めていく順序を、トップダウンとボトムアップの両方を想定してます。\n問題駆動型(problem-driven) 問題駆動型(problem-driven)の作業では、トップの「ドメイン状況」レベルから始め、「タスクとデータの抽象化」、「ビジュアル・エンコーディング／インタラクティブ・イディオム」、「アルゴリズム」の決定を下に進めます。\n現実世界のユーザーの問題を取り組み、より効果的に作業できるソリューションを設計しようとします。この種の研究はデザイン研究と呼ばれることが多い。しばしば、新しいものを設計するのではなく、既存の視覚的エンコーディングと相互作用のイディオムを使用して問題を解決することができ、課題の多くは抽象レベルにあります。しかし、既存のものが抽出された設計上の問題を適切に解決できないと判断した場合、問題は新しいイディオムの設計を促すことがあります。\nこの設計プロセスは、決して厳密には線形ではなく、すべてのレベルで繰り返す中で洗練されていくとしています。\n技術主導型(technique-driven) 技術主導型(technique-driven)の作業では、既存の抽象概念をよりよくサポートする新しい視覚的なエンコーディングやインタラクションの「イディオム」や、既存のイディオムをよりよくサポートする新しい「アルゴリズム」を開発することを目標として、下位の2つのレベル、「ビジュアル・エンコーディング／インタラクティブ・イディオム」、「アルゴリズム」設計のいずれかで作業します。\n","date":"2020-01-12T00:00:00Z","image":"http://localhost:1313/tamar-4levels/images/fig4.2_ja-1_hu_ea6b5a81422b632.png","permalink":"http://localhost:1313/tamar-4levels/","title":"ビジュアルデザインの複雑な問題を4つのカスケードレベルに分割する"},{"content":"可視化を科学可視化と情報可視化に分類する考え方があります。\nそれによると、可視化自体は、認知を増幅するために行うインタラクティブな視覚的表現の使用のことを指す、という点では共通ですが、以下のような違いがあります。\n科学可視化 物理的な空間に基づいている（明確な空間マッピングを持つ）科学データを用いた、現実世界の正確な可視化。 具体的には、宇宙を含む三次元空間上の現象、流体力学のシミュレーション結果の表示、人体内部の三次元構造を医療画像を元にした復元表示、分子動力学シミュレーション結果の表示などを指します。 対応する物理的な形状や外観を持っている。 情報可視化 物理的な空間に基づいていない（明確な空間マッピングを持たない）抽象データを用いた、本質的に抽象的な概念の可視化。 具体的には、財務データ、ビジネス情報、収集されたドキュメント、抽象的な概念など非物理情報の表示を指します。 対応する物理的な形状や外観を持っていません。 一般の人が普段接している情報の多くは情報可視化 科学可視化と情報可視化、これらは明確に分けられます。\n科学可視化は、まずはデータが基づいている物理的な空間として再現することを目指し、加えてその他の属性を表示することを目指します。\n情報可視化は、そもそも基づいている物理的な空間が存在しないため、空間的な表現方法が自由で、そのためデータ構造の自由度もより高いです。\n一般の人が普段接している情報は情報可視化が扱う範疇のものが多い一方で、抽象的な概念を、幾何図形を用いて可視化することが、親しみにくさ、情緒的な共感の低さにもつながっているのではないか、と矢崎は考えます。\n参考文献 Card, S. K., Mackinlay, J. D., Shneiderman, B.: Readings in Information Visualization: Using Vision to Think 伊藤貴之: 意思決定を助ける情報可視化技術 高間康史: 情報可視化　データ分析・活用のためのしくみと考え方 ","date":"2020-01-01T00:00:00Z","image":"http://localhost:1313/scientific-and-information/images/science_information_hu_259690db7c78bc2c.png","permalink":"http://localhost:1313/scientific-and-information/","title":"科学可視化と情報可視化"},{"content":"Open Refineでデータクレンジングをなさっている方には役立つ日付関数のパターン文字一覧です。適宜ご活用ください。\nhttps://github.com/OpenRefine/OpenRefine/wiki/GREL-Date-Functions パターン文字 日付・時刻コンポーネント データ型 例 G 時代表記（西暦） テキスト AD y 年 年 1996; 96 Y 年（年末年始などで週の半ばで年が変わる際に用います） 年 2009; 09 M 月名 月 July; Jul; 07 w 通年における何番目の週か 数値 27 W 月における何番目の週か 数値 2 D 通年における何番目の日にちか 数値 189 d 日にち 数値 10 F 月の初めから数えた曜日 数値 2 E 曜日名 テキスト Tuesday; Tue u 曜日の番号表記 (1 = 月曜, \u0026hellip;, 7 = 日曜) 数値 1 a Am/pm マーカー テキスト PM H (0-23)時 数値 0 k (1-24)時 数値 24 K am/pm表示における (0-11)時 数値 0 h am/pm表示における (1-12)時 数値 12 m 分 数値 30 s 秒 数値 55 S ミリ秒（1000分の1秒） 数値 978 n ナノ秒（10億分の1秒） 数値 789000 z タイムゾーン General time zone Pacific Standard Time; PST; GMT-08:00 Z タイムゾーン RFC 822タイムゾーン -0800 X タイムゾーン ISO 8601 タイムゾーン -08; -0800; -08:00 ","date":"2019-11-23T00:00:00Z","image":"http://localhost:1313/open-refine-grel-date/images/image_3hours_refine_hu_b443b315df3556d2.png","permalink":"http://localhost:1313/open-refine-grel-date/","title":"Open Refine - GREL日付関数 パターン文字一覧"},{"content":"データの視覚化がもたらす「データ・ストーリーテリング」は、従来の形式のストーリーテリングとは重要な点で異なるのではないか、と主要作品を分類するなかから体系化を試みた2010年の論文をご紹介します。そして、様々な切り口が登場しながらもそれらの関連付けがやや複雑かつ曖昧ですので、分類の枠組みとして参考にする程度がよいでしょう。引用する図版はすべて下記リンク先の論文からのものです。\nhttp://vis.stanford.edu/files/2010-Narrative-InfoVis.pdf この体系化は大きくわけて3つ、（1）ジャンル（Genre）（2）「視覚的な物語」の戦術（Visual Narrative）、（3）「物語構造」の戦術（Narrative Structure）の機能区分（切り口）から成り立っています。\n(1)ジャンル 物語可視化のジャンル\n視覚的な物語タイプを分類したもので、主に（a）フレームの数（時間および/または空間で多重化された個別の視覚シーン）の数、（b）視覚要素の順序、がジャンルごとに異なる、としています。また排他的ではない（一つの作品が複数のジャンルに該当することもある）とのこと。\n(2)「視覚的な物語」の戦術（Visual Narrative） 物語を支援し促進する視覚デバイスを特定します。\n視覚的構造化（Visual Structuring） Establishing Shot / Splash Screen Consistent Visual Platform Progress Bar / Time bar “Checklist” Progress Tracker 強調表示（Highlighting） Close-Ups Feature Distinction Character Direction Motion Audio Zooming トランジションのガイダンス（Transition Guidance） Familiar Objects (but still cuts) Viewing Angle Viewer (Camera) Motion Continuity Editing Object Continuity Animated Transitions （3）「物語構造」の戦術（Narrative Structure） 物語を支援や促進する非視覚的なメカニズムを特定しています。\n順序付け（Ordering） Random Access User Directed Path Linear 対話性（Interactivity） Hover Highlighting / Details Filtering / Selection / Search Navigation Buttons Very Limited Interactivity Explicit Instruction Tacit Tutorial Stimulating Default Views メッセージング（Messaging） Captions / Headlines Annotations Accompanying Article Multi-Messaging Comment Repitition Introductory Text Summary / Synthesis 以上の体系化を元に分析 オンラインジャーナリズム（71％）、ビジネス（20％）、および視覚化調査（9％）から収集された58の例を元に分析したものが以下のチャートです。\n現在足りていない要素は？ その上で論文では、2010年現在での作品において、不足しているデータストーリーテリングの要素を特定しています。最初の図版の（1）〜（４）の赤い矩形の箇所になります。\n（1）は、視覚ナレーションの異なるジャンルに対応する順序付け戦略のクラスターを示しています。\n（2）は、視覚化で使用されるインタラクティブなデザインの一貫性を強調しています。\n（3）は、ユーザーが対話型機能に関与するための戦略が十分に活用されていないことを示しています。\n（4）は、物語の視覚化における一般的なストーリーテリングテクニックの活用不足を示しています。\n作者ドリブン vs 読者ドリブン さきほどの体系化を受けて、作者ドリブン vs 読者ドリブンという切り口も提示されています。\n作者ドリブン 視覚化を厳密に直線的に進め、メッセージングに大きく依存し、インタラクティブ性は含まれません。\n・例：フィルム、非インタラクティブなスライドショー\n・タスク：ストーリーテリングまたは効率的なコミュニケーション\n読者ドリブン 規定された順序や、メッセージング、高度なインタラクティブ性はありません。\n・例：TableauやSpotfireなどの視覚分析ツール\n・タスク：データ診断、パターン検出、仮説形成\n作者・読者ドリブンのどちらが優先されるかで、アプローチを3つに分類 マティーニ・グラス型 作者主導の物語が最初に機能し、次に読者主導の対話が個別に続きます。\nインタラクティブ・スライドショー型 一般的なスライドショー形式に従いますが、各スライドの範囲内でのナレーションの中間的なインタラクションを取り入れています。作成者主導型と読者主導型のアプローチのよりバランスのとれた、物語の中期的な対話を可能にします。\nドリルダウン・ストーリー型 読者主導のアプローチに重点を置いており、ユーザーがストーリーをいつどのように伝えるかを決定できるようにします。\n","date":"2019-10-28T00:00:00Z","image":"http://localhost:1313/storytelling-edwardsiegel/images/Genres-of-Narrative-Visualization_hu_4cac46040e1d3bd1.png","permalink":"http://localhost:1313/storytelling-edwardsiegel/","title":"データ・ストーリーテリングの体系化（エドワルド・シーゲルさんの分類）"},{"content":"※このページは随時更新されます。\n政府によるハリケーンの被害状況が現状を正しく表していないのではないかと、CPI（Puerto Rico’s Center for Investigative Journalism）、AP通信、Quartzのコラボレーションによる調査報道プロジェクト。\nデータジャーナリズムの観点からこのプロジェクトのイノベーティブな部分を紹介をする。\n1.ツールを使用してハリケーン関連の死亡を特定し、公式統計と死亡証明書を相互参照・検証したこと。\n2.データ収集プロセスの一部を自動化したこと。\n3. 統計分析プログラムRを使用して、ケースを収集、クリーンアップ、重複排除して、重複のない均一な死亡記録のスプレッドシートを作成したこと。\nがあげられる。3について、複数のデータを参照したが、同じ人が複数カウントされている可能性があったため、機械学習による自然言語処理からのいくつかのプラクティスを参照して、同じ人である可能性が高いケースを抽出した。ただし堅実に進めるために、個別に電話インタビューを行い、それらが本当に同一人物のことなのかを確認していった、とのこと。\nプロジェクト成果物サイト http://hurricanemariasdead.com/ https://hurricanemariasdead.com/about.html CPIによる記事 http://periodismoinvestigativo.com/2018/09/the-deaths-of-hurricane-maria/ AP通信 https://www.apnews.com/HurricaneMaria'sToll Quartz https://qz.com/1390559/how-many-people-died-in-hurricane-maria-an-investigation/ https://qz.com/1288679/a-new-survey-of-puerto-rico-death-toll-from-hurricane-maria/ https://qz.com/1395908/hurricane-maria-death-count-in-puerto-rico/ Data Journalism Awards https://www.datajournalismawards.org/projects/hurricane-marias-dead/ Online News Association 2019 - Creating Guidelines for Machine Learning in the Newsroom - AP通信のTroy Thibodeauxが一部エピソードを語っている。 https://ona19.journalists.org/sessions/23518453/ ","date":"2019-10-12T00:00:00Z","image":"http://localhost:1313/hurricane-maria/images/hurricanemariasdead_hu_56d701c6c913148b.png","permalink":"http://localhost:1313/hurricane-maria/","title":"ハリケーン・マリアは人災だった。Quartz、AP通信、CPIによるコラボレーティブ・ジャーナリズム"},{"content":"Datashareは、非営利の国際調査ジャーナリストコンソーシアム（ICIJ）によって開発された無料のオープンソースデスクトップアプリケーションです。ジャーナリストが利用することが想定されています。\nパナマペーパーやパラダイスペーパーなど、ICIJが最大のプロジェクトを実現するのに役立ったのと同じテクノロジーで構築されています。こんなことが行えるそうです。\nhttps://www.icij.org/blog/2018/05/icijs-datashare-project-will-help-journalists-breach-borders/\n潜在的なサードパーティの干渉からドキュメントを保護しながら、ローカルコンピューター上ですべてのドキュメントにワンストップにアクセスする ファイルからテキストを抽出（現在は英語、スペイン語、フランス語、ドイツ語に対応）することによって、PDF、画像、テキスト、スプレッドシート、スライドなど様々な形式のファイルを同時に検索 人、組織、場所ごとに自動的にタグづけし、検出およびフィルタリングが可能 「ファイルからテキストを抽出」や「人、組織、場所ごとに自動的にタグづけ」するところに、様々なアルゴリズムが用いられています。\n機械可読テキスト化にはApache Tikaを使用、光学文字認識にはTesseract OCRを適用し、検索エンジンにはElasticsearchを使用しています。\nhttps://www.icij.org/blog/2018/05/icijs-datashare-project-will-help-journalists-breach-borders/\nまた、分析のためにGoogleが制御するサーバーなどのサードパーティのプラットフォームにデータを送信しません。そうではなく、ICIJのナレッジセンターでホストしている以前のICIJ調査（パナマペーパーやパラダイスペーパーなど）からのすべての漏洩データとも接続できるとのことです。\nDatashare開発者のJulien Martinさんは、「Datashareは作業の重複を回避するだけでなく、新しい探検の道を開き、多様な思考を促し、セキュリティとプライバシーを改善して、選択したジャーナリストが24時間年中無休で情報を入手できるようにします。」と述べています。\nhttps://datashare.icij.org/ https://icij.gitbook.io/datashare/ https://github.com/ICIJ/datashare ","date":"2019-10-12T00:00:00Z","image":"http://localhost:1313/datashare/images/Datashare-topimage_hu_d72983c84430c83c.png","permalink":"http://localhost:1313/datashare/","title":"調査報道のためのファイル探索アプリDatashare"},{"content":"元バズフィードニュースデザイナーだったMichelle Rialさんのかわいらしい絵本です。毎日の生活でグルグル思い悩んでいることを時に過剰に、時にモノからテーマを発想してチャート作品作りをしています。いくつかご紹介します。\nAm I Overthinking This?: Over-answering life’s questions in 101 charts\nベン図 ダイエットを妨げるもの、ということで、乳製品、カフェイン、糖分、アルコール、グルテンを制限するとして…どうやっても友達を減らしてしまうのでは?と考えすぎています。\n友達・同僚・好ましくない人、それぞれに送るメールの最後にどう書くか？考えすぎても、結局「Sent from my iPhone」となってしまいます。\nビートルズの歌詞から、人生を励ます言葉を探す。\nコーヒーカップの裏を使ったベン図で、結局珈琲が好き。\n植物 鉢植えと植物、いつもちょうど良いものが手に入らなくてグルグル。\n小物使い 検索でプラスチック被害のことを知ってから、プラスチック使用料の激減（マイナスなのはどういうこと?）。\n歯医者の予約日が近くと歯磨き頻度が上がり、歯医者にかかり終わると歯磨き頻度が減っていく。\n見た目に気を使いたいのと、楽なウェアを着たい気持ちの戦い。\nサンフランシスコの地元の出版社から発売 Am I Overthinking This?: Over-answering life’s questions in 101 charts\nKindle版、書籍版と両方発売されています。発売元は Chronicle Books というサンフランシスコにある地元の出版社です。アップルのWWDC（製品発表会）でサンフランシスコのモスコーンセンターに行かれたことがある方は、会場近くに書店があったのを覚えているかと思います。あれが Chronicle Books の旗艦店です。ほかにも素敵な装丁の本をいくつも発売しています。\n","date":"2019-10-11T00:00:00Z","image":"http://localhost:1313/overthinking-this/images/EB3B25MVUAAOXDE_hu_5b5b4b37edfe4b97.jpeg","permalink":"http://localhost:1313/overthinking-this/","title":"考えすぎ? ハンドメイドの過剰なチャートたち"},{"content":"AIによる音声の自動文字起こし（トランスクライブ）、良いサービスが続々登場しています。英語にも当然対応しているので、特に海外のカンファレンスに参加される方には強い味方になります。ぼくも実際に、カンファレンス会場でのライブ録音や動画ファイルの文字起こしとして、アカウント制限の目一杯まで使いまくっています。\n海外カンファレンス参加のお供なら Otter Otter\nライブ録音：対応 ファイル読み込み：アップロードのみ 提供形態：ウェブサービス 対応言語：英語 カンファレンス会場で、スマートデバイスを使って録音した内容を、その場でトランスクライブしてくれるサービス。 ファイルのアップロードにも対応しているが、ウェブサービス上の動画を直接読み込むといったことは出来ない。 動画ファイルをアップロードしても、音声のみがサイトに保存される。講演の様子をみながら音声をみたい場合には Trint を使う。\n海外カンファレンスの公演録画を活用したいなら Trint Trint\nライブ録音：対応 ファイル読み込み：ウェブサービス上から 提供形態：ウェブサービス 対応言語：28言語 カンファレンス会場で、スマートデバイスを使って録音した内容を、その場でトランスクライブしてくれるほか、様々なウェブサービスに掲載されている動画を直接読み込むことができる。Otterでは音声しか残らなかったが、Trintは映像と音声の両方がサイトに保存される。ただし利用料はOtterに比べてかなり高め。\n自分が作成した動画に自動で字幕をつけたいなら Vrew Vrew\nライブ録音：非対応 ファイル読み込み：アップロードのみ 提供形態：デスクトップアプリ 対応言語：日本語、英語、韓国語 アプリ上で動画を見ながら、AIが自動生成した文言の訂正が行える。作業後、字幕付きの動画として書き出すことができる。\n自分がイベントを開催する側で字幕を提供したいなら UD Talk UD Talk\nライブ録音：対応 ファイル読み込み：非対応 提供形態：録音用スマートデバイスアプリと文言訂正用デスクトップアプリ 対応言語：多数 イベントを開催する際に、自動字幕化と翻訳の両方に対応している。デスクトップアプリを使ってイベントの最中に、生成された文言の訂正が行える。\n四者四様なので目的に合わせてどうぞ これまで明瞭に聴き取れなくて諦めていた動画ソースから、自動で文字起こしができる。これは英語のリスニングに慣れていない非英語圏の人にとっては新しい眼を手に入れたようなインパクトがあります。有料サービスですので料金はご確認の上、ぜひ活用してみてください。\n","date":"2019-08-30T00:00:00Z","image":"http://localhost:1313/transcriber/images/fi_Transcribe_hu_b7b762a296a6e5a0.png","permalink":"http://localhost:1313/transcriber/","title":"海外カンファレンス参加の強い味方、AI自動文字起こしアプリ四つご紹介"},{"content":"ツイートにはノイズが多いけども、消費者動向を探ることのできる無料データとみなしてもっと活用できるんじゃないかということで、チャートを使って具体的に示した事例を紹介します。\nVision Statement: Six Ways to Find Value in Twitter’s Noise iPadがラウンチした直後の週末に、iPadという単語とともに検索された単語の量が、時系列でどう変化していくかを可視化しているチャートです。こういうチャートを Streamgraph とよびます。時系列でのボリューム変化の全体感をバクッと掴むのに有効です。\n画面左から右へ時間が進んでいて、その中で検索数の多さを面積で示し、色が単語を区別するために使われています。\n記事内では「Twitterのノイズから価値を発見する6の方法」として以下の方法をあげています。チャートへのアノテーションとして示しているので、わかりやすいですね。\n競合製品の動向を探る 思いもよらなかった単語を発見する 単語の意味をちゃんと確かめる（一見ネガティブな単語でも商品名の一部だったり、バズったジョークツイートの場合もある） ユーザーからの率直な意見として受け止める 顧客の痛みをわかるためにネガティブワードとも向き合う 突然現れた支配的な単語はその大元を探る Vision Statement: Six Ways to Find Value in Twitter’s Noise\nある週末だけという短い期間ですが、競合製品のKindleが早々に検索されなくなったり、Jailbreakの話があるタイミングから盛り上がったりします。\nただ、この手のStreamgraphは、静止画で仕上げると迫力が出ますが、個別に単語がどういう傾向を辿ったのかを目で追いづらいです。インタラクティブに仕上げると、マウスポインタやタッチされた単語のみをハイライトしたり、絶対値だけでなく相対値で示たり、と伝達の質と量が向上します。\n","date":"2019-08-25T00:00:00Z","image":"http://localhost:1313/hbr-vision-statement/images/F1006Z_A_lg_hu_13a1fa66f087989.gif","permalink":"http://localhost:1313/hbr-vision-statement/","title":"ツイートから価値を発見する6の方法【Streamgraph】"},{"content":"※Yahoo!ニュース個人掲載記事の転載です。\nこれまで検索が難しかった国の事業予算の使いみちを、全文横断で検索できるサービス「Judgit」が登場した。これまで個別にExcelファイルを一ファイルづつ見ていくしかなかったところへ、どんな事業でどの省庁からどの企業へいくら支払われたのか、通常のウェブ検索の感覚で利用することができる。\n仮説や切り口を持っている人のためのフリーワード検索とメタデータ検索、仮説や切り口が思いつかないけど、データからなにか気づきや仮説自体を見つけられないかという人のためのクロスフィルター検索の三種類の検索モードが用意されている。\n報道機関によるネガティブ・チェック機能のためだけでなく、民間の企業や組織へ、どんな事業へいくら支払われているかポジティブ・チェック機能にもなる。\n海外でも同様の事例はある。代表的な事例として、アメリカとイギリスの事例を取り上げる。JUDGIT!と比較して、機能的には大きな違いはないが、特徴は異なる。アメリカの事例では、連邦政府や元MS CEOによる主導で、誰から得たお金を誰へ支払っている、という組織や人種が表立って登場していない。イギリスの事例は民間NPO主導で、数値をそのまま出すにとどまらず、自分の世帯年収（納税額）から換算した、自分に近い市民一人あたりどのくらいの金額が何に使われているのかを示すことによって、自分ゴト化を促している。\n日本において、連綿と続く大小問わず報道機関の使命感ある営み、中央政府側のオープンデータ施策、行革、現在のデジタル・トランスフォーメーションにつながるデータ整備の流れ、民間のシビック・テックやガブ・テック系の活動や事例の増加という流れ、そういった個別の流れが織りなす時代の潮流の中の一つに、このJUDGIT!も位置づけられるのではないか。\n以下、個別に詳細をみていこう。\n国の事業予算の使いみちを、全文横断検索。 これまで検索が難しかった国の事業予算の使いみちを、全文横断で検索できるサービス「JUDGIT!」が登場した。これまで個別にExcelファイルを一ファイルづつ見ていくしかなかったところへ、どんな事業でどの省庁からどの企業へいくら支払われたのか、通常のウェブ検索の感覚で利用することができる。\n国の各省庁が行う約5,000事業のほぼ全てについて「目的」「内容」「成果」「予算の支払い先」などを、一般の検索サイトと同様に誰もが調べることができる。\n事業仕分けを開発・スタートした政策シンクタンクである**構想日本、ジャーナリズムNPOであるワセダクロニクル**、開発を主導した日本大学 情報科学科 **尾上洋介研究室(vdslab)と、データの可視化が専門のVisualizing.JP**によるプロジェクトだ（ディスクレイマー：筆者はVisualizing.JPの主宰者として本プロジェクトに関わっている）。\nフリーワード検索、メタデータ検索、クロスフィルター検索の三種類の検索モードが用意されている。 仮説や切り口を持っている人のためのフリーワード検索とメタデータ検索、仮説や切り口が思いつかないけど、データからなにか気づきや仮説自体を見つけられないかという人のためのクロスフィルター検索の三種類の検索モードが用意されている。\nフリーワード検索 フリーワード検索は、探したい事柄はあるが、それがどこの省庁で扱っているのか、どんな企業が受注しているのか、そういった予断なく探したい人のためのものだ。\nフリーワード検索が行えるのは、トップページの検索欄および「行政事業」（やわらかい言葉でいえばプロジェクト・ベース）検索ページだ。\n行政事業レビューシート全体からフリーワードで検索を行う。\nメタデータ検索 メタデータ検索は、探したい事業の輪郭がわかっている人のためのものだ。\nメタデータ検索が行えるのは「主要支出先」（支払先）「府省庁別」（支払元）「主要施策別」検索ページだ。\n検索対象をメタデータに限定することで、見つけやすさを向上させることができる。たとえば「主要支出先」ページで「オリンピック」と検索すると、支出先名称に「オリンピック」が含まれているもののみがヒットする。\nクロスフィルター検索 クロスフィルター検索は、仮説や切り口が思いつかないけど、データ自体からなにか気づきや仮説自体を見つけられないかという人のためのものだ。\nクロスフィルター検索が行えるのは「行政事業」検索ページ内の「グラフで検索タブ」だ。\n棒グラフにて、府省庁・会計区分・主要施策・予算最少額の傾向を把握できる。同時に棒グラフ自体が、絞り込むためのユーザー・インターフェイスになっている。クリックすると、その内容でフィルターされた結果が、棒グラフでその場で確認できる。\n試しに「府省庁」→「主要施策」で絞り込んでみて、一旦リセットし、今度は「主要施策」→「府省庁」で絞り込んでみてほしい。前者は「府省庁」ごとの事業の傾向をまず把握し、そこから詳細を探索することができる。後者はその「主要施策」がどういった府省庁で行われているのかを把握し、そこから詳細を探索することができる検索の仕方だ。静止画のチャートはたいてい何らかの方法で集計されてしまっている。その集計のくびきからデータを解き放ち、見る人に集計の切り口や順番を委ねることができるのがこの見せ方の特徴だ。\nネガティブ・チェックとしてだけでなく、ポジティブ・チェックにも活用できる。 報道機関によるネガティブ・チェック機能のためだけでなく、民間の企業や組織へ、どんな事業へいくら支払われているかポジティブ・チェック機能にもなる。\n報道機関によるネガティブ・チェックに 良くも悪くも、世に炎上のネタはつきない。その際、関連する事業や組織への受注状況を手早く調べることができる。見つかるはずのものが見つからない場合はデータクレンジングやデータソースの問題である可能性もあるので、事務局へ連絡を。\nコストパフォーマンスという言葉があるように、費用と成果のバランスが大事なのであって、国の予算が支払われたこと自体が悪ではない。ただ、数値やデータを参照しないままでは、見えない幽霊と格闘するようなものなので、そうでなくてエビデンスの一つとして活用してほしい。これをルサンチマン生成システムにしないためには、活用のされ方にかかっている。少なくとも、ルサンチマン生成を助長するようなサービスの作りにはなっていないはずだ。\nもちろんここで掲載されているデータや情報でワンストップで取材が完結するものではなく、情報ソースの一つとしてという前提。ホテルのルームサービスのようにすべてを肩代わりしてくれるものでは、そもそもない。\n事業者によるポジティブ・チェックに 一方で、ポジティブ・チェックに活用することもできる。どういうことか。\nたとえば、大企業に所属している方であれば自社名で検索してみると、自分の知らなかった事業を自社で受注していることを知ることができる。\nもしくは自社の事業ドメインで、どんな事業に国からいくらくらいの規模の予算がついているのかを検索することもできる。\nこれらの情報を自らの事業へ活用することが可能で、たとえば、これまで情報の非対称性から入札に慣れた事業者のみが定常的に落札していた案件に、健全な競争原理を支援することにつながる。\n報道機関や事業者以外の市民にも JUDGIT!自体は無料のサービスで、誰でも利用することができる。ただ、たとえばいきなり一般の方が自分の時間を使って自ら調べるということも、ゴールがないので考えづらい。\n報道機関や事業者、デザイナーやエンジニアによる創作が広がっていくことによって、生のデータベースの周囲に、二次コンテンツ圏とよべるものが広がっていけば、そこにあるストーリーを一般の方が楽しむ、ということは考えられるし、そこを支援できたらと運営団体としても、個人的にも考えている。\n海外での事例 海外でも同様の事例はある。以下、代表的な事例として、アメリカとイギリスの事例を取り上げる。\nJUDGIT!と比較して、機能的には大きな違いはないが、特徴は異なる。アメリカの事例では、連邦政府や元MS CEOによる主導で、誰から得たお金を誰へ支払っている、という組織や人種が表立って登場していない。イギリスの事例は民間NPO主導で、数値をそのまま出すにとどまらず、自分の世帯年収（納税額）から換算した、自分に近い市民一人あたりどのくらいの金額が何に使われているのかを示すことによって、自分ゴト化を促している。\nアメリカの事例 USAspending.gov\nアメリカ連邦政府公式の決算情報を公開しているサイト。Spending Explorerから、お金の使いみちを、施策別、省庁別、購買サービス・商品別に、ツリーマップ形式で見ていくことができるほか、フリーワード・メタデータ検索であるAward Search、組織や団体を切り口にみていくProfilesが用意されている。\nUSAFacts | Non-partisan Government Data\n元マイクロソフトCEOのスティーブ・バルマー氏が自費を投入して構築したサイト。お金の入と出、人口動態、（その結果、国がどういう状態かという）メトリックス、アニュアルレポートで構成されている。お金の入と出がシンプルなチャートで表現されている。\nスティーヴ・バルマーがつくる、「米政府の財政データ」を視覚化する美しきウェブサイト｜WIRED.jp\n初めてプロジェクトが公にされたのはおそらく2016年11月の下記報道で、サービス公開自体はトランプ政権発足後だが、以前の問題意識から数年前から取り組んでいだようだ。\nSteve Ballmer’s Plan to Make America Great Involves Excel Spreadsheets - Bloomberg\n特徴的なのは、どんな分野から入と出があるかは示されているが、誰から誰へという組織や人種が登場しないこと。そもそもマクロなお金の使い道をざっくり認識するためのものとして詳細を省いたともいえるし、「誰」が扱われた瞬間、議論が別な方向で進んでいくことを抑制しているとも受け取れそうだ。\nイギリスの事例 Welcome - Where Does My Money Go?\n政府側のサービスとしてではなく、民間NPO団体主導で同様のサービスが2009年に作られた。NPO団体Open Knowledge Foundationが2009年に初めて公開した、政府予算の使いみちを可視化したサイト。\n当初のヴァージョンは、支払った税金のうち、一世帯あたりいくら支払ったものが何に使われているかを示すことによって「自分ゴト化」を促すつくりになっていた。\n上記サイトのソースコードを元に日本版が盛んに作られた。今でも日本語でみることができる。\n税金はどこへ行った？ - WHERE DOES MY MONEY GO? -\n現在は活発な活動にはなっておらず、データの更新状況自体は各自治体版ごとにマチマチのはずだ。最終的に173基礎自治体まで広がったこのムーブメントは、日本における初期のシビック・テック活動の中心の一つであった。\nイギリス版に話を戻すと、現在のヴァージョンは、おそらくデータフォーマットが共通化していることで全世界を横断検索できるOpenSpendingというサイトと、そのイギリス版という位置づけのWhere Does My Money Go?というというサイトの二層構成になっている。\n日本におけるここまでの流れ 日本において、連綿と続く大小問わず報道機関の使命感ある営み、中央政府側のオープンデータ施策、行革、現在のDX（デジタル・トランスフォーメーション）につながるデータ整備の流れ、民間のシビック・テックやガブ・テック系の活動や事例の増加という流れ、そういった個別の流れが織りなす時代の潮流の中の一つに、このJUDGIT!も位置づけられるのではないか。\nそんなふうに筆者が認識できたのは、オープンデータ伝道師として著名な庄司昌彦さんがFacebookにこんな投稿をされているのを読んだからだ（公開範囲を限定した投稿を、許可を得て転載）。\nとても良い。課題はまだまだあるけど、こういうことができるようになったのはほんとうに感慨深い。\nここまでくるには長い長い道のりがあったといえる。行政事業レビューはまさに構想日本の事業仕分けから始まったものだし、民主党政権時代にそれを取り入れパフォーマンスを批判されながらも裏側でオープンガバメント・オープンデータ的要素を取り入れてくれた蓮舫議員などの貢献も大きい。そして、民主党政権の代名詞ともいえる事業仕分けを行政事業レビューとして改良し維持発展してくれた自民党の行革系の方々がいて、「税金はどこへ行った」などのシビックテック系の活動があって、調達情報や法人番号などの裏側のデータ整備やデータ連携を進めた電子政府関係の方々の仕事があって、そして、このサイトを作った人たちの仕事があって…。\n出典:https://www.facebook.com/mshouji/posts/10157480939181823\n","date":"2019-08-25T00:00:00Z","image":"http://localhost:1313/judgit-overview/images/fi_JudgitOverview_hu_20a69fa571b5dbf2.png","permalink":"http://localhost:1313/judgit-overview/","title":"国の事業予算の使いみちを全文横断検索できるサービス「JUDGIT!」"},{"content":"「データ可視化」という言葉を使うとき、何だかふわっとしてるなと感じませんか？\nデザイナーとしての一個人としてはこのようなモヤモヤ体験があります。\n「あくまでデータ分析がメインなのであって、可視化はその結果、おまけにすぎない」\n「そのインフォグラフィック、良いんだけど、でもそれって統計的有意はないのでしょう？」\n私が思うに、世間一般的に 「データ可視化」 という言葉が指し示している対象が異なるのではないでしょうか。異なることを語っているのに同じ言葉を使っているのですれ違ってしまう。外来語あるあるですね。\n１つ目、 探索行為 としてのデータ可視化。 ２つ目、 分析結果 としてのデータ可視化。 ３つ目、 表現や伝達 のためのデータ可視化。 です。図示すると以下の通りです。\n「問いを立てる」 というのは、知りたいこと、調べたいこと、関心があることなどテーマ全般を指すものとします。\n「仮説を立てる」 というのは、すでに出版されている本や研究結果を知ったり、詳しい人や当事者に聞きに行くことと同様に、すでに存在しているデータや自分で集めたデータを元にして可視化をする。それらのことで仮説を立てる、ということを指します。\n「分析する」 というのは、データ分析全般をここではざっくり指すものとします。ここも学術・手法・目的などでいくらでも細分化できそうですが、本文章ではスコープ外としてこの程度の言及とさせてください。\n「表現・伝達する」 というのは、表現であれば最終的な成果物（アウトプット）として完成させることや、それを他者へ伝えることを指します。\nここへさらに**「誰にとって」**という視点を加えると、より違いが鮮明になります。\nここではデータサイエンティストを社会の実課題を解決につなげることを目的とする実務者に含めています。\n研究者や実務者にとって、探索的データ分析・可視化や、確証的データ分析・可視化は馴染み深いものだと思います。\n市民データサイエンスとして、ここに市民が付け加わります。市民にとっての探索的データ可視化は、たとえば大多数の関心はないけれども自分にとっては切実な問題や、思いつきや問題意識です。この図の冒頭にリサーチクエスチョンとありますが、何をテーマだと思うかは、研究成果ということに範囲を絞らなければ、市井（しせい）の人、どなたにでも開かれているものだと思います。ただ思いついただけでは、誰かに伝えることができませんし、言葉で伝えたとして聞いた人が正確に伝言ゲームに参加できるかというと、記憶の細かさはどうしても落ちてしまいますし、そもそもその思いつきがどのくらいのインパクトのあるものなのか、客観的に人へ示すことができません。ここに具体的な手段を提供するのが市民にとってのデータ可視化です。\nデザイナーやアーティストにとっては、探索的行為としてのデータ可視化と表現・伝達としてのとデータ可視化が明確に区別されていないと感じることがあります。テーマとコンセプトとデータと表現が、自分の得意な手法であらかじめ決め打ちされてしまっているといいますか…。この辺りの問題意識を昨年から多摩美術大学で持たせていただいている三年生向け「可視化演習」では取り組んでいこうとしています。\nこうしてみていきますと、データ分析の結果としてのデータ可視化以外にもデータ可視化の使い所はあります。インフォグラフィックの内容が統計的有意を含めなくてもよい点についてはここで書ききれていないのでまた今度。\nそして長くなってしまったので記事を改めますが、次以降の記事では**「誰」×「指し示している対象」**別に、必要なことや課題を取り上げていこうと思います。\n","date":"2019-08-24T00:00:00Z","image":"http://localhost:1313/viz-for-whom/images/picture_pc_508a912df679a6045d79eb479914817f_hu_a96f6113a1d361f.png","permalink":"http://localhost:1313/viz-for-whom/","title":"「データ可視化」の指す、三種類の行為"},{"content":"ローカル環境で簡易サーバを手軽に起動できる方法の一つとして、テキストエディタを使った例を紹介します。\nテキストエディタ：Visual Studio Code テキストエディタ：Visual Studio Code メリット テキストエディタで開発しつつ、その場で簡易サーバとしての動作の確認が行えます。 ファイルを修正し保存すると、自動でブラウザをリロードしてくれますので、何度もブラウザをリロードする手間から解放されます。 Live Serverのインストール Live Serverのインストール Extension（拡張）としてインストールします。\n作業するディレクトリを開く Explorerから、作業するディレクトリを開きます。\nサーバを起動する ウインドウ右下の Go Live をクリックします。\nサーバを停止する ウインドウ右下の Go Live があった場所でポート番号が表示されています。ここをクリックするとサーバは停止します。\nそのほか ポート番号は5500が使われます。複数のプロジェクトで同時に使用することもできます。その場合は、5501、5502…とポート番号が1づつ増えていきます。\n","date":"2019-08-24T00:00:00Z","image":"http://localhost:1313/vcs-liveserver/images/fi_VcsLiveServer_hu_3d713fa078511920.png","permalink":"http://localhost:1313/vcs-liveserver/","title":"【ワークショップなどで便利】ローカル環境で、自動リロードする簡易サーバを手軽に【Visual Code EditorとLive Server】"},{"content":"PDFに含まれている表をテキストデータとして抜き出すことのできるTabulaというアプリケーションがあります。\nTabula インストール型なので最初は少し手間ですが、精度が高いのと、ナイト財団などの複数の財団の助成を受けているので、今後もメンテナンスが続いていきそうです。\nWindows OSへインストールする際に、文字コードの関係で、少し手間がかかります。TabulaはUTF-8で起動することを想定した作りになっているのに、Windows OSではShift-JISで起動しようとするため、エラーが発生して起動しないということになります。\n対処方法 バッチファイルを作成して、今後はアプリファイル（tabula.exe）ではなく、そのバッチファイルをクリックすることで、Tabulaを起動することにします。 そのバッチファイルには文字コードをUTF-8で起動することが記述されています。 というやり方になります。\n用意するもの UTF-8での記述に対応するテキストエディタ マイクロソフトのVisual Studio Codeがおすすめです。 Visual Studio Code – コード エディター | Microsoft Azure 作業手順 Tabulaが保存されているディレクトリにて、テキストエディタでtabula.batというファイルを作成します。 そのファイルの中には以下の二行を書きます。 1 2 set RUBYOPT=-EUTF-8 tabula.exe 以上です！やってしまえば簡単でしょう？以下のリンク先にて制作済のファイルを配布しています。\nhttps://github.com/data-visualization-lectures/tabula 注意すること タスクが複数立ち上がりっぱなしの場合、うまくいかないことがあります→タスクマネージャーを開いて、Tabula関連のタスクをすべて閉じてから、起動するとよいです。 ","date":"2019-08-24T00:00:00Z","image":"http://localhost:1313/tabula-windows-install/images/fi_TabulaWindows_hu_d574684fef94e1d0.png","permalink":"http://localhost:1313/tabula-windows-install/","title":"Tabula Windows版のインストールがうまくいかない方へ"},{"content":"※日経ビッグデータ2014年4月号掲載記事の転載です。\nデータ活用とデータ分析の間には「データ可視化」、最近は「データビジュアライゼーション」と呼ぶ段階が存在している。 オープンデータが広がる今、市民がビジュアライゼーションの基本を身に付けることが社会を変える第一歩となる。\n情報デザインの世界で著名な米カリフォルニア 芸術大学デザイン戦略MBAプログラム・ディレクターのネイサン・シェドロフ氏が考案した「理解のスペクトル」という図だ。単なる「データ」が「知恵」になるステップを説明するものだ。\nデータはそのままでは人の記憶に残りづらい。量が膨大だったり、特徴が視覚的に捉えづらかったりするからだ。そこでチャートやグラフなどで表現すると、特徴を視覚的に捉えられ短期記憶に残る。これは「情報」と呼ぶが、過去の経験や記憶と結びつき自分ごとになり得る。\n人はそれぞれ立場が異なる。データの絞り込みや視点の変更といった\n「柔らかで動的なユーザーインターフェース」が大事だ。うまく機能する ことで、腑に落ちる。これが「知識」であり、経験を通じて「知恵」になり、さらに同じ知識を多くの人が共有し常識となっていく。\n相手の状況で異なる伝え方 こうして相手に何かを伝えようとするとき、相手が能動的に接しようとしているか、もしくは受動的かによっても伝え方を変えていく必要がある。また、相手の知識の多寡によっても、伝え方や伝える順番を考慮 する必要がある。知らないかつ受動的な場合、興味を持ってもらうために訴求方法を工夫し、エンタテインメント性を高めなければならない。\n多くのチャートやグラフは、2次元(ディメンジョン)程度しか表現できず、工夫を凝らすことは難しい。そこで世に存在する多数のデータの中から適切なものを組み合わせ、次元を追加して表現することが有効である。意図したインサイトが表現できれば、誰にでも開かれた「データ分析の大衆化」につながる。\n自治体や国がオープンデータを公開するようになった。また、国や自治体だけでなく民間企業のデータ活用を後押しするための基本法「官民データ活用推進基本法」が成立。個人が自身のデータの流通に積極的に関与するようになる。オリンピックまでの期間を国が「オープンデータ2.0」と名付けるなど、データ活用の社会的な機運が高まっている。\n東京オリンピック・パラリンピックのボート・カヌー会場は提案時の会場が思いのほか高額になったため、他の候補地が検討された。五輪 組織委員会はコスト増大、選手輸送、宿泊施設など9つの問題点を挙げた。\n仮にこれらを、それぞれの会場ごとに、実現度と足りない部分を追加するとどこにいくらかかるのか、全てを一覧できる一枚の大きなマトリックスのチャートで表現したらどうだったろう。1つの価値観、つまり1つの次元だけで比較できないからこそ、いくつもの価値観で同時に比較 することが欠かせない。\nデータから知識・知恵を紡ぎだし、人の心に寄り添い、社会をよりよくすることに役立てられるデータビジュアライゼーションの果たす役割がこれまで以上に重要となっている。市民が自らその基本を習得することが、知識、知恵を広げて社会を変える第一歩となる。\n","date":"2019-08-24T00:00:00Z","image":"http://localhost:1313/nikkeibd-201404/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/nikkeibd-201404/","title":"データ可視化は相手の腹に落ちて価値が出る"},{"content":"データ可視化において、色はデータの性質を過不足なく表現するために利用されるべきでしょう。そのための考え方の入り口をご紹介します。\nカラースペースとは？ 事務のお仕事でWordを使っている人や、デザインのお仕事でPhotoshopを使っている人は、色を指定する際に、RGBやCMYKという文字をみかけていると思います。これはカラースペースとよばれる、一つの色を指定するための、色をつくる方法です。\nRGBとは Red（赤）、Green（緑）、Blue（青）を混ぜることによって、一色の色をつくる方法です。液晶ディスプレーにおいて色を発色する仕組みとして採用されています。出力の強さが3つともゼロであれば真っ黒、出力が最大になると真っ白になるような、色の作られ方です。\nCMYKとは Cyan（シアン）、Magenta（マゼンダ）、Yellow（黄）Black（黒）を混ぜることによって、一色の色をつくる方法です。印刷物において色を発色する仕組みとして採用されています。インクの量がゼロであれば真っ白（白い紙の色のまま）、4つのインク量が最大になると真っ黒になるような、色の作られ方です。\nRGBやCMYKは実はデザインやカラーパレット生成には向いていない？ 光の三原色がRGBであること、その補色でCMY（+K）があり、色を人工的に再現する方法として、ディスプレイや印刷物において色を表現する仕組みとして採用されています。最終的にディスプレイや印刷物で色を表現するためには、これらを用いて指定することになります。\nところが、たとえば複数の色の組み合わせ（カラーパレット、カラースキームなどと呼ばれます）をどう選択すべきか、特に、あるデータ・セットの特性にあわせて選択する際に、RGBやCMYによってカラーパレットを生成するのは非常に困難です。なぜならRGBにしてもCMYにしても、すべてが色相（色の区別そのもの）を表す軸だからです。頭の中でこれらの複数の色の組み合わせによる新たな一色の創出は困難ですし、覚えたり慣れたりしたとしてもデータの特性に合わせて生成するのは困難だといえます。ではどのような指定が最適なのでしょうか?\nそこで登場するHSB HSBとは？ Hue（色相）、Saturation（彩度）、Blightness（明度）の3つの要素から一つの色をつくることができるカラースペースです。色相は色の区別そのもの、彩度は飽和度や純度ともよばれるのですが色の鮮やかさのこと、明度は明暗を表します。この3つの数値変化によって、一つの色を表します（HSBと似たカラースペースにHSVというのもあります）。\nデータ構造と一致させやすいHSB ある文字データを色で表す際に、どういうふうに色でどう表せばよいでしょうか。具体的には、名義スケールや順序スケールとよばれる、たとえばAとBは異なるんだよ、ということを表します。そのためには区別する必要がありながら、存在感の強弱は揃っていてほしいです、と。この場合には、彩度と明度は揃えておきながら、色相のみを変化させることによって複数の色を生み出せばよさそうです。\nある数値データが0〜10000の幅で存在するときに、この変化を色でどう表せばよいでしょうか。具体的には間隔スケールや比例スケールと呼ばれる数字のデータで、存在自体を区別する必要はなく、ただ数値の大きさや差が区別できればよいので、この場合は色相は固定で、明度の変化によって、数値を表現すればよいということになります。この場合は彩度も固定にしておきます。\nそしてHSBなら、主なOSで標準的に利用でき、代表的なグラフィックアプリでも利用可能です。\n主なOSやアプリにおける利用可能なカラースペース アドビ社Photoshop\u0026hellip;RGB、CMYK、HSB、Lab アドビ社Illustrator\u0026hellip;RGB、CMYK、HSB Sketch\u0026hellip;RGB、HSB Mac OSX標準\u0026hellip;RGB、CMYK、HSB Windows OS標準\u0026hellip;RGB、HSB しかしファイナルアンサーではないHSB 合理的なHSBですが、実はこれがファイナルアンサーではありません。なぜなら、色によって人間の眼の感度が異なるからです。\n“Photopic Spectral Sensitivity Function”（Kaiser、96）\n\u0026ldquo;Visualization Analysis and Design. Tamara Munzner, with illustrations by Eamonn Maguire. A K Peters Visualization Series, CRC Press, 2014.\u0026rdquo;\nつまり、彩度や明度を揃えて複数の色を生成したとしても、波長によっては（緑や黄など）、人間は数値指定されて生成された色を、値よりも高感度に認識（明るく感じられる）してしまいます。\nウェブデザイナーがカラーパレットをつくる際は、OSやグラフィックアプリのレベルでは、RGBかCMYKかHSBしか選択肢がないので、この辺り、おそらく目分量で調整しているのではないかと思います。私はそうやっていました。もちろん、文字色なのか広い面のベタ塗りなのか、色が使用される面積によって受ける印象や可読性は異なりますが。\n人の眼の色認知能力に近いカラースペース L*A*B* 今度は、人の眼の色認識能力をみてみましょう。人の眼の網膜にある二種類の受容体のうちひとつ、錐体には3つのタイプがあり、それぞれが異なる感度をもっています。輝度チャンネル、赤緑チャンネル、青黄チャンネルの3つです。この性質にあわせたカラースペースがL*a*b*です。Lが明度で、aが赤緑、bが青黄の色相です。赤緑色盲の方は赤緑チャンネル(a)の錐体の感度が生まれつき低いということになります。\nPhotoshopの色選択ウインドウ\nL*a*b*は上記にあげた中ではPhotoshopでしか利用できないですし、明度に加えて色相が2軸ですので、直感的に色は選びづらいことには、かわりありません。\nでは実際にどうするか? では、「HSBに代表されるような、データの性質と一致させやすい合理的な色選択システム」と「人の眼の網膜の性質」のギャップをどう埋めるのか、そしてデータの特性にあったカラースキームをどのように作ったらいいのか。後者については、いわゆるプレゼンテーション用以外にも、データを探索的・分析的にみるためのカラースキームの作り方、という考え方もあります。\nここから先はぜひ「データビジュアライゼーション講習」を受講し、学んでください。\n","date":"2018-06-23T00:00:00Z","image":"http://localhost:1313/color-space/images/fi_ColorSpace_hu_d0c2c11202698521.png","permalink":"http://localhost:1313/color-space/","title":"データ可視化にとって最適なカラースペースは？"},{"content":"オープンデータ、ビッグデータというキーワードがここ数年普及してきており、活用する機運が高まっています。本格的なデータ分析までは必要ないもののデータを活用したい、という需要があるが、何をどう学んだらいいかわからない、という声をよく聞きます。\nこれに答えるものとして、統計学を学ぶことが必須とされていますが、実は統計学が前提としている「確証的データ分析」に対して「探索的データ分析」という考え方があります。統計学によるデータ分析の結果が出てから初めて可視化を考えるのではなく、まずはデータを可視化してみるところから探索的にデータの活用の仕方や分析を考えるというアプローチです。課題が何かはっきりしていれば、それに即した統計学の手法を用いればよいですが、そもそも何が問題かがわからない段階では手段を選択することができません。「確証的データ分析」のみを前提としていると、そこで行き止まってしまいます。\nコンピュータが大衆化し、大学のスーパーコンピュータだけではなく、一般的に手に入るコンピュータで充分可視化が行えることや、データが多種大量に存在しているにもかかわらず、可視化すらされず放置されているものが膨大に存在しているという現状があります。\nこれらの状況を踏まえて、問いの立て方から、データの扱い、可視化、プレゼンテーション、評価までを、実務・原理原則の両方を踏まえながら学ぶことができ、何をどう学んだらいいかという需要に答えることのできる講習が必要だと考えております。\nAI時代においても、コンピュータに自動的に判断させないもの、人間が最後に意思決定をするものは、動的なユーザーインターフェイスになるはずです。また、人は自分が手を動かして意思決定したものにより納得するIKEA効果が知られています。データビジュアライゼーションのトレーニングはそこでも活かされると考えています。\n","date":"2018-05-18T00:00:00Z","image":"http://localhost:1313/meaning/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/meaning/","title":"データビジュアライゼーションを学ぶ意義"},{"content":"※Yahoo!ニュース個人掲載記事の転載です。\nYahoo!ニュースで記事を書かせていただくことになりました矢崎です。私はデータ・ビジュアライゼーションとよばれる領域で実務家として活動しています。\nデータ・ビジュアライゼーションとは データ・ビジュアライゼーションという言葉、聞いたことがありますか？インターネット検索するとたくさんのページがヒットしますが、言葉を分解すると「データ」と「ビジュアライゼーション（可視化）」でして、昔から存在していたもののようにもみえます。いったい何が新しいのでしょうか？\n二つの一般名詞が合体して、新しい言葉「データ・ビジュアライゼーション」として語られる際、まずはチャートやグラフ、地図を思い浮かべてほしいのですが、これらがインターネット・ブラウザ上で、年代・地域など、色んな切り口で操作可能なことが最大の特徴です。ここでのポイントは操作して動かせると楽しい、ということだけではなく、データの切り取り方をユーザーが選べることでコンテンツをより自分事にすることができたり、多様なモノの見方を提供できること、などにあります。\n統計学で存在しているチャートやグラフの原理原則、地図の世界で確立されてきた視覚的な原理原則、サイエンスの世界で活用されていた可視化技術、それらを現代の視点で包括的に扱い体系化した知といえそうです。\nこれらの技術を用いることで、一般の人であっても新しい価値観の提案ができるのではないか、ということに可能性を感じ、この連載を「新しい単位」としました。\n（説明が足りていない部分もあるかと思いますが、今後の記事の中で徐々に触れていきたいと思います。）\nYahoo!ニュースでカバーする範囲 で、具体的には何を書くの？という話なんですが、Yahoo!ニュースですので、データ・ビジュアライゼーションが網羅するすべての領域ではなく、社会課題に関わっている事柄について書いていこうと思います。エンターテイメントへの適用、メディアアート作品など、データ・ビジュアライゼーションならではの楽しい領域があるのですが、泣く泣く割愛します。\n「シビック・テック」 私は コード・フォー・トウキョウ という団体で活動しています。アメリカで始まった Code For America という団体の活動を2012年に知り影響をうけたこと、日本でも コード・フォー・ジャパン の活動が始まったこと、少し遡って2010年ごろのGov 2.0の動きに受けた影響に端を発しています。これらの活動は「シビック・テック」と呼ばれています。「シビック」（市民の）と「テック」（テクノロジー）をあわせたこの言葉の定義の話をはじめると別な記事がひとつ必要になってきてしまいますので以下のページを参照いただき、\nテクノロジーで地域課題を解決、草の根的に広まる「シビックテック」とは【柴田重臣】\nここでは一旦手短に「行政と住民、デザイナーやプログラマー、データ分析家などが連携して、行政サービスに類するサービスを、IT技術やオープンデータを活用して実現するコミュニティ活動を指す」とします。\nこの活動のほか、データ・ビジュアライゼーションの専門家として、他の地域で活動されている団体から呼んでいただいたり、勝手に押しかけたり（汗）することもあります。これらの活動の中で得た知見や経験・視点などを、当事者・観察者として、社会へ紹介していけたらと思います。\n日本や海外での事例紹介 また、上記以外の日本での事例、海外での事例も紹介していきます。海外での事例についてはこれまではIT系海外翻訳メディアなどで、数あるコンテンツの一つとして、散発的にデータ・ビジュアライゼーションの事例が日本語で紹介されていることがありましたが、その領域の話が集積しているメディアは、日本語ではまだあまりないように思えます。この連載がその一助となればと願います。専門家の観点から日本社会にとってどのような意味がありそうか、どう適用可能か、関連する事例はあるか、どういう人たちが関わっているのかなど、単なる翻訳にとどまらず時には当事者へ問いかけながら、コンテクストをあきらかにしていけたらと考えています。\n","date":"2017-08-05T00:00:00Z","image":"http://localhost:1313/what-is-dataviz/images/fi_WhatIsDataviz_hu_ee7db1cd77146a3a.png","permalink":"http://localhost:1313/what-is-dataviz/","title":"社会課題を可視化する「データ・ビジュアライゼーション」とは"},{"content":"「A地点からB地点まで」。いわゆるナビゲーションシステムによるルート案内を、感性に訴えるものにしようという提案をした研究者がいます。彼の話を聞いてみましょう。\n彼のとった方法論としては、大きく２つ。\n一つ目はロンドンで実施したといいますが、クラウドソーシングを利用して、Google Street ViewやGeographから取得した位置情報を持っているAとBの２つの写真を同時に見せ、どちらがより「美しく、幸せ」にみえるかを人間に選んでもらい、その結果をナビゲーション結果表示に利用する、というものです。実際に美しいと感じるかどうかを住民30人に歩いてもらい検証したそうです。写真を撮った本人以外がタグ付け（評価）に参加できるところが面白いですね。\n二つ目は500万枚あるFlickr上の写真と、ポジネガ判定したそのコメント文を利用し、同様のアルゴリズムを用いてボストン版を制作（つまりクラウドソーシングを使わずにFlickr上のテキストデータを用いた）したそうです。こちらでも数十人でテストして実証できたそうです。\n美しさを尊重しても12%ほどしか時間が長くならなかったそうです。\nこれは、バルセロナにあったYahoo Labs（2016年2月にYahoo! Researchへの組織改編にともなって解散）に所属していたダニエレ・クエルチャ氏がLabsに入る前から進めていた研究を、Labsに入ってから三名で結実させ、論文として公表したものです。\nThe Shortest Path to Happiness: Recommending Beautiful, Quiet, and Happy Routes in the City\n欧州においてバルセロナはICT分野で抜きん出た功績を挙げている都市なんだそうで、「初音ミク」の基礎技術をヤマハと共同研究したのがバルセロナの大学のようなんですね。Yahooがラボをバルセロナに置いていたこともそれを裏付けしそうです。\nヤマハ・剣持秀紀氏のVOCALOID開発昔話\n初音ミクに使われている技術ってメイド・イン・カタルーニャだったのか！って話\n通常のナビゲーションシステムでは主に、いかに早くたどり着くか、もしくは安くたどり着くかが提案されます（カーナビのように渋滞を避けるようなものもありますが）。これは、早かったり安かったりすることが良いことである、という価値観自体が、ナビゲーションシステムにすでに組み込まれてしまっているともいえるし、そういう価値観があるからこそ作り出されたともいえそうです。\nこのこと自体は自明ではあるのですが、しかし人は時には、通勤であってもひと駅余計に歩いていつもと違う道を歩きながら新しい景色を探しながら歩いたり、大きい荷物があるときないときでルートを変えたりしているはずです。また旅行でその都市を訪れた人が、住んでいる人のように町を歩く手がかりを得られるのかもしれません。\n客観データ（地形、交通、公的施設、売店や商業施設）などは（場所によりそうですが）かなりの部分がデータとしてストックされ、実際に一般ユーザーに利用されていると思うのですが、さらに細微な人の指向性に寄り添うためには、このような主観データといえるものを、コンセプトや絵ではなく、実際のサービスとして提供されると、より人の価値観へ訴えかけそうです。\nTED ダニエレさんがこの話をTEDで7分くらいで話してますのでよかったらどうぞ。\n最も楽しい経路が選べる地図\n紹介記事 VentureBeat MIT Technology Review 秋元@サイボウズラボ・プログラマー・ブログ ","date":"2016-07-20T00:00:00Z","image":"http://localhost:1313/most-beauty-route/images/fi_MostBeautyRoute-1_hu_a8922a1859a852aa.png","permalink":"http://localhost:1313/most-beauty-route/","title":"「最も美しい」や「最も楽しい」道順を提案する研究"},{"content":"国立国会図書館 初のデータビジュアライゼーションイベントが開催されます。\n国会図書館にはデータがたくさん 国会図書館には収蔵している書籍に関するデータもあるのですが、今回は「ウェブサイト」がテーマとなっています。 国会図書館では、15年前よりウェブページのアーカイブをおこなっており、その結果はWARPというウェブサービスとして公開されています。\nWarp – 国立国会図書館インターネット資料収集保存事業\nデータを探しだそう 今回はこれらの中から、地方自治体ウェブサイトのメタデータなどを使って、データ・ビジュアライゼーションを行います。今回のイベント専用に、データ取得サイトを用意しています。ヤフーなどで検索するように、検索した結果をデータセットとして取り出すことが可能となっています。APIを扱うエンジニア・スキルは今回必要ありません。 地方自治体というとちょっと硬そうですが、私達の出身地や今住んでいる場所についての個性がここからわかってくるかもしれません。\nたとえば…? 都道府県同士の関係性に注目してみましょう。都道府県それぞれのサイトから、他の都道府県サイトへ、どのくらいリンクが張られているでしょうか。またそこには何らかの偏りがあるでしょうか。昔と今とで何か違いがあるでしょうか。\n都道府県、どう並べる？ グラフの種類が…とか、ツールが…と考える前に自由に発想してみましょう。 円状に並ぶと、かわいいですね。\n一直線に並べてみたり。\n地図っぽく並べてみたり。\nつながりを視覚化してみる それではこれらを使って、都道府県同士のつながりを線で表現してみましょう。つながりが強いほど太い線で表してみます。またつながりの質によって色を変えてみることにします。\n円状 円状に置いた都道府県同士を曲線でつないでいます。またつながりが多い都道府県ほど、弧の長さが長くなっています。\nここでは静止画でいくつかの都道府県にフォーカスしてみましょう。\n八方美人な北海道\nたくさんの都道府県にまんべんなくエールを送る、そつのない北海道。\n関東エリアと大阪のみの東京\n意外と付き合いの範囲が狭い東京（汗）。\n自由奔放な長崎\n長崎さん。自由すぎます（笑）。おつきあいの内容が気になります。\nこれは国会図書館で公開している可視化のサンプルでもあります。国会図書館サイト上で見ていただくと、他の都道府県の様子もみることができます。\n都道府県サイトのリンク関係\n一直線 この例は筆者の作例で、個別の関係性を明らかにすることよりも、全体的にみたときの印象を重視してみました。\n地図っぽく この例も筆者の作例で、個別の関係性を明らかにすることよりも、全体的にみたときの印象を重視してみました。日本列島を描かずに、日本を浮かび上がらせたらと思いました。\nこれらはすべて同じデータを元にしたものです（フォーマットは少し異なります）。同じデータからであっても、このように色々な表現が可能なことがおわかりいただけるかと思います。\nツール紹介 Tableau Public パソコンにインストールするソフトウェア。数十万円するソフトウェアですが、Publicヴァージョンを利用すると無償です。制作したものをウェブで公開することを条件に、無償となっています。\nTableau Public\nRAW ブラウザ上でチャートを作成できるツール。ダウンロードし、イラストレータで加工する、といった使い方が可能です。\nRAW\nインフォグラム ブラウザ上でチャートを作成できるツール。\nインフォグラム\nD3.js 今回の「一直線」、「地図っぽく」の例のように、一から好きなようにコーディングで作るにはこのライブラリを利用します。\nD3.js\nQGIS パソコンにインストールするソフトウェア。無償。地図上にてデータを可視化するのが得意です。\nQGIS\nハッカソンに参加しよう ツールは一部難しいものはありますが、しばらく使えばなれてしまうことと思います。また不明点は会場で教えてもらうことも可能となっています。 今回のハッカソンでは、都道府県の特徴や関係性を、データベースから如何に探すか、という面白さがあると思います。 名産物の単語がどのくらい含まれているのか？　方言は？　また他のデータを同時に扱うことで、これまでわからなかった特徴が浮かび上がってくるかもしれません。 ウェブサイトの大きさと人口に関係はあるのか？　人口が減っていく地方自治体のサイトに共通の予兆はあるのか？　自治体の広報予算とウェブサイトの大きさに関係性は見いだせるのか。 パッと思いついたものだけ上げましたが、ここのアイディア次第で、面白い作品が作れると思います。 ツールを使いこなして、データから何かを発見する。お互いの成果をみることも、ためになるし、面白い体験になると思います。\n","date":"2016-07-13T00:00:00Z","image":"http://localhost:1313/ndl-dataviz/images/ndl2016-1-1_hu_11c924dcefbff73e.png","permalink":"http://localhost:1313/ndl-dataviz/","title":"国立国会図書館 初のデータビジュアライゼーションイベントが開催されます"},{"content":"D3.jsでレスポンシブ・レイアウトを 最近はウェブの閲覧環境が多様化し、PCとモバイルでは画面解像度が全くことなります。\nD3.jsでなにかを作る際、ワンソースで多様な閲覧環境に対応するための、レスポンシブ・レイアウト対応方法の一つを以下に紹介します。\nD3.jsはSVGを使っている そこで、SVGが標準でサポートしている属性を使います。\n個別の要素の大きさをすべて調整するのは大変なので、一番親要素のSVGの大きさを変更することで対応することにします。\nviewBoxとpreserveAspectRatioの設定 viewBoxとpreserveAspectRatioという属性の設定をします。\nこれはSVGが拡大表示されたときの振る舞いを決定するものです。\nSVGのviewBox属性が分かり辛い 座標系, 変換, 単位 – SVG 1.1 （第２版） 1 2 .attr(\u0026#34;viewBox\u0026#34;, \u0026#34;0 0 960 400\u0026#34;) .attr(\u0026#34;preserveAspectRatio\u0026#34;, \u0026#34;xMidYMid\u0026#34;) viewBoxの値は、\u0026ldquo;0 0 width height\u0026rdquo; とします（widthとheightは整数）。\npreserveAspectRatioの値は xMidYMid とします。これでviewBoxのX/Y中央値を、ビューポートのX/Yの中央値に揃えることになります。\nウインドウサイズが変更した際に、SVGの大きさも変更する 1 2 3 4 5 6 7 8 9 10 var chart = $(\u0026#34;#chart\u0026#34;), container = chart.parent(); $(window).on(\u0026#34;resize\u0026#34;, function() { var targetWidth = container.width(); chart.attr(\u0026#34;width\u0026#34;, targetWidth); chart.attr(\u0026#34;height\u0026#34;, Math.round(targetWidth / aspect)); }).trigger(\u0026#34;resize\u0026#34;); svgの親要素の横幅を取得し、SVGをその大きさに合わせます。\n縦幅は独自には取得せず、横幅との比率で処理をします。\nサンプルコード responsive layout with d3.js 参考リンク Whats the best way to make a d3.js visualisation layout responsive? Responsive d3.js | tnoda ","date":"2016-01-01T00:00:00Z","image":"http://localhost:1313/responsive-d3/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/responsive-d3/","title":"D3.jsでレスポンシブ・レイアウトを実現するには"},{"content":"D3.jsを使って、チャートを一つウェブに表示することはexampleを利用すればできますが、たとえば以下のような場合にはどうしたらいいでしょうか。\n・データが異なるバーチャートをいくつか掲載したい\n・カラースキーム（色の指定ルール）が異なるバーチャートをいくつか掲載したい\n・バーチャートとパイチャートに同じデータを適用したい\nこれらのような場合に、一つひとつexampleのような書き方をすると冗長ですし、整合性をヒューリスティックに確かめなければなりません。D3.jsのメインコントリビューターであるMike Bostockが使った‘reusable’=再利用可能、というキーワードがここで登場します。\nTowards Reusable Charts 再利用可能なチャートに向けて ただ、再利用可能なチャートのためのフレームワークはD3.jsには含まれていず、個々人で用意するか、既存のD3.jsをラッピングしたライブラリを使う必要があります。他のプログラム言語だとクラス化するところですが、JavaScriptはクラスの仕組みがないのと、D3.jsの実装にも特徴があるので、それに沿った実現の仕方が必要です。カプセル化しクロージャの仕組みを利用する、というのが定番になっているようです。\nボストンのデベロッパー会社bocoupでは再利用可能なことについての記事と、その考えを適用したライブラリ（d3.Chart）をリリースしています。\nhttp://misoproject.com/d3-chart/ http://bocoup.com/weblog/reusability-with-d3/ また、D3.jsのグーグルグループ参加者の有志でreusableな実装の仕方についてまとめた本が出ています。\nDeveloping a D3.js Edge bocoupのメンバーが提案している再利用可能であることの特徴として以下のような定義をしています。\n(bocoup Irene Rosの講演、Fluent 2013: Irene Ros, \u0026ldquo;The ABC of Data Visualization\u0026rdquo;からの引用)\nRepeatable - かんたんにいくつも作り出せること Configurable - 特定のタスクのための適切な変更がかんたんに行えること Extensible - 機能の拡張がかんたんなこと Composable - 他のチャートとの組み合わせがかんたんなこと 世の中にあるD3.jsを活用したライブラリというのはあまねく、D3.jsを包み込んだ上で、APIを簡略化したり、機能を足したもの（そのどちらかか両方）である、ということができます。\nこれらのリソースを参考に、ぼくも自分で使う用にライブラリの整備を進めています。\n・データやDOMと、チャート描画メソッドを分離しておける。\n・getter/setterメソッドを用意することで、ライブラリ外部から指定が可能な変数を指定できる。\n・d3.dispatchというメソッドを利用することで、カスタムイベントを定義し、ライブラリから外部へイベントを発火させることができる。\nあたりの性質を活かしているもので、サンプルコード（今回はトグルナビゲーション）を以下に掲載しました。\nToggle Navigation(reusable way) ","date":"2014-12-18T00:00:00Z","image":"http://localhost:1313/d3js-reusable/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/d3js-reusable/","title":"D3.jsを使ったreusableな実装"},{"content":"Natural Earthというサイトで、パブリックドメイン扱いで地図データを配布しています。\nそこで配布されているShapefileは（すべてのファイルを確認していないですが）北方領土や竹島が、日本政府の主張( 北方領土 竹島 )と異なる、日本の領土ではないようなデータになっています。D3.jsの作者(New York Timesに勤めてます)がこのファイルを使用していて、かつShapefileをGeo/Topojsonへ変換する方法を知らない人たちは彼のファイルをそのまま使うので、いつの間にかこのような領土の表示がウェブの一部（例えばデータビジュアライズなどの領域）で事実上の標準、常識になってしまうことに懸念を表明します。\n地図の間違いを受け付ける窓口から上記の内容を送っているのですが返事はありません。パブリックドメイン扱いで公益になるデータを広く共有するために自分の時間を使う人たちのこのようなコミュニティに、誰か日本人が一人でもいたらまた状況は違うかもしれないと考えます（いたらごめんなさい）。\nデータの状況を確認できるようなコードをかきました（gist。リンク先はbl.ocks.org）。\nNatural Earth Border Issue\n","date":"2014-11-03T00:00:00Z","image":"http://localhost:1313/natural-earth-border-issue/images/fi_NaturalEarth_hu_24a1cd9e8b52f811.png","permalink":"http://localhost:1313/natural-earth-border-issue/","title":"Natural Earth配布ファイルの国境について"},{"content":"OpenVis Conference 2014 Part 2: Keynote Day 2\n2. John Resig: Analyzing Art Data for Fun and Profit 二日目のキーノートスピーカーは言わずと知れた著名ライブラリjQueryの作者、John Resigでした。彼はJavaScript関連の本を何冊も執筆している有名なJavaScriptハッカーですが、他方、非常に熱心な日本文化、特に浮世絵のファンとしての一面も持っています。彼のキーノートは、まさにその両面が融合された非常に興味深いものでした。\n講演の様子（YouTubeへのリンク） John Resig - Analyzing Art Data for Fun and Profit\n日本文化と浮世絵 日本の絵画について。私（Resig)は日本絵画の大ファンであり、文化についても個人的に研究している 日本の絵画と文化的背景の紹介 スライドを使って日本の有名な絵画について説明。日本人には馴染みの深いものばかり 葛飾北斎　「富嶽三十六景　神奈川沖浪裏」 江戸時代の地図 浮世絵(Pictures of the floating world, or Ukiyo-e)の紹介 各種美人画 当時の文化的背景の紹介 参勤交代 歌舞伎 当時の社会での歌舞伎の人気。 スポーツイベントと演劇の融合のようなもの。(屋号を観客が叫ぶ辺りをスポーツイベント的と捉えているようだ) 女形の概念 神話の世界 歌川国芳の紹介 擬人化の歴史 国芳による猫の侍　(1840年代) だまし絵。有名な人間で人間の顔を描いた浮世絵 そこに描かれるナマズの絵。これは日本においての地震のメタファー つまりこれは震災で死んだ人々を描いたもの どのように日本絵画を学んだか 日本絵画に関する英語の専門書を読む 日本語の学習。江戸時代における古語も。 古い書（毛筆文）を学ぶ コメント 日本人である私よりも、遥かに江戸文化に理解があるようでした。趣味とは言え凄いことです。そして同時に海外で暮らす人間として、自国文化への知識の欠如は恥ずかしいことだとも改めて認識しました。自国文化におけるaestheticsに対して自分なりの考えと理解を持つことは、英語よりもずっと大切です。印象派絵画と浮世絵の関係などは、欧米人あたりが良く興味を持って聞いてくるトピックですし。\n浮世絵のデータベース このような趣味が高じて浮世絵のデータベースを作ることにした。 Ukiyo-e Search 世界中のデータベースや美術館のサイトから集めた浮世絵のデータベース 検索は英日対応。自力で翻訳したらしい（日本からのユーザーも多い） この部分の実装は、Node.jsの国際化モジュールを使った i18n-node-2 デプロイはAmazon Cloudfrontを利用 版画のデータ収集 これはかなり困難な作業だった。Machine-friendlyなAPIを公開しているようなところは少ない 基本的にはクローリング\u0026amp;スクレイピング 大学や美術館のデータベースは必ずしもベストではない。検索もあまり使い勝手が良くなかった。 実際の作業 PhantomJSを利用して美術館、大学、研究機関などのサイトをクローリング 自動的にクロールして、必要な情報をデータベースに流し込むために、かなり大規模なパイプラインを構築した。 その他に使用したツール Image Scrubber Stack Scraper MatchEngine 類似した画像を検索するツール 実際に使用してみると、元のデータにかなりの間違いが見つかった 間違いの例としては、左右逆のイメージや白黒など。 画像の類似性サーチ 実際の版画を撮影してネットで検索 * offline-crop * node-appcache-glob * オフラインで処理\n画像解析による版画の研究 スクレイピングで得たデータベースを検索すると、たくさんの類似した画像が見つかった。それらは別のものなのか、何か共通点があるのか？ * 例：　二つの良く似た浮世絵（歌舞伎役者） * メトロポリタンの画像データでサインを改変してあるものを発見した * 元々は同じもの。 * 多面的なデータ比較により、歌川国芳もののだと発見した\n* 例：作者不明の浮世絵 * メトロポリタン美術館では作者不明となっていた浮世絵の画像があった * しかし、画像類似検索で上がってきた他の美術館のデータにはアノテーションがあった * そしてメトロポリタンのメタデータは修正されることになった\nメタデータの比較 日本人の名前の表記の揺れを吸収してメタデータを作成するのは困難な作業。(これは日本人にとっても困難な作業なので、日本語の専門家でもない外国人である彼がこの作業を一人でやってのけたのは驚きです。) * 例: 浮世絵画家の「歌川広重」を指す名前のメタデータ * 広重 * 歌川広重 * hiroshige * Hiroshige utagawa * ひろしげ\n* 例：苗字の表記の揺れ * Ando, 安藤, 安東, あんどう, 安堂, etc.\n* これらの揺れを統合して一つのメタデータエントリに仕上げる。 * 発音、漢字、ローマ字等のデータを統合 * JSONとしてストア * (この作業を、彼は_Artist Rectification_と呼んでいた。「アーティスト情報の整流作業」とでも訳せばよいのだろうか？)\n* 利用したツール群 * hepburn * node-enumdict * node-ndlna\nメタデータ統合により作成した東洲斎写楽のエントリ例 JSON:syaraku.json { \u0026quot;original\u0026quot;: \u0026quot;Sharaku Tōshūsai (東洲斎写楽)\u0026quot;, \u0026quot;locale\u0026quot;: \u0026quot;ja\u0026quot;, \u0026quot;kanji\u0026quot;: \u0026quot;東洲斎写楽\u0026quot;, \u0026quot;given\u0026quot;: \u0026quot;Sharaku\u0026quot;, \u0026quot;given_kana\u0026quot;: \u0026quot;しゃらく\u0026quot;, \u0026quot;surname\u0026quot;: \u0026quot;Tōshūsai\u0026quot;, \u0026quot;surname_kana\u0026quot;: \u0026quot;とおしゅうさい\u0026quot;, \u0026quot;surname_kanji\u0026quot;: \u0026quot;東洲斎\u0026quot;, \u0026quot;given_kanji\u0026quot;: \u0026quot;写楽\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Tōshūsai Sharaku\u0026quot;, \u0026quot;ascii\u0026quot;: \u0026quot;Tooshuusai Sharaku\u0026quot;, \u0026quot;plain\u0026quot;: \u0026quot;Toshusai Sharaku\u0026quot;, \u0026quot;kana\u0026quot;: \u0026quot;とおしゅうさいしゃらく\u0026quot; }\nコメント 多分に力技な部分もありますが、趣味でよくここまでやったなあ、というのが正直な感想です。ずいぶんと良くなってきたとは言え、様々な形で保存されている生物学関連の公共データベースのデータを統合する作業を日頃行っている身としては、色々と頷ける部分もある一方、こういう苦労が少なくなる「機械にやさしいウェブ」が世界には必要だという認識も新たにしました。最近は、天文学分野で使われる「ダークマター」と言う語をもじって、「ダークデータ」などという呼び方もあるようですが、情報としては価値があるにもかかわらず、機械からのアクセスが困難なためにネットの海の底にひっそりと眠っているこういったデータをサルベージする技術や標準化がますます必要な時代になると思います。\nフリックコレクションとのコラボレーション このようなデータベースを作成する過程で、世界各地の美術館とコンタクトを取り合うようになり、結果、業務としてフリック・コレクション（ニューヨークにある美術館）とコラボレーションすることになった。\nコレクション画像データの機械による解析 例：イタリアのルネッサンス期絵画のデータ解析 相同性検索で同じ絵画からの画像かどうか、膨大な数の画像を検証 結果、多数のコピー（模倣）、修復痕等を発見した そっくりな画像だが細部と画家のメタデータが異なる（＝模倣） メタデータが一致、画像もほぼ一致するが、画像のある一部分が異なっている（＝修復） これらを発見する技法としては、Neo4jを使ってのグラフ解析を行った Cypher（Neo4j固有のグラフDB用クエリ言語）を使用 SQLでは困難な、複雑なクエリを作成 画像、メタデータをグラフ構造として表現したことにより、間違ったデータが収蔵されてるのを発見することが出来た まとめ * アートをハックするには？ * オークションに行くといい * プレビューの日を使うと、買うか買わないかはともかく、非常に高価なものに間近で見て触れることが出来る\n* 毎日（自分のための）コードを書くということ * Write Code Every Day * いずれそれが仕事になることもある * Research\n全体の感想 ハッカーに好きなことをやらせると面白いことが起こると言う好例だと思いました。世界各地に散らばる、あまり使い勝手の良くない浮世絵のデータベースから、自分で使いたいからという理由で、精度の高いメタデータベースを構築したと言う、最近のテクノロジーを人文学系の研究に適用した結果起きた良い化学反応だと思います。現在の高度に複雑化した世界では、ある分野の専門家でもちょっと専門外のことになるとまるでわからない、ということが頻繁に起きます。彼の使っているツールやアルゴリズムは、画像解析やコンピュータビジョンの研究者の間では「枯れた」ものでしょうし、グラフデータベースやNode.jsベースの各種ツールも全てオープンソース実装で手に入る一般的なものです。しかしそれらを組み合わせて、アート分野に適用した結果、美術館のキュレーターの人力だけではとてもできなかったであろう仕事が完成しています。\n日本絵画に対する情熱から始まり、没頭するうちにそれが仕事の一部にもなったと言う理想的な流れですが、やはり普通の人間と違うのは、仕事の外できっちりと動くものをリリースして、メンテナンスするというモチベーションの維持でしょう。後日私が参加したEdward Tufteのレクチャーで彼が引用したこのフレーズを思い出しました。\nReal artists ship - Steve Jobs\n","date":"2014-07-01T00:00:00Z","image":"http://localhost:1313/openvisconf-2014-johnresig/images/fi_AnalyzingJapaneseArt_hu_48bc4a709b491366.png","permalink":"http://localhost:1313/openvisconf-2014-johnresig/","title":"[OpenVis Conf 2014] John Resig講演"},{"content":"Shapefile→GeoJSON→TopoJSON Shapefile(地理情報システムにおけるオープン標準ファイル形式)をウェブで使用可能なGeoJSONやTopoJSONへ変換するための手順をご紹介します。今回は都道府県ごとに分かれた日本地図を描画することをゴールにします。まずはShapefileからGeoJSONを生成し、その後GeoJSONからTopoJSONを生成することとします。\nShapefileを編集する 国土地理院「地球地図」からShapefileをダウンロードする 今回の目的から都道府県ごとの粒度のものがいいのですが、ないので市区町村ごとの粒度のものをダウンロードし、手元で修正することにします。「地球地図日本のデータ」から第2版ベクタ（2011年公開）行政界 Shapeファイルをダウンロードします。\nQGISでShapefileを読み込む ここからQGISというアプリケーションを使います。展開したフォルダ内にはShapefileが３つありますが、そのうちpolbnda_jpn.shpというファイルをQGISで読み込みます。QGISで「ベクターレイヤーの追加」を選択するとダイアログが表示されますので、ソース→データセットの箇所でShapefileを指定する、という方法で取り込みます。\nCRSを確認する するとこんな感じで表示されます。見慣れた日本地図の形ではないな？と思ったら（そうでなくても）右下を見てください。ここに現在の描画用のCRS(Coordinate Reference System=空間参照系)の設定が(EPSG:\u0026hellip;)と表示されています。赤丸箇所のボタンをクリックすると設定画面のCRSタブが開きます。\nCRSを変更する 最上段の「\u0026lsquo;オンザフライ\u0026rsquo;CRS変換を有効にする」にチェックを入れると、座標参照システムを変更できるようになりますので、EPSG:900913（Google Mercator）を選択し、この画面を閉じます。\n属性テーブルを開く 日本地図の乗っているベクターレイヤーを右クリックし、「属性テーブルを開く」を選択します。\n不要のカラムを削除する 不要のカラムを削除します。左上の鉛筆アイコンの「編集モードを切替」ボタンをクリックして編集モードに入り、「カラムを削除する」ボタンを押すと、ダイアログが表示され、そこで削除するカラムを選択します。今回はnamカラム以外をすべて削除します。\nnamカラムの表記揺れを解消する 愛知県と福岡県と長野県が表記揺れしているので、表記を統一します(例：Aichi KenとAICHIなど)。\n都道府県ごとにまとめる 現在のデータは市区町村ごとにわかれていますので、namカラムの都道府県表記を使って、都道府県ごとにまとめます。「ベクター」→「空間演算ツール」→「融合」を選択すると図のようなダイアログが表示されるので、融合フィールドに「nam」を選択します。「出力シェープファイル」はお好きなものを、「結果をキャンパスに追加する」をチェックすると融合した結果を現在開いているファイルへベクターレイヤーとして追加されます。\n日本語表記とIDを追加する 使い勝手を考えて、カラムを追加します。左上の鉛筆アイコンの「編集モードを切替」ボタンをクリックして編集モードに入り、「新規カラムを作る」ボタンを押すと、ダイアログが表示され、そこで新規カラムの名称と幅を指定します。追加には外部ファイルを読み込む方法と、QGIS上で手入力する方法とあります。\nShapefileとして保存する ベクターレイヤーを右クリックし「名前をつけて保存」を選択すると図のようなダイアログが表示されるので任意の設定をして保存します。これでShapefileの編集をおわります。\nShapefileをGeoJSONに変換する ShapefileをGeoJSONに変換する GDALというツールを使って、ShapeファイルをGeoJSONに変換します。一つ前のステップで、ファイルを保存する際にGeoJSON形式を選べばGeoJSONに変換することが可能です。別な方法としてGDALを使う方法もあります。GDALはMacであればHomebrewでインストール可能です。ogr2ogr -f geoJSON (出力ファイル名) (入力ファイル名)というコマンドを実行すると変換されます。\n生成されたファイルの中身はこんな感じです。\nGeoJSONをTopoJSONに変換する topojsonというツールを使って、GeoJSONをTopoJSONに変換します。topojson -o (出力ファイル名) (入力ファイル名) -pというコマンドを実行すると変換されます。-pをつけないとGeoJSONのときにあったプロパティがすべて含まれなくなってしまいます。\n手元のPCでGeoJsonをTopoJsonに変換したい場合 生成されたファイルの中身はこんな感じです。\nTopoJSONを読み込んで地形を描画する こんな感じで、描画することができました。今回加工したファイルはGitHubに掲載しています。\nData of Japan | Land ","date":"2014-05-18T00:00:00Z","image":"http://localhost:1313/shapefile-to-topojson/images/fi_Shape2Topo_hu_8865267ff7c1e0dd.png","permalink":"http://localhost:1313/shapefile-to-topojson/","title":"ShapefileからTopoJSONを生成する"},{"content":"\n参加者がディスカッションの議題を持ち寄りunconferenceがスタートしました。実際のタイムテーブルはこのような感じです。\n* http://visfest.com/d3unconf/\nせっかくなので私も一つ提案してみました。**Network visualizations; d3 + sigma + Cytoscape etc.**と言うのが私の提案したセッションです。\n実際のディスカッション 普通のカンファレンスとは異なり当日にテーマを決めるため、誰かがスライドを使って話すと言う事は無く、イーゼルパッドとペン、そしてラップトップを持ち寄り、そのテーマについて皆で話し合います。当然全て英語ですので、日本からも参加してみたいと言う方はここで尻込みしてしまうかもしれませんが、基本的に話を聞くだけのカンファレンスとはまた違った面白さもありますので、機会があればぜひ挑戦してみてください。各トラックは並行して行われますので、全部に参加する事はできません。まずリストを見て興味のあるトピックを選び、そのセクションへ向かいディスカッションに参加します。しかし、あまり内容に興味が持てない場合や、他のセッションの方が面白そうな場合には、自由に移動しても問題ありません。私もとりあえず全体のリストを見て、面白そうだと思ったものにいくつか参加してみました。\nクライアントサイドMV*とD3.jsの併用 午前はまずクライアントサイドMV_とD3.jsとの連携についてのトラックに参加してみました。参加者には、AngularJSなどをD3.jsと共にかなり使い込んでいる人、MV_との連携に懐疑的な人など混ざっていて、特定のフレームワークとの併用を行う場合の深い議論を行うというよりは、各参加者が使っているものとの連携に関する体験談などを持ち寄る感じでした。きちんと数えてはいませんが、AngularJSとBackbone.jsユーザーが多い印象でした。私は両者ともちょっとだけいじった事があるのですが、Backboneがかなり薄いフレームワークで自分でかなりの部分を作らなければならないのに対し、Angularは様々な機能があらかじめ含まれており、設計思想そのものがかなり異なります。この話題は様々な場所で行われています:\nContrasting Backbone and Angular Angular, Ember, And Backbone: Which JavaScript Framework Is Right For You? D3.jsを組み合わせるかどうかという以前の部分で好みが別れるため、なかなか深い部分までの議論には至りませんでしたが、実際の連携に関しては、この辺りが参考になると思います:\nD3 on AngularJS なお、AngularJSとD3.jsの連携に関しては、本も出ているようです\n* D3 on AngularJS: Create Dynamic Visualizations with AngularJS\nネットワーク可視化 次は自分がディスカッションのリーダーとしてネットワーク(グラフ)可視化のトラックに参加しました。まとめは（英語ですが）こちらにあります。\nd3unconf session (11:30-12:30) Network Visualization 「再利用可能なチャートモジュールを」と言う目標でd3.chartライブラリが作られているように、ネットワーク（グラフ）可視化分野にも同じような考えが必要だと感じました。D3.jsで作られたよくあるネットワーク図は、こんな感じのものだと思います\n* Yeast PPI Network Generated in Cytoscape\nこれだけで確かに取り敢えずグラフの構造を見ることは出来ますが、実際に使えるアプリケーションにするには、\nパン、ズームなどの基本的な操作の追加 レイアウトオプションの提供 基本的なグラフアルゴリズムの実装 等、様々なものが欠如しています。これらは自前で作るよりも、共通で使えるライブラリとして用意されていた方がより効率的です。この辺りの整備がグラフ描画用JavaScriptライブラリには必要でしょう。手前味噌ですが、ある程度の大きさのネットワークをCanvasを用いて描画するならば、cytoscape.jsは良い選択だと思います。基本的なレイアウトアルゴリズムやUI、ネットワーク構造を操作するための高レベルAPIも整備されていて、レンダリング品質も高いです。\nまた最近は、クライアントのパフォーマンスが非常に高い場合、サーバー側にタスクを投げる必要はあるのかと言う問題もあります。グラフの大きさや構造によりますが、今の計算機のパワーを考えると、最短経路検索や簡単なクラスタリングなどはJavaScriptで書かれたクライアント側での処理とする方が自然です。そうなるとますます自前での実装は効率が悪いので、既存のプロジェクト同士が協力して「車輪の再発明」を避ける方向に動くべきだと感じました。\nWebGL/WebCLを利用した大規模データの可視化 このセッションはLeoさんと言う最近データ解析の会社を立ち上げた方がメインで開発しているSuperconductorと言うフレームワークの話題が中心でした。これは現状で考えられうる最も先端のWeb関連テクノロジーを組み合わせて作られています。\n* Superconductor\nこれは独自のDSLでデータ可視化の方法を記述することにより、GPUプログラミング特有の極めてローレベルな記述を覆い隠すようなフレームワークです。目標としては、OpenGLやGPGPUプログラミングに精通していないデータ解析者やプログラマにもGPUのパワーを活用できる機会を与える、と言うもののようです。ウェブブラウザ上で大規模なグラフィックスを描画したいときは、WebGLを使うというのが徐々に一般的になってきています。ゲーム業界などでも盛んに使われ始めていますので、WebGLは実際のプロジェクトに使うのに十分成熟してきたと感じます。一方、WebCLに関してはまだまだ使える環境が極端に限られるため、これからの技術ですが、数十倍・数百倍のオーダーで並列可能なアルゴリズムを高速化したい場合、現実的にはこれしか選択肢はないと思われますので、これから普及に入っていくと思われます。データ可視化の分野だと、レイアウトの計算やエッジバンドリングなど、非常に重い計算をしなければならな部分が幾つか存在するので、そういった部分もGPUを使って並列化することにより、WebGLとの組み合わせで、ほぼリアルタイムでインタラクティブな解析ができるようになると思います。\n更に、PathGLと言うこの辺りのGPU活用ノウハウをD3.jsと組み合わせたフレームワークも紹介されました。\n* PathGL\nバックエンドかフロントエンドか？ ここまでクライアントが高性能になると、何をバックエンドに任せ、何をフロントエンドで処理するかと言う問題も出てきます。現在は移行期に当たり、ハイパフォーマンスなクライアント（ハイエンドデスクトップマシンなど）が利用できる場合、かなりの部分をフロントエンドで行っても問題がない一方、タブレット等で走るブラウザではまだまだ使いものにならないアプリケーションも数多く存在します。もしユーザ（ここでは科学技術系の複雑な可視化ソフトウェアのユーザ）がそういったデバイスでの作業を求めた時、クライアントの種類によってサーバから配布するソフトウェアを切り替える必要があるかもしれません。\n以下はこのセッションで触れられた最近のブラウザを使って実装されたアプリケーションの例です\n* GLSL Sandbox\n* Welcome to the stellar neighborhood.\n学術的な内容になりますが、このあたりの大規模データのインタラクティブな解析、と言うテーマについて論じられたペーパーも紹介されました:\nZ. L. Liu, B. Jiang, and J. Heer. imMens: Real-time visual querying of big data. Computer Graphics Forum (Proc. EuroVis), 2013. （ちなみに、ラストオーサーの方はD3.js作者のMike Bostock氏の院生時代のアドバイザーです。）\nニューラルネットワークの可視化 バズワードと言っていいくらい、最近はメディアでも「機械学習」や「ディープラーニング」と言った言葉を耳にするようになってきました。このセッションは、機械学習の手法でも歴史の古いニューラルネットワークの学習過程等を可視化してみようというもので、計算機科学の博士課程の学生さんがリードしていました。よく入力、出力の各ユニット、その間の隠れ層を接続したネットワークを可視化したものはよく見かけると思います。教師あり学習の場合、トレーニングセットを食わせている時にどのようにネットワークがデータを学習しているのかをリアルタイムで見えるように、ブラウザで動くクライアントを作ろう、と言う感じです。このセッションで紹介された以下のライブラリは可視化そのものがゴールではないですが、ブラウザひとつで実際に学習プロセスを走らせてしまおうというもので、教材としても面白いのではないかと思いました。\n* ConvNetJS\n私も学生時代にパーセプトロンから始まり、バックプロパゲーション法やら何やら単純なものはやって、おもちゃのような顔認識モジュールを実装したりはしましたが、知識が古いままなので色々とアップデートしなくては\u0026hellip;と言う思いを新たにしました。実は自分が関わっている分野でも、label propagation等の機械学習の手法は最近盛んに用いられ、応用分野はどんどん広がっています。研究に直接関わらない人でも、プログラマーが「リテラシーとしての機械学習への理解」を求められる時代は確実に来ると思われます。\n参考: * HotNet\n生物学と可視化 これも意外だったのですが、なぜか生物学関連のセッションがありましたので参加してみました。果たしてそのディスカッションのリーダーは、私の業務プロジェクトのコラボレーターの方でした。トピックは生化学的パスウェイの可視化についてでしたが、現実的にはそれをブラウザ上で行うと言う事は、ブラウザ上にHTML5関連技術を使ってVisioやOmniGraphのようなソフトウェアを構築する事に等しいので、他分野の方にこういう分野がある事を紹介し、協力者を募ると言う感じでした。私も便乗して、自分のプロジェクトを紹介してみました(下図を参照)。データの内容にはそれほど深く立ち入りませんでしたが、取り敢えず複雑な可視化を求められる問題のドメインが存在して、そういう方面で才能のあるプログラマを求めているよ、と言う思いは伝わったと思います。\nNeXO リアルタイムデータ さて最後のセッションにもなると、皆各自でコードを書いていたり酒を飲んでいたりとグダグダになりつつあったのですが、まあそれもこの形式のいいところということで。最後に覗いてみたこのセッションでは、Leap Motionを使い、そこから得られるデータをリアルタイムのデータストリームとみなし、それをD3.jsを使ったJavaScriptのコードで可視化する、と言った感じでした。まあお遊びといえばそれまでですが、ジェスチャー入力はまだまだ色んなポテンシャルがあると思うので、こういう遊びの中から色々と面白いものが生まれて行けばいいと思います。\nまとめ カンファレンスの名前こそd3.unconfでしたが、扱った話題はD3.jsに限らず「データ可視化の実際」「可視化の現場」全般に渡るものでした。そしてそこに参加している人々も多岐に渡り、ソフトウェア開発者、データ解析者、データ解析サービス系スタートアップの創業者、計算機科学の大学院生、デザイナー、そしてGitHub本社に勤めてるエンジニアの方等も参加していました。こういうところで知り合い、Linkedinで繋がって行くと言うのが最近のアメリカの人脈開拓法なんだな、と実感しました。意外だったのは、アカデミア方面からの参加者がけっこう居たことで、データ解析や可視化といった話題に真剣に取り組むには、やはりそれなりの学術的バックグラウンドがないと厳しいということも感じました。そして今回このカンファレンスをホストしてくれたGitHubは、典型的な最近のテック系企業という感じで、エントランスホール付近には様々なオブジェやDJブース、実際にお酒も飲めるバーまで設置されていて、優秀な人材の奪い合いへの対応に余念がない感じでした（笑）。\n","date":"2014-04-20T00:00:00Z","image":"http://localhost:1313/d3-unconf-2014-2/images/fi_D3Conf2014-2_hu_379031e23b8d81aa.png","permalink":"http://localhost:1313/d3-unconf-2014-2/","title":"d3.unconfレポート[後篇]"},{"content":"Keiichiro Ono UC, San Diego School of Medicine Cytoscape Consortium\nはじめに まず自己紹介をさせていただきます。私はアメリカ西海岸、カリフォルニア州の最南端に位置するサンディエゴ在住のソフトウェア開発者です。カリフォルニア大学サンディエゴ校(UCSD)と言う大学の医学部で、生物学者や医師に混じって彼らが研究で必要とする各種ツールを開発しております。分野としてはbioinformaticsと呼ばれるものです。\n先週の土曜日(3/29/2014)、サンフランシスコにあるGitHub本社にて行われたd3.unconfというD3.jsや可視化周辺の実務的な話題を扱う会議がありました。Cesar Chavez Dayで三連休だと言うこともあり1、私にとってはちょうどいいタイミングでしたので、久しぶりにサンフランシスコまで足を伸ばしてみました。このカンファレンスがどのようなものだったか一通りレポートしてみます。\nどんなカンファレンスか？ 可視化のカンファレンスと言っても、現在は様々な傾向のものがあります。アカデミック寄りなIEEE系の学会や分野特化型の学会もありますし、もっとカジュアルなコードレベルの話題を主に扱うような勉強会もあります。昨今、様々な要因が重なり後者に属するカンファレンスがここアメリカでは増えてきたような気がします。ここで言う要因とは、以下のようなものです：\nパーソナルコンピュータ、モバイルデバイスの劇的な価格低下と高性能化 第二次ブラウザ戦争の遺産としての非常に高速化されたJavaScriptエンジンとCanvasをはじめとするHTML5関連テクノロジー クライアント関連テクノロジーのブラウザへの集約 各種デバイスから生み出される凄まじい量のデータ それらを扱うためのオープンソースツール群の発展 そしてそれらを利用したいスタートアップや大手企業の可視化分野への関心 まだ他にも色々とありますが、これらの要因が重なり、可視化のための実際のコードを書くvisualization practitioner(実務家)向けのカンファレンスが増えています。私はオープンソースソフトウェアを書く事が日常の業務ですが、これは自分の関係する分野に限った事ではなく、メジャーなオープンソースプロジェクトは、事実上業務として開発している人々に支えられていると言う面が大きいです。そしてデータ可視化分野でもそのように職業としてオープンソースソフトウェア(OSS)を書いている人々も多く、それが現在の状況に繋がっています。こういった背景もあり、今回のカンファレンスはオープンソースソフトウェアに関わる開発者向けの「実際に手を動かす人々」をメインターゲットに据えています。それを強調する意味もあり、カンファレンスへの登録時にD3.jsを使い自分で作ったサンプルをgistへアップロードして、bl.ocksを使い一覧にしてみると言う試みも行われました。\n参加者が登録時に送ったBL.OCKS一覧: http://visfest.com/d3unconf/blocks.html Unconference 今回のカンファレンスは、d3.unconfと言う名前の通りunconference（アンコンファレンス）形式で行われました。日本ではあまり馴染みの無い言葉かもしれませんが、unconferenceと言うのはテック系のワークショップやカンファレンスでは最近よく使われる手法です。これは当日まで細かいトピックについては決定せず、スピーカーも基本的には決めない形で集まります。そして開催日の朝にその日話し合うトピックを参加者らが出し合い、主催者は各トラックの時間と場所だけを指定して、参加者から提示されたトピックを各トラックに割り当ててその日のスケジュールを決定します。その後ディスカッションが成立しやすいように、数人から数十人程度のグループに分かれて各トピックについて話し合います。余談ですが、Googleがオープンソースプロジェクト開発者向けに毎年本社で開催しているGoogle Summer of CodeのMentor Summitもこの形式で行われています。こちらにも何回か参加しましたが、様々な話題にカジュアルに参加できて楽しかったです。\n今回はIrene Ross氏によるキーノートで始まりました。彼女はBocoupと言う会社で各種可視化システムやアプリケーション構築のコンサルティング、オープンソースソフトウェアの開発、関連ツールの教育を行っている方で、Misoプロジェクト2と言うD3.jsをより便利に使うためのツール群を作っていらっしゃいます。\n* The Miso Project: http://misoproject.com/\nこのMisoにはd3.chartと言うサブプロジェクトが含まれています。これはD3.jsの作者であるMike Bostock氏がTowards Reusable Chartsと言う記事で論じている「チャート生成コードの再利用性」にフォーカスしたツールです。彼女の講演は、この再利用問題をテーマにしたものでした:\nArchitecting code with d3: https://speakerdeck.com/iros/architecting-code-with-d3 D3.jsをお使いの方なら分かると思いますが、D3は自由度やカスタマイズ性の高さの代償として、たとえ求めるものがシンプルなバーチャートであっても殆どの要素を一から書かなければならないと言う問題があります。そういったものは、実際のチャート部分、軸、タイトル、レジェンドと言った共通要素に分解する事ができます。このような様々なチャートに共通する概念をコンポーネント化して、他のデータセットに対しても再利用可能にすると言うのがd3.chartの主なゴールです。ここは私も昨年のD3.jsアドベントカレンダーで記事を書かせていただきましたので、興味のある方はこちらもあわせてどうぞ。\nD3.js Advent Calendar 2013 Day 21: D3.jsと周辺ツールを使ったデータの可視化 また彼女は今月末にボストンで行われるOpenVisカンファレンスのオーガナイザーでもあるので、そちらの方の宣伝もしていました。私はこちらにも参加しますので、そのレポートもまた後日。\n1.カリフォルニア州政府は、この日をアメリカ国民の祝日にしようと連邦政府に働きかけているため、州政府関連施設の職員は休みになります。私はカリフォルニア大学の研究系スタッフなので、州政府職員とみなされます。 2.日本人からすると若干奇妙なネーミングですが、「折り紙」「俳句」など、ある程度英語圏で浸透している日本語は最近よくOSSプロジェクトの名前に使われるようです\n（本レポートは後篇に続きます。）\n","date":"2014-04-11T00:00:00Z","image":"http://localhost:1313/d3-unconf-2014-1/images/fi_D3Conf2014-1_hu_81b12aae9a52e25e.png","permalink":"http://localhost:1313/d3-unconf-2014-1/","title":"d3.unconfレポート[前篇]"},{"content":"たとえばある変数の値が350の場合、ある棒グラフではY座標はいくつになるでしょうか。またはあるバブルチャートでは円の直径はいくつになるでしょうか。\nインプットとしてのデータセットが持つ数値体系や幅（最小値〜最大値）などは、たいていアウトプット先の例えば液晶ディスプレイなどとは数値体系や幅（例えば表示領域など）が異なるため、両者をつなぐための方法論が必要になります。視覚化される要素の座標や大きさだけではなく、色や数値ではない例えばカテゴリーなどにも同様の手法が適用可能です。\nProcessingではmap、D3ではscaleという機能でまとめられています。しかしここには「正規化」という概念が隠されています。正規化という言葉にはいくつかの意味があり、ここではベクトルにおける正規化のことを指します。\nその変数が含まれるデータセット全体（もしくは基準とすべき）最小値〜最大値の幅の中で、どの辺りにあるかを、0.0〜1.0の間で数値化します。そしてその値を表示のための値として再度変換します。\n前者を正規化(normalize)、後者を補間(interpolation)と呼ばれることが多いです。\n※P5\u0026hellip;ビジュアライズのためのフレームワークProcessingの略称。P5には他にもnormalize()やlerpColor()などの関数もありますがわかりやすさのために図からは省略しています。\nなんでこんなことをするのかというと、いくつか理由があげられます。\n１回正規化されたデータは、様々な表示スタイルに利用可能。 ユーザーインタラクションによって、表示領域の幅が変更されたり、レイアウトのフォーマットが棒グラフから地図へ変更されても、正規化されたデータは有効で、表示スタイルにあわせて補間して使えばよいです。補間というと語感的に少しわかりづらいですが、イメージ的には伸張とかレンダリングという言葉が近いかもしれません。\n異なるデータを同様に扱うことができる。 いったん正規化という枠にはめることで、多様なデータを同様に扱うことができるようになります。たとえば統計データとセンサーが取得したデータを関連づけて表示することも可能になります。\nプログラムが生成する値との親和性 プログラム内部で生成される乱数やパーリンノイズ、またサイン／コサインなど三角関数で生成される値なども正規化された値（0.0〜1.0）で用意されることが多いです。外部から取り込んだ数値も、プログラム内部で生成された数値も、同様に扱うことができるようになります。\n正規化と補間は、正比例で入出力がなされるべきとは限らない。 描くグラフによって y=ax+b のような正比例、ではない関数を用いるものがあるためです。\nProcessingの場合、組み込み関数ではおそらく正比例のみが用意されています。\nD3では統計学で必要なものが一通り用意されているので最適なものを選ぶことができます。一つのオブジェクトにつき正規化と補間で同じスケーリングの仕方が適用されます。\n","date":"2014-03-24T00:00:00Z","image":"http://localhost:1313/normalize-visualize/images/fi_Normalize_hu_294fe4681070b782.png","permalink":"http://localhost:1313/normalize-visualize/","title":"ビジュアライズにおける正規化"},{"content":"去年（2013年）クラスカで行われたFITC Tokyoに参加してきて、最も印象深かった話の一つが、Kyle McDonaldの \u0026lsquo;How to Give Everything Away\u0026rsquo;（あらゆるものを公開する方法）という話でしたので、ご紹介させてください。\nFITC2013 \u0026lsquo;How to Give Everything Away\u0026rsquo;（あらゆるものを公開する方法）Kyle McDonald | FITC2013 公式サイトでは \u0026lsquo;give away\u0026rsquo; を「公開する」と訳してるんですが「プレゼントしてしまう」とか、英英辞書ひくと「うっかり誰かが優位性を持つことができるように」というニュアンスもあるようです。言葉の並びをみると差し出すことによって自分から遠ざける（ざかる）というニュアンスもありそうです。\nそして、何を \u0026lsquo;give away\u0026rsquo; するのかとして具体的には、アイデアを共有すること、自分の書いたソースコードをすべてccライセンスで公開すること、個人情報を含むキータイプすべてを自動的にtweetすること、が語られます（一つすごく面白いエピソードがあるのですが話の筋から逸脱するのでそれは機会を改めます）。アイデアもコードも個人情報もさらけ出すことで、自分のプライベート領域にあるものをパブリック領域にさらけ出し、そのことによってプライベートとは何か、パブリックとは何かを考察したいという動機があったようです。\n講演を聞いていて、具体的な事例ばかりが語られたものの、そこには貫く一本の個人的な生き方の物語、フィロソフィーのある話だな…と理解しつつ、その行き着く先がよくわからなかったので、イベント後の二次会の飲みの席で本人に聞いてみました。\n「すべてを \u0026lsquo;give away\u0026rsquo; するということは、その結果、自分はemptyになってしまうということだと思うけど、その先には何があるの？」と質問してみたところ、\u0026lsquo;You\u0026rsquo;re complete when you\u0026rsquo;re empty.\u0026rsquo; という返事が返って結構驚きました。自分は空っぽになることで初めて完成するんだということ。\nそこで思い出したのが、彼の同様の内容の話を、アメリカはミネアポリスで半年前に開かれたカンファレンスで観ていたのだけど、その時出てきた茶室の話。このFITCの時に出てこなかったんですよね（遠慮だったのか配慮だったのかは不明だけども）。\nEyeo2012 - Kyle McDonald （道教や禅の）「哲学は、完全そのものより、完全を追求する過程により重きを置くほどダイナミックなものであった。不完全を完成させた者のみが、真の美を見出すことができる。人生や芸術の力は、それが成長する可能性を秘めている点にこそあるというのだ。茶室では自己との関係において全体の効果を完成させることが、客の想像に任されている」岡倉天心「茶の本」IBCパブリッシング刊より引用。\n続けて本人曰く「オープンソースは、茶室です。それは誰もが等しい存在であり、魂の鏡です。オープンソースの芸術は、各投稿者が自分自身の作業を如何に完成させるかであり、不完全なもの（バグ）に如何に協業で立ち向かうかにあるのです。」\n茶道とオープンソースが結びついて語られたのが新鮮でした。時には自分の中に隠しておきたいこともあるけどそれでも公開するんだというようなことを言ってました。\nここからは少し個人的な解釈です。\n彼は世界的に活躍しているまだ20代のアメリカ人メディアアーティストで、ややGitHubやオープンソースというものに傾倒しすぎている物の見方かもしれませんが、気付かせてくれるものはあります。「すべてを \u0026lsquo;give away\u0026rsquo; する」ことと「空っぽになることで初めて完成する」ことの結びつきが少し弱いように感じたのですが、「茶の本」を読むと一つの地続きな思想が見えてきます。\nそれは例えば、老子は「真に不可欠なものは虚ののみ存在する」として、部屋の実体は屋根と壁に囲まれた空虚な部分に見出されるのであって、部屋と壁そのものではないとか、水さしは水が大事であって水さしの形や素材にあるのではないといったようなニュアンスです。\n福岡伸一さんの「動的平衡」も思い出されます。「絶え間なく動き、入れ替わりながらも全体として恒常性が保たれていること。」こそが生き物の生き物たる条件なんだといいます。\nJohn Lennonのアルバム \u0026lsquo;Some Time in New York City\u0026rsquo;に収録されているオノ・ヨーコの曲に\u0026quot;We\u0026rsquo;re All Water\u0026quot;というのがあります。\nあなたは水\n私も水\n私たちはそれぞれの容器に入った水\nだからこんなに簡単に出会える\nいつの日かみんな一緒に蒸発しましょう\nたとえ水がなくなってしまっても、\n私たちはたぶん容器を指さして言うでしょう\n「私たちはあそこにいる、あの容器は私です」と\n私たちは容器の番人\nオノ・ヨーコ \u0026ldquo;We\u0026rsquo;re All Water\u0026rdquo;\n加えて、自分の外に出していないものは自分が死んでしまったら誰からも知ることのないまま存在しなくなってしまうということとか、他人から認知される自己こそが自己のすべてであるというようなニュアンスもつけ加えられるかもしれません。\n情報の出し入れや扱いから派生する、アイデアや特許を巡る紛争や権力闘争。そういったものから一旦離れて、なすべきことに集中できる茶室のような場所…として彼がゆび指すのがGitHubです。おぉ…。\n具体的なエピソードとして語ってくれた話で終わらせたいと思います。あるコーダーがccライセンスでコードを公開していて、掲示板に大量の質問と少しの回答が載せられていたのだけど、そのうち質問しか載らなくなり、第三者のある人がこのコーダーは亡くなったんだと告げたとのこと。それ以降は来訪者同士で回答を教え合うようになりました。オープンにしておいたことで、何がどう作られているのかをリバースエンジニアリングして引き継ぐこともできるし、これを使うときに彼のことを少し思い出すのかもしれないですね。\n","date":"2014-01-14T00:00:00Z","image":"http://localhost:1313/how-to-give-everything-away/images/thumb_ph_vizjp_hu_226faecc4e6a3702.png","permalink":"http://localhost:1313/how-to-give-everything-away/","title":"すべてを明け渡すことではじめて完成する、茶道としてのオープンソース"},{"content":"2013年12月20日、「データカタログサイト試行版」として、data.go.jpが開設されました。\n「各府省の保有データをオープンデータとして利用できる場をつくり、データの提供側・利用側双方にオープンデータのイメージを分かりやすく示すことを目的としています。」とのことで、「日本のオープンデータ憲章アクションプラン」に基づいたものです。\nSNSを検索すると「マシンリーダブルなデータじゃない」や「同種のサイトが多すぎる」という指摘がいくつか見られ、同感ではあるのですが、以下の二つのことが画期的だと考えています。\nCC-BYライセンスが付与されていること（利用規約 第１条）\n省庁横断でデータが集められていること\nまずは場作りと様子見であるようなので、ここで「まだできてない」じゃなくて「二歩進んだ」進んだと捉えて今後の動きにも注視していきたいところです。\nさて、どんなデータが集められているのでしょうか？このサイトはnet commonsとCKANが使われているようで、CKANはデータカタログサイトを立ち上げる際によく利用されるもので、これにはAPIが用意されています。これを利用することで登録されているデータのメタデータについて、クロス集計的に、立体的に捉えることができるようになるのですが、これが現時点で公開されてなく残念です。\n集められているデータの大枠が掴めるように、メタデータやタグを手動で拾って並べてみました。経年で記録していけばそれ自体も一つのデータになるかと思います。\nmeta data of data.go.jp\n些末なところだと、タグやキーワードの与え方にいくつか課題がありそうです。\nシステム的な観点では、\ncsvやtsvなど区切りに使用される文字はタグやキーワードに含めない %がパースできていない 2020年30％ IA的的な観点では、\n・半角、全角を名寄せすべき Ｇ８とG8\n半角、全角を名寄せすべき Ｇ８とG8 一つのキーワードに二つ以上の項目を含めてしまっているのは避けるべき 予算_平成22年度 ともあれ、色んなことが発見できそうなので、じっくりみていきたいところですね。\nオープンデータ推進へ約１万種を公開　内閣官房 - 朝日新聞 CKANについて – data.go.jp ","date":"2013-12-30T00:00:00Z","image":"http://localhost:1313/data-go-jp/images/fi_DataGoJp_hu_19aff964a7c593f8.png","permalink":"http://localhost:1313/data-go-jp/","title":"data.go.jp開設"},{"content":"Webの発明者であるティム・バーナーズ＝リーが、オープンデータのための5つ星スキームを提案しています。\n★(どんな形式でも良いので) あなたのデータをオープンライセンスでWeb上に公開しましょう★★データを構造化データとして公開しましょう (例: 表のスキャン画像よりもExcel)★★★非独占の形式を使いましょう (例: ExcelよりもCSV)★★★★物事を示すのにURIを使いましょう，そうすることで他の人々があなたのデータにリンクすることができます★★★★★あなたのデータのコンテキストを提供するために他のデータへリンクしましょう 5 ★ オープンデータ これはとてもキャッチーさを狙った図で、これの元にあるコンセプトはLinked Dataというもので、TEDやGov2.0 Expoなどでも本人が講演し、その必要性を訴えています。Raw Data Now!\n2009年TED「ティム・バーナーズ＝リーが示す次のウェブ」 2010 Gov2.0 Expo \u0026ldquo;Open, Linked Data for a Global Community\u0026rdquo; Linked Dataとは「構造化されたデータをWeb上で相互にリンクづけして、それらを公開できる一連のしくみを提供する実践的方法」（近代科学社「Linked Data」より）とのこと。\n今年（2013年）2月に訳書が出たこちらで詳しく論じられています。 [amazonjs asin=\u0026ldquo;4764904276\u0026rdquo; locale=\u0026ldquo;JP\u0026rdquo; title=\u0026ldquo;Linked Data: Webをグローバルなデータ空間にする仕組み\u0026rdquo;]\n最近ではLinked Open Dataというように、Linked DataとOpen Dataを合わせて語られることもありますが、Open Dataは「データを配布する際に一定のライセンスを適用することによって，データの消費者が自由にアクセスや再利用，再配布をすることを可能」とすることで、Linked Dataは、「Linked Dataは構造化データを適切に公開・共有するためのWeb技術」で、これらを一体的な取り組みとして表現した言葉がLinked Open Dataといえそうです。 （上記定義はいずれも加藤文彦氏のLinked Open Dataより引用）\n","date":"2013-11-08T00:00:00Z","image":"http://localhost:1313/linked-data/images/fi_LinkedData_hu_292b4ac344f2f9a7.png","permalink":"http://localhost:1313/linked-data/","title":"Linked Data"},{"content":"ブラウザー上でデータビジュアライゼーションをやる場合にどの技術を使うべきなのか。そんなテーマでTwitter社でVisual Analysis \u0026amp; Insights teamのMiguel Rios氏が、今年5月にボストンのOpenVis Conferenceで講演しました。\n講演での順番とはちょうど逆になりますが、話の流れがわかりやすい順番に構成します。\n主にブラウザーのレンダリングの仕方が、DOM構造を残した状態なのか、そうでなく1つのDOM要素(canvas要素)の中にすべて描画するのか、という点を切り口に、主要な実装方法であるHTML/CSS、SVG、HTML5 Canvas、WebGLを取り上げ、整理しています。\n実装にとりかかる前に明らかにすべきこと 要素はどのくらいの数になるのか それらの要素はどのくらい複雑な形をしているか、また配置するか どの程度インタラクティブ性を持たせるか アニメーションや変形はさせるのか 古いブラウザをサポートする必要があるかどうか 関係するオープンソースの例やフレームワークはあるのかどうか これらの検討項目とともに依ってたつ実装方法と実際のTwitter社での事例とともにまとめた表を使いながら説明がされました。\nウェブ標準技術とビジュアライゼーションとの親和性 こちらも講演ドキュメントで一番右側の列がハイライトされてますが、これはその項目を説明中のキャプチャだからなので気にしないでください（すべてフラットに扱われている表が講演ドキュメント中ないため）。わかりやすくするため、並び順を一部入れ替え翻訳すると以下の通りになります。\nウェブ標準技術HTML/SVGHTML 5 CanvasWebGLオープンソースのフレームワークd3.jsprocessing.jsPhiloGLTwitter社での実例2012 U.S. ELECTIONS MAP2011 JAPAN EARTHQUAKENEIL ARMSTRONG'S VISUALIZATION要素の数少ない多い多い要素の複雑さ複雑簡易複雑インタラクティブ性なしありありアニメーションなしありありブラウザのサポートIE7+モダンブラウザのみモダンブラウザのみ それぞれの実装法の用途 文章としては以下のようにまとめられています。\nHTML/SVG要素が少ない、形状が複雑、インタラクティブなビジュアライゼーションに適している。CANVAS小規模から比較的多数の要素やアニメーションに適している。WEBGL小規模から非常に大多数の要素、複雑な形状のアニメーションや3Dビジュアライゼーションに適している。\n参照したTwitter社の実装例 2012 U.S. ELECTIONS MAP 2012年選挙の際、大統領候補者によって送られたTweetによるエンゲージメントの可視化。\n2011 JAPAN EARTHQUAKE（リンク先は動画） 3.11の地震発生一時間後、日本発のTweetがどのようにRetweetされ世界中に伝播していったかの可視化。\nNEIL ARMSTRONG\u0026rsquo;S VISUALIZATION（リンク先は動画） ニール·アームストロングが亡くなったことについての@NASAのTweetがどのようにRetweetされ世界中に伝播していったかの可視化。\n所感 全体的に話の構造がすっきりとわかりやすい理にかなう説明でしたが、DOM構造を活かすかどうかがブラウザー上の実行速度しか念頭にない点は気になりますね。このプレゼンテーションの会場に筆者は居たのですが、会場から「モバイルの場合は？」という質問に「モバイルは今回考慮してないよ」との回答に会場の一部から失笑が起こりました。…なかなかシビアですね。\nまた直接この講演の内容とは関係ないですが、SVG用ライブラリを使った実装でも描画部分をCanvasで行って描画速度をあげているユーザーもその会場にいました。\n降壇あとに直接聞いたところ、Twitter社のデータサイエンティストは4名で、主に社内向け（インターナル）の分析とビジュアライズの方がほとんどだとのことでした。またこの講演の少し後の時期にTwitter社はLucky Sortというビッグデータのビジュアライゼーション会社を買収していますので現在はまた体制が変わっていることと思います。\n実際のプレゼンテーションの動画やドキュメントへのリンクを以下に掲載しますので是非たどってみてください。\nMiguel Riosの講演(スライド) Miguel Riosの講演(動画) Twitter\u0026rsquo;s Miguel Rios on Choosing Viz Methods - Features - Source: An OpenNews project ","date":"2013-11-05T00:00:00Z","image":"http://localhost:1313/openvisconf2013-miguel/images/fi_OVC2013Miguel_hu_b519035d01154df4.png","permalink":"http://localhost:1313/openvisconf2013-miguel/","title":"ブラウザーでのデータビジュアライゼーションにおける技術選定のポイント"},{"content":"世界各国のデータをビジュアライズする場合、国をIDで管理すると複数データの連携が取れ、便利です。\nISO 3166（Wikipedia） Country Codes - ISO 3166 ラテン文字2文字の国名コード、3文字の国名コード、数字の３種類あります。数字だとコーディング中で扱いがしやすいですね。\nデータセットとしては、Datahubに掲載されているものがあります。\niso-3166-1-alpha-2-country-codes | Datahub ここで一つ問題なのはデータビジュアライゼーションで過去のデータを扱う際、現在存在していない国をデータとして扱う場合、ISOでコードが発番されていないことです。例）全く存在しない国（ユーゴスラビア）、政治体制が代わり国名が変わった国（ドイツ、ロシアなど）、各国と並列するカタチで自治州も扱う場合（スペイン）など。\nSpecial code elements not to be used in ISO 3166-1 によるとローカルな環境でアサイン可能な空き番号としていくつか提示されていて、数字のものについても900から999まで使用可能とのことです。\n","date":"2013-10-27T00:00:00Z","image":"http://localhost:1313/country-codes/images/fi_CountryCode_hu_2fe900f04c4e3a09.png","permalink":"http://localhost:1313/country-codes/","title":"カントリー・コード"},{"content":"20年以上シニア・エグゼクティブたちにプレゼンテーションのコーチングやティーチングをしてきているDr.Abela氏が、“Extreme Presentation method”というプレゼンテーションのためのメソッドを公開し本としても出版もしているのですが、その中で、チャートについてのチャートがとてもわかりやすいのでご紹介します。\n“Extreme Presentation method”\nデータ同士の関係性を示したいのか、比較したいのか、分布を示したいのか、構成を示したいのか…などによって選択すべきチャートが異なります。この選択自体が間違っているとデータの内容が適切に示せないことがありえます。\nたとえば棒グラフで表せる内容をツリーマップで表したり、ヒストグラムなのにバー同士の間隔が空いていて視覚的には棒グラフになっている、など。\nこれらは定番として骨組みや構造を理解し、これを元にそれぞれの要件にあったスタイリングをつけていくことが望ましいですし、これらだけがチャートの原型ではありません。\nまたこれは静的なチャートの話で、オンラインのデータ・ビジュアライズにおいては、データ軸を追加することが可能です。わかりやすい例では時間軸がそうです。これまでも同じチャートを何枚か使って例えば時間軸のみが異なる同じチャートを並べて提示することはできましたが、オンラインではそれらをすべて一つのチャートとして表現することが可能です。その際、図のあり方に介入しない方法としてチャート外のユーザーインターフェイスとして時間軸を扱えるようにする方法と、チャートのあり方に介入する方法として既存のチャートのスタンダードなあり方を更新する方法がありえます。これについてもケーススタディが集まっていく中でメソッド（方法論）が確立していくのでしょう。\n","date":"2013-10-26T00:00:00Z","image":"http://localhost:1313/chart-suggestions/images/chartSuggestions-1_hu_9ed21e5710fe9a70.png","permalink":"http://localhost:1313/chart-suggestions/","title":"どのチャートを使うべきか"},{"content":"D3には、外部ファイルの読み込み用にいくつかヘルパー関数が用意されています。ファイル形式によって、D3に読み込んだ後のデータ保持の形式が異なるので一覧にするとこのような感じです。\nAPIリファレンスのd3.csv()項目をみると、d3.csv.parse()、d3.csv.parseRows()、d3.csv.format()、d3.csv.formatRows()、などというメソッドも用意されているような印象ですが、これらはd3.csv()が内部的に使用するので、通常はd3.csv()を利用すればよいです。\ncsvは上図の通り、読み込まれるとデフォルトではオブジェクトの配列に変換されてしまうのですが、これを配列の配列（二次元配列）として読み込みたい場合には、d3.csv.parseRows()を使うのですが呼び出し方としては、汎用的なd3.text()を利用して\n1 2 3 4 d3.text(url, \u0026#34;text/csv\u0026#34;, function(text) { var rows = d3.csv.parseRows(text); // ... }); とすればよいようです。考え方と実装はtsvもdsvも同様のようです。\n","date":"2013-09-22T00:00:00Z","image":"http://localhost:1313/d3-requests/images/fi_D3DatFormat_hu_949364a717a98b39.png","permalink":"http://localhost:1313/d3-requests/","title":"D3: データ形式"},{"content":"耳慣れない名称ですがD3の作者Michael BostockがD3で地理データを扱うために独自に策定したGeoJSONの拡張形式です。\nTopoJSON on Github TopoJSONについて（日本語訳ページ） 特徴 データから冗長性を排した結果、効率的にデータの活用ができたり、ファイルサイズをかなり削減できる。\n国境や州境など複数の国や州が共有する地形データを重複することなく格納できる。 一つの TopoJSON ファイルで、ポリゴン（フィル＝塗り用）と境界線（ストローク＝輪郭線用）の両方を、同じarcメッシュを共有する二つのフィーチャーコレクションとして効率的に表現することができる。 座標計算に固定精度エンコーディングを用いることで正確性を犠牲にすることなく座標値の精度の丸め処理を省略できる。 とのことでこの結果、ファイルサイズをかなり削減(通常のものでは80%程度)できて、効率的にデータの活用もできるとのことです。\n手元のPCでGeoJsonをTopoJsonに変換したい場合 コマンドラインで実行します。Node.js、topojsonをインストールしたのち、Macの場合はTerminalで、topojson -o output.json input.json といったコマンドを実行します。\nCommand Line Reference API Server用APIとClient用APIの両方が用意されています。Server用はGeoJSONファイルやESRI ShapefileをTopoJsonに変換する役割があり、Client用はブラウザでレンダリング用にTopoJsonをGeoJsonに戻す役割があります。Server用はコマンドラインツールとして用意されたものと同じで、Node.jsのパッケージとしてローカルサーバで事前的に実行するか、ウェブサーバでリアルタイムに近い形で実行するかの違いです。\nServer用パッケージのインストール 利用に際しては、Node.jsのパッケージ管理ツールnpmを通じてインストールします。\ntopojson | npm Server用コマンドラインツールのリファレンス Command Line Reference | topoJson Client用JSファイル ヴァージョン1.0.0とそれ以前で関数の定義に変更がありますのでご注意ください。\nTopojson: list of differences between v0 and v1?\nhttps://github.com/mbostock/topojson/blob/master/topojson.js Client用JSファイルで用意されている関数 bisect(a, x) feature(topology, o) featureOrCollection(topology, o) merge(topology, arcs) mesh(topology, o, filter) neighbors(objects) object(topology, o) reverse(array, n) topojsonファイルの構造 TopoJSONのファイル構造\nGeoJSONのファイル構造\ntype=topologyとすることでこのデータがGeoJsonでなくてTopoJsonであることを示す。 objects、arcs、transformの3つのobjectで構成される。 objects…標準であるGeoJSON形式で記述されたobjectを名前でインデックス化。 arcs…objectsに格納されているobject群の座標値を一元的に管理。線のように、点の連続で構成されている。 transform…デルタ符号化された整数の座標をそれぞれのネイティブな値へ変換するための、変換値を保持（大きさと位置の補正） 行政界データでいうと境の部分はそれを共有する双方の県なり市区町村が同じ形状のものを持ちますがこれを一元化したり、座標は一カ所だけ絶対値でもちそれ以外の座標を相対値で持つことで必要な桁数をグッと減らすことができ、その結果ファイルサイズの軽量化が測れる構成になっているようです。またブラウザで表示用にレンダリングする際にはGeoJsonに戻してからレンダリングしますので、地形データはファイルサイズが大きくなりがちで、デコードするコストをかけても転送速度を軽減した方がよい、という考えのようです。\n参考リンク GeoJSON仕様（日本語訳） Difference between GeoJSON and TopoJSON | stack overflow TopoJSON Basics D3.jsとTopoJSONで地図を作る ","date":"2013-09-18T00:00:00Z","image":"http://localhost:1313/d3-topojson/images/fi_TopoJson_hu_3621622b2d4f9990.png","permalink":"http://localhost:1313/d3-topojson/","title":"D3: TopoJSON"}]